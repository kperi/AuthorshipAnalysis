Right	RB
of	IN
Inference	NNP
:	:
Nearest	JJS
Rectangle	NNP
Learning	NNP


Revisited	NNP


Byron	NNP
J.	NNP
Gao	NNP
and	CC
Martin	NNP
Ester	NNP


School	NNP
of	IN
Computing	NNP
Science	NNP
,	,
Simon	NNP
Fraser	NNP
University	NNP
,	,
Canada	NNP


-LCB-	-LRB-
bgao	NN
,	,
ester	NN
-RCB-	-RRB-
@cs	NNS
.	.

sfu.ca	NN


Abstract	JJ
.	.

In	IN
Nearest	NNP
Rectangle	NNP
-LRB-	-LRB-
NR	NNP
-RRB-	-RRB-
learning	NN
,	,
training	NN
instances	NNS
are	VBP
generalized	VBN
into	IN
hyperrectangles	NNS
and	CC
a	DT
query	NN
is	VBZ
classiï	NN
¬	NN
ed	VBD
according	VBG
to	TO
the	DT
class	NN
of	IN
its	PRP$
nearest	JJS
rectangle	NN
.	.

The	DT
method	NN
has	VBZ
not	RB
received	VBN
much	JJ
atten	NN
-	:
tion	NN
since	IN
its	PRP$
introduction	NN
mainly	RB
because	RB
,	,
as	IN
a	DT
hybrid	NN
learner	NN
,	,
it	PRP
does	VBZ
not	RB
gain	VB
accuracy	NN
advantage	NN
while	IN
sacriï	NN
¬	CD
cing	NN
classiï	NN
¬	CD
cation	NN
time	NN
comparing	VBG
to	TO
some	DT
other	JJ
interpretable	JJ
eager	JJ
learners	NNS
such	JJ
as	IN
decision	NN
trees	NNS
.	.

In	IN
this	DT
paper	NN
,	,
we	PRP
seek	VBP
for	IN
accuracy	NN
improvement	NN
of	IN
NR	NN
learning	VBG
through	IN
con	NN
-	:
trolling	VBG
the	DT
generation	NN
of	IN
rectangles	NNS
,	,
so	RB
that	IN
each	DT
of	IN
them	PRP
has	VBZ
theright	NN
of	IN
inference	NN
.	.

Rectangles	NNS
having	VBG
the	DT
right	NN
of	IN
inference	NN
are	VBP
compact	JJ
,	,
conser	NN
-	:
vative	NN
,	,
and	CC
good	JJ
for	IN
making	VBG
local	JJ
decisions	NNS
.	.

Experiments	NNS
on	IN
benchmark	JJ
datasets	NNS
validate	VBP
the	DT
eï	NN
¬	CD
$	$
ectiveness	JJ
of	IN
the	DT
proposed	VBN
approach	NN
.	.


1	CD
Introduction	NN


Nearest	JJS
Rectangle	NN
-LRB-	-LRB-
NR	NN
-RRB-	-RRB-
learning	NN
-LSB-	-LRB-
9	CD
-RSB-	-RRB-
is	VBZ
a	DT
hybrid	NN
inductive	JJ
learning	NN
approach	NN
,	,
in	IN
which	WDT
training	NN
instances	NNS
are	VBP
generalized	VBN
into	IN
axis-parallel	JJ
hyperrectangles	NNS
,	,
and	CC
a	DT
query	NN
is	VBZ
classiï	NN
¬	NN
ed	VBD
according	VBG
to	TO
its	PRP$
nearest	JJS
rectangle	NN
.	.

If	IN
a	DT
query	NN
falls	VBZ
inside	IN
a	DT
rectangle	NN
,	,
its	PRP$
distance	NN
to	TO
that	DT
rectangle	NN
is	VBZ
zero	CD
;	:
if	IN
the	DT
query	NN
lies	VBZ
outside	IN
a	DT
rectangle	NN
,	,
the	DT
distance	NN
is	VBZ
the	DT
-LRB-	-LRB-
weighted	JJ
-RRB-	-RRB-
Euclidean	JJ
distance	NN
from	IN
the	DT
query	NN
to	TO
that	DT
rectangle	NN
.	.

If	IN
the	DT
query	NN
is	VBZ
equidistant	JJ
to	TO
several	JJ
rectangles	NNS
,	,
the	DT
smallest	JJS
of	IN
which	WDT
is	VBZ
chosen	VBN
.	.

The	DT
rectangles	NNS
we	PRP
mention	VBP
in	IN
this	DT
paper	NN
are	VBP
isothetic	JJ
bounding	VBG
boxes	NNS
of	IN
the	DT
instances	NNS
they	PRP
contain	VBP
,	,
unless	IN
otherwise	RB
speciï	NN
¬	CD
ed	VBD
.	.


NR	NN
learners	NNS
belongs	VBZ
to	TO
the	DT
class	NN
of	IN
hybrid	NN
lazy-eager	NN
learning	VBG
algorithms	NNS
.	.

Lazy	JJ
algorithms	NNS
such	JJ
as	IN
k-Nearest	NN
Neighbor	NN
-LRB-	-LRB-
kNN	NN
-RRB-	-RRB-
classiï	NN
¬	CD
ers	NNPS
are	VBP
instance-based	JJ
and	CC
non-parametric	JJ
,	,
where	WRB
the	DT
training	NN
data	NNS
are	VBP
simply	RB
stored	VBN
in	IN
memory	NN
and	CC
the	DT
inductive	JJ
process	NN
is	VBZ
deferred	VBN
until	IN
a	DT
query	NN
is	VBZ
given	VBN
.	.

In	IN
contrast	NN
,	,
eager	JJ
algo	NN
-	:
rithms	NNS
such	JJ
as	IN
decision	NN
trees	NNS
,	,
neural	JJ
networks	NNS
,	,
and	CC
naive	JJ
Bayes	NNP
classiï	NN
¬	CD
ers	NNPS
are	VBP
model-based	JJ
and	CC
parametric	JJ
,	,
where	WRB
the	DT
training	NN
data	NNS
are	VBP
greedily	RB
compiled	VBN
into	IN
a	DT
concise	JJ
hypothesis	NN
-LRB-	-LRB-
model	NN
-RRB-	-RRB-
and	CC
then	RB
completely	RB
discarded	VBN
.	.

Obviously	RB
,	,
lazy	JJ
al	NNP
-	:
gorithms	NNS
incur	VBP
lower	JJR
computational	JJ
costs	NNS
during	IN
training	NN
but	CC
much	RB
higher	JJR
costs	NNS
in	IN
answering	VBG
queries	NNS
also	RB
with	IN
greater	JJR
storage	NN
requirements	NNS
,	,
not	RB
scaling	VBG
well	RB
to	TO
large	JJ
datasets	NNS
.	.

They	PRP
do	VBP
not	RB
generate	VB
interpretable	JJ
models	NNS
as	IN
some	DT
eager	JJ
al	NNP
-	:
gorithms	NNS
,	,
in	IN
particular	JJ
,	,
decision	NN
trees	NNS
can	MD
be	VB
directly	RB
inspected	VBN
to	TO
understand	VB
the	DT
decision	NN
surfaces	NNS
embedded	VBN
in	IN
data	NNS
even	RB
for	IN
non-technical	JJ
end-users	NNS
.	.

This	DT
ease	NN
of	IN
comprehension	NN
is	VBZ
very	RB
appealing	JJ
in	IN
decision	NN
support	NN
related	JJ
data	NNS
mining	NN
activities	NNS
,	,
where	WRB
insight	NN
and	CC
explanations	NNS
are	VBP
of	IN
critical	JJ
importance	NN
-LSB-	-LRB-
2	CD
-RSB-	-RRB-
.	.


J.	NNP
FÂ	NNP
¨	NN
urnkranz	NN
,	,
T.	FW
Scheï	FW
¬	FW
$	$
er	JJ
,	,
and	CC
M.	NNP
Spiliopoulou	NNP
-LRB-	-LRB-
Eds	NNP
.	.
-RRB-	-RRB-

:	:
ECML	NN
2006	CD
,	,
LNAI	NNP
4212	CD
,	,
pp.	FW
638â	FW
$	$
``	``
645	CD
,	,
2006	CD
.	.

c	NN
Springer-Verlag	NNP
Berlin	NNP
Heidelberg	NNP
2006	CD



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
1	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



Right	RB
of	IN
Inference	NNP
:	:
Nearest	JJS
Rectangle	NNP
Learning	NNP
Revisited	NNP
639	CD


q	SYM


q	SYM


In	IN
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
,	,
the	DT
rectangles	NNS
make	VBP
â	RB
$	$
œwildâ	JJ
$	$
,	,
inappropriate	JJ
inferences	NNS
and	CC
the	DT
query	NN
q	NN
is	VBZ
classified	VBN
as	IN
c	NN
;	:


-LRB-	-LRB-
a	DT
-RRB-	-RRB-
q	RB
as	IN
c	NN


-LRB-	-LRB-
b	NN
-RRB-	-RRB-
q	RB
as	IN
!	.


In	IN
-LRB-	-LRB-
b	NN
-RRB-	-RRB-
,	,
the	DT
rectangles	NNS
generalize	VBP
the	DT
same	JJ
training	NN
instances	NNS
in	IN
a	DT
compact	JJ
and	CC
conservative	JJ
fashion	NN
,	,
having	VBG
the	DT
right	NN
of	IN
inference	NN
,	,
and	CC
q	NN
is	VBZ
more	RBR
appropriately	RB
classified	VBN
as	IN
!	.
.	.


Fig.	NN
1	CD
.	.

Right	RB
of	IN
inference	NN


However	RB
,	,
in	IN
terms	NNS
of	IN
accuracy	NN
,	,
lazy	JJ
methods	NNS
can	MD
be	VB
more	RBR
advantageous	JJ
.	.

They	PRP
do	VBP
not	RB
lose	VB
information	NN
since	IN
all	PDT
the	DT
training	NN
data	NNS
are	VBP
retained	VBN
.	.

They	PRP
have	VBP
ad	NN
-	:
ditional	JJ
information	NN
to	TO
utilize	VB
,	,
the	DT
query	NN
instances	NNS
,	,
so	RB
that	IN
local	JJ
and	CC
adaptive	JJ
decisions	NNS
can	MD
be	VB
made	VBN
for	IN
predictions	NNS
.	.

On	IN
the	DT
other	JJ
hand	NN
,	,
eager	JJ
methods	NNS
try	VBP
to	TO
make	VB
predictions	NNS
that	WDT
are	VBP
good	JJ
on	IN
average	NN
using	VBG
a	DT
single	JJ
global	JJ
model	NN
.	.


To	TO
compromise	VB
on	IN
some	DT
of	IN
the	DT
distinguishing	JJ
characteristics	NNS
of	IN
purely	RB
lazy	JJ
or	CC
eager	JJ
methods	NNS
,	,
hybrid	NN
lazy-eager	NN
algorithms	NNS
are	VBP
studied	VBN
.	.

As	IN
an	DT
example	NN
,	,
NR	IN
learning	VBG
partially	RB
processes	VBZ
the	DT
training	NN
instances	NNS
and	CC
generalizes	VBZ
them	PRP
into	IN
hy	NN
-	:
perrectangles	NNS
;	:
these	DT
intermediate	JJ
results	NNS
are	VBP
retained	VBN
and	CC
used	VBN
to	TO
answer	VB
queries	NNS
.	.

Nonetheless	RB
,	,
the	DT
NR	NN
method	NN
has	VBZ
not	RB
received	VBN
much	JJ
attention	NN
mainly	RB
because	IN
it	PRP
is	VBZ
considered	VBN
not	RB
accurate	JJ
enough	RB
.	.

The	DT
original	JJ
NR	NN
learning	VBG
algorithm	NN
as	RB
well	RB
as	IN
several	JJ
improved	JJ
versions	NNS
were	VBD
experimentally	RB
compared	VBN
with	IN
kNN	NN
-LSB-	-LRB-
10,11	CD
-RSB-	-RRB-
,	,
and	CC
it	PRP
was	VBD
concluded	VBN
that	IN
the	DT
NR	NN
approach	NN
performed	VBD
well	RB
in	IN
domains	NNS
with	IN
axis-parallel	JJ
decision	NN
boundaries	NNS
;	:
while	IN
in	IN
other	JJ
occasions	NNS
it	PRP
was	VBD
signiï	JJ
¬	NN
cantly	RB
inferior	JJ
to	TO
kNN	NN
in	IN
terms	NNS
of	IN
accuracy	NN
.	.

Comparing	VBG
to	TO
axis-parallel	JJ
decision	NN
trees	NNS
,	,
which	WDT
are	VBP
essentially	RB
rectangle-based	JJ
,	,
the	DT
rectangles	NNS
induced	VBN
by	IN
NR	NN
learners	NNS
also	RB
oï	VBP
¬	CD
$	$
er	CD
a	DT
level	NN
of	IN
intuitive	JJ
interpretability	NN
.	.

However	RB
,	,
as	IN
a	DT
hybrid	JJ
approach	NN
,	,
NR	NN
is	VBZ
slower	JJR
in	IN
answering	VBG
queries	NNS
;	:
then	RB
with	IN
similar	JJ
accuracy	NN
,	,
it	PRP
has	VBZ
no	DT
advantage	NN
over	IN
decision	NN
trees	NNS
and	CC
this	DT
line	NN
of	IN
research	NN
discontinued	VBN
soon	RB
after	IN
its	PRP$
introduction	NN
.	.


We	PRP
revisitNR	NN
learning	NN
,	,
and	CC
propose	VBP
that	IN
the	DT
major	JJ
reason	NN
accounting	NN
for	IN
its	PRP$
loss	NN
of	IN
accuracy	NN
in	IN
previous	JJ
endeavors	NNS
was	VBD
that	IN
,	,
the	DT
generalized	VBN
rectangles	NNS
were	VBD
not	RB
given	VBN
the	DT
right	NN
of	IN
inference	NN
that	WDT
guarantees	VBZ
the	DT
appropriateness	NN
of	IN
rectangles	NNS
in	IN
making	VBG
inferences	NNS
.	.

In	IN
general	JJ
,	,
rectangles	NNS
having	VBG
the	DT
right	NN
of	IN
inference	NN
should	MD
be	VB
compact	JJ
,	,
conservative	JJ
,	,
and	CC
good	JJ
for	IN
making	VBG
local	JJ
decisions	NNS
,	,
as	IN
illustrated	VBN
in	IN
Fig.	NN
1	CD
.	.

By	IN
imposing	VBG
the	DT
right	NN
of	IN
inference	NN
on	IN
rectangles	NNS
,	,
NR	NN
classiï	NN
¬	CD
ers	NNPS
can	MD
potentially	RB
be	VB
intuitively	RB
explanatory	JJ
,	,
fast	RB
,	,
scalable	JJ
,	,
yet	RB
highly	RB
accurate	JJ
,	,
having	VBG
many	JJ
combined	JJ
appealing	JJ
properties	NNS
from	IN
decision	NN
trees	NNS
and	CC
kNN	NN
classiï	NN
¬	CD
ers	NNPS
.	.


1.1	CD
Related	JJ
Work	NN


Decision	NN
trees	NNS
-LSB-	-LRB-
6	CD
-RSB-	-RRB-
are	VBP
typical	JJ
eager	JJ
learners	NNS
while	IN
kNN	NN
classiï	NN
¬	CD
ers	NNPS
-LSB-	-LRB-
4	CD
-RSB-	-RRB-
exemplify	VB
the	DT
simplest	JJS
form	NN
of	IN
lazy	JJ
learners	NNS
.	.

-LSB-	-LRB-
1	LS
-RSB-	-RRB-
identiï	NN
¬	CD
ed	VBD
the	DT
distinguishing	JJ
characteristics	NNS
of	IN
eager	JJ
and	CC
lazy	JJ
learners	NNS
.	.

Both	DT
types	NNS
of	IN
learners	NNS
have	VBP
their	PRP$
own	JJ
desirable	JJ
prop	VBP
-	:
erties	NNS
.	.

To	TO
obtain	VB
good	JJ
trade-oï	NN
¬	CD
$	$
s	NNS
,	,
varied	VBD
hybrid	NN
approaches	NNS
were	VBD
proposed	VBN
,	,
e.g.	FW
,	,
-LSB-	-LRB-
7	CD
-RSB-	-RRB-
introduced	VBD
a	DT
method	NN
combining	VBG
instance-based	JJ
and	CC
model-based	JJ
learning	NN
.	.



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
2	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



640	CD
B.J.	NNP
Gao	NNP
and	CC
M.	NNP
Ester	NNP


As	IN
a	DT
hybrid	JJ
approach	NN
,	,
nearest	JJS
rectangle	NN
learning	NN
was	VBD
ï	JJ
¬	NN
rst	NN
introduced	VBN
in	IN
-LSB-	-LRB-
9	CD
-RSB-	-RRB-
under	IN
the	DT
name	NN
of	IN
Nested	NNP
Generalized	NNP
Exemplar	NNP
-LRB-	-LRB-
NGE	NNP
-RRB-	-RRB-
theory.In	NN
NGE	NN
,	,
an	DT
exemplar	NN
can	MD
be	VB
a	DT
generalized	VBN
axis-parallel	NN
hyperrectangle	NN
or	CC
a	DT
single	JJ
training	NN
instance	NN
,	,
which	WDT
is	VBZ
a	DT
degenerate	NN
-LRB-	-LRB-
trivial	JJ
-RRB-	-RRB-
rectangle	NN
.	.

Arbitrary	JJ
overlapping	VBG
and	CC
nesting	JJ
of	IN
rectangles	NNS
of	IN
diï	NN
¬	CD
$	$
erent	JJ
classes	NNS
are	VBP
allowed	VBN
.	.

-LSB-	-LRB-
10,11	CD
-RSB-	-RRB-
challenged	VBD
the	DT
ac	NN
-	:
curacy	NN
performance	NN
of	IN
NGE	NN
and	CC
made	VBD
several	JJ
improvement	NN
attempts	NNS
such	JJ
as	IN
disallowing	VBG
nesting	JJ
and/or	CC
overlapping	VBG
,	,
modifying	VBG
the	DT
rectangle	NN
construction	NN
heuristic	NN
,	,
and	CC
weighting	NN
features	NNS
by	IN
mutual	JJ
information	NN
.	.

It	PRP
was	VBD
concluded	VBN
that	IN
the	DT
major	JJ
reason	NN
leading	VBG
to	TO
the	DT
loss	NN
of	IN
accuracy	NN
of	IN
NGE	NN
was	VBD
the	DT
overlapping	VBG
of	IN
rectangles	NNS
of	IN
diï	NN
¬	CD
$	$
erent	JJ
classes	NNS
,	,
yet	RB
the	DT
best	JJS
improved	VBN
version	NN
was	VBD
still	RB
signiï	JJ
¬	NN
cantly	RB
inferior	JJ
to	TO
kNN	NN
in	IN
most	JJS
of	IN
the	DT
tested	VBN
datasets	NNS
.	.

We	PRP
notice	VBP
that	IN
,	,
all	PDT
the	DT
above	JJ
at	IN
-	:
tempts	VBZ
did	VBD
not	RB
pay	VB
much	JJ
attention	NN
to	TO
the	DT
quality	NN
of	IN
the	DT
generated	VBN
rectangles	NNS
.	.

They	PRP
allowed	VBD
rectangles	NNS
to	TO
make	VB
wild	JJ
and	CC
inappropriate	JJ
inferences	NNS
,	,
which	WDT
would	MD
signiï	VB
¬	CD
cantly	RB
deteriorate	VBP
the	DT
accuracy	NN
performance	NN
as	IN
illustrated	VBN
in	IN
Fig.	NN
1	CD
.	.


-LSB-	-LRB-
5	CD
-RSB-	-RRB-
studied	VBN
cluster	NN
description	NN
formats	NNS
,	,
problems	NNS
and	CC
algorithms	NNS
,	,
which	WDT
also	RB
involved	VBD
discriminative	JJ
summarization	NN
of	IN
labeled	VBN
data	NNS
using	VBG
hyperrectangles	NNS
.	.

But	CC
they	PRP
considered	VBD
only	RB
a	DT
two-class	JJ
problem	NN
concerning	VBG
objects	NNS
in	IN
or	CC
not	RB
in	IN
the	DT
cluster	NN
.	.

Moreover	RB
,	,
their	PRP$
focus	NN
was	VBD
on	IN
description	NN
-LRB-	-LRB-
generalization	NN
-RRB-	-RRB-
instead	RB
of	IN
classiï	NN
¬	CD
cation	NN
-LRB-	-LRB-
inference	NN
-RRB-	-RRB-
;	:
the	DT
appropriateness	NN
of	IN
inference	NN
of	IN
rectangles	NNS
was	VBD
not	RB
an	DT
issue	NN
,	,
but	CC
the	DT
conciseness	NN
of	IN
descriptions	NNS
,	,
i.e.	FW
,	,
the	DT
number	NN
of	IN
rectangles	NNS
.	.


In	IN
the	DT
remaining	VBG
of	IN
the	DT
paper	NN
,	,
Section	NN
2	CD
discusses	VBZ
the	DT
concept	NN
of	IN
right	NN
of	IN
inference	NN
and	CC
its	PRP$
enforcement	NN
.	.

Section	NN
3	CD
proposes	VBZ
LearnCovers	NNP
,	,
an	DT
NR	NN
learning	VBG
heuristic	NN
.	.

Section	NN
4	CD
presents	VBZ
empirical	JJ
results	NNS
and	CC
Section	NN
5	CD
concludes	VBZ
the	DT
paper	NN
.	.


2	CD
Right	NNP
of	IN
Inference	NNP
and	CC
Its	PRP$
Enforcement	NN


2.1	CD
Right	NNP
of	IN
Inference	NNP


Rectangle-based	JJ
classiï	NN
¬	NN
ers	NNPS
can	MD
provide	VB
certain	JJ
degree	NN
of	IN
insight	NN
and	CC
understand	VB
-	:
ing	NN
into	IN
data	NNS
and	CC
the	DT
instance	NN
space	NN
.	.

In	IN
fact	NN
,	,
consider	VB
a	DT
closed	JJ
rectangular	JJ
in	IN
-	:
stance	NN
space	NN
,	,
the	DT
leaf	NN
nodes	NNS
of	IN
an	DT
axis-parallel	JJ
decision	NN
tree	NN
correspond	VBP
to	TO
a	DT
set	NN
of	IN
isothetic	JJ
rectangles	NNS
-LRB-	-LRB-
not	RB
bounding	VBG
boxes	NNS
-RRB-	-RRB-
forming	VBG
a	DT
partition	NN
of	IN
the	DT
in	NN
-	:
stance	NN
space	NN
.	.

The	DT
induction	NN
of	IN
decision	NN
trees	NNS
generalizes	VBZ
the	DT
training	NN
data	NNS
and	CC
makes	VBZ
inferences	NNS
to	TO
the	DT
entire	JJ
instance	NN
space	NN
simultaneously	RB
with	IN
the	DT
disjoint	NN
-	:
ness	NN
constraint	NN
,	,
striving	VBG
to	TO
achieve	VB
good-on-average	NN
predictions	NNS
.	.

Intuitively	RB
,	,
if	IN
we	PRP
separate	JJ
generalization	NN
and	CC
inference	NN
into	IN
two	CD
serial	JJ
phases	NNS
and	CC
allow	VB
same-class	JJ
rectangles	NNS
to	TO
overlap	VB
,	,
we	PRP
should	MD
be	VB
able	JJ
to	TO
build	VB
classiï	NN
¬	NN
ers	NNPS
that	WDT
are	VBP
more	RBR
ï	JJ
¬	NN
‚	NN
exible	NN
,	,
adaptive	JJ
and	CC
accurate	JJ
,	,
with	IN
the	DT
capacity	NN
to	TO
make	VB
local	JJ
decisions	NNS
.	.


Potentially	RB
,	,
NR	IN
learning	NN
can	MD
induce	VB
such	JJ
explanatory	JJ
,	,
adaptive	JJ
and	CC
accu	NN
-	:
rate	NN
classiï	NN
¬	CD
ers	NNPS
.	.

However	RB
,	,
if	IN
in	IN
the	DT
generalization	NN
phase	NN
,	,
the	DT
rectangles	NNS
are	VBP
not	RB
constructed	VBN
in	IN
a	DT
conservative	JJ
and	CC
compact	JJ
fashion	NN
,	,
they	PRP
would	MD
make	VB
wild	JJ
and	CC
improper	JJ
inferences	NNS
,	,
similar	JJ
to	TO
the	DT
case	NN
of	IN
decision	NN
trees	NNS
,	,
asdemonstratedin	NN


Fig.	NN
1	CD
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
.	.

It	PRP
can	MD
be	VB
inspected	VBN
that	DT
decision	NN
trees	NNS
would	MD
make	VB
the	DT
same	JJ
decision	NN
for	IN
the	DT
query	NN
in	IN
the	DT
ï	NN
¬	NN
gure	NN
.	.

On	IN
the	DT
contrary	NN
,	,
Fig.	NN
1	CD
-LRB-	-LRB-
b	NN
-RRB-	-RRB-
illustrates	VBZ
some	DT
compact	JJ
rectangles	NNS
for	IN
the	DT
same	JJ
training	NN
data	NNS
that	WDT
are	VBP
good	JJ
for	IN
making	VBG
local	JJ
decisions	NNS
,	,
having	VBG
the	DT
so-called	JJ
right	NN
of	IN
inference	NN
.	.



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
3	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



Right	RB
of	IN
Inference	NNP
:	:
Nearest	JJS
Rectangle	NNP
Learning	NNP
Revisited	NNP
641	CD


râ	NN
$	$
™	CD


râ	NN
$	$
™	CD


p	NN


qâ	NN
$	$
™	CD


r	NN


q	SYM


r	NN


q	SYM


q	SYM


r	NN


p	NN


k	NN


-LRB-	-LRB-
a	DT
-RRB-	-RRB-
false	JJ
invalidation	NN


-LRB-	-LRB-
b	NN
-RRB-	-RRB-
true	JJ
invalidation	NN


Fig.	NN
2	CD
.	.

For	IN
Deï	NN
¬	CD
nition	NN
1	CD


Fig.	NN
3	CD
.	.

For	IN
Theorem	NNP
1	CD


The	DT
right	NN
of	IN
inference	NN
of	IN
a	DT
rectangle	NN
can	MD
be	VB
conceptually	RB
deï	NN
¬	CD
ned	VBD
as	IN
the	DT
privi	NN
-	:
lege	NN
that	IN
the	DT
rectangle	NN
has	VBZ
to	TO
make	VB
sound	NN
and	CC
local	JJ
inferences	NNS
.	.

As	IN
we	PRP
have	VBP
seen	VBN
,	,
rectangles	NNS
having	VBG
the	DT
right	NN
of	IN
inference	NN
should	MD
appear	VB
compact	JJ
and	CC
saturated	JJ
.	.

Then	RB
,	,
how	WRB
to	TO
deï	VB
¬	CD
ne	NN
right	NN
of	IN
inference	NN
in	IN
a	DT
quantitative	JJ
manner	NN
?	.


Deï	NN
¬	CD
nition	NN
1	CD
.	.

-LRB-	-LRB-
right	NN
of	IN
inference	NN
-RRB-	-RRB-
Arectangle	NN
r	NN
has	VBZ
the	DT
right	NN
of	IN
inference	NN
if	IN
and	CC
only	RB
if	IN
for	IN
any	DT
query	NN
q	VB
outside	IN
of	IN
r	NN
,	,
dist	NN
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
âˆ	NN
'd	MD
ist	VB
-LRB-	-LRB-
q	RB
,	,
r	NN
-RRB-	-RRB-
â	NN
‰	CD
$	$
Î	JJ
´	NN
,	,
where	WRB
dist	NN
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
is	VBZ
the	DT
Euclidean	JJ
distance	NN
from	IN
q	NN
to	TO
its	PRP$
kth	NN
nearest	JJS
instance	NN
in	IN
r	NN
,	,
dist	NN
-LRB-	-LRB-
q	NN
,	,
r	NN
-RRB-	-RRB-
is	VBZ
the	DT
Euclidean	JJ
distance	NN
from	IN
q	NN
to	TO
r	NN
,	,
and	CC
Î	NN
´	NN
is	VBZ
the	DT
distance	NN
threshold	NN
.	.


The	DT
distance	NN
from	IN
q	NN
to	TO
r	NN
is	VBZ
equivalent	JJ
to	TO
the	DT
line	NN
dropped	VBD
perpendicularly	RB
from	IN


q	VB
to	TO
the	DT
nearest	JJS
face	NN
,	,
edge	NN
,	,
or	CC
vertex	NN
of	IN
r	NN
,	,
which	WDT
is	VBZ
formally	RB
deï	JJ
¬	NN
ned	VBD
as	IN
follows	VBZ
,	,


without	IN
considering	VBG
rectangle	NN
weighting	NN
and	CC
feature	NN
weighting	NN
.	.

Let	VB
qf	NN


i	LS


be	VB
the	DT


value	NN
ofq	NN
on	IN
the	DT
ith	NN
feature	NN
,	,
where	WRB
1	CD
â	NN
‰	CD
$	$
i	FW
â	FW
‰	FW
$	$
m	NN
;	:
let	VB
rlower	NN
,	,
f	SYM


i	LS


and	CC
rupper	NN
,	,
f	SYM


i	LS


be	VB
the	DT


lower	JJR
and	CC
upper	JJ
end	NN
values	NNS
of	IN
r	NN
on	IN
the	DT
ith	NN
feature	NN
,	,
then	RB
:	:


âŽ	NN
§	SYM



m	NN
âŽ	NN
¨	CD
qf	NN
when	WRB
qf	NN


i	LS


>	JJR
r	NN


upper	JJ
,	,
fi	IN


dist	NN
-LRB-	-LRB-
q	NN
,	,
r	NN
-RRB-	-RRB-
=	JJ



i	LS


âˆ	NN
'	''
rupper	NN
,	,
f	SYM


i	LS


dif2i	NN
where	WRB
difi	NN
=	JJ


âŽ	NN
©	SYM


rlower	NN
,	,
f	SYM


i	LS


âˆ	NN
'	POS
qf	NN


i	LS


when	WRB
qf	NN


i	LS


<	JJR
r	NN


lower	JJR
,	,
fi	IN


i	LS
=	SYM
1	CD
0otherwise	NN


What	WP
is	VBZ
the	DT
rationale	NN
behind	IN
the	DT
right	NN
of	IN
inference	NN
thus-deï	NN
¬	CD
ned	VBN
?	.

Note	VB
that	IN
,	,
we	PRP
always	RB
havedist	NN
-LRB-	-LRB-
q	NN
,	,
r	NN
-RRB-	-RRB-
â	NN
‰	CD
$	$
dist	CD
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
.	.

If	IN
dist	NN
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
âˆ	NN
'd	MD
ist	VB
-LRB-	-LRB-
q	RB
,	,
r	NN
-RRB-	-RRB-
istoolarge	NN
,	,
the	DT
inference	NN
on	IN
the	DT
class	NN
of	IN
q	NN
from	IN
r	NN
might	MD
be	VB
inappropriate	JJ
,	,
since	IN
dist	NN
-LRB-	-LRB-
q	NN
,	,
r	NN
-RRB-	-RRB-
would	MD
alter	VB
-LRB-	-LRB-
bring	VB
closer	JJR
-RRB-	-RRB-
the	DT
locality	NN
of	IN
the	DT
instances	NNS
in	IN
r	NN
with	IN
respect	NN
to	TO
q	VB
in	IN
an	DT
intolerable	JJ
manner	NN
;	:
e.g.	FW
,	,
in	IN
Fig.	NN
1	CD
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
,	,
q	NN
is	VBZ
very	RB
close	JJ
to	TO
the	DT
left	JJ
rectangle	NN
,	,
but	CC
far	RB
away	RB
from	IN
the	DT
instances	NNS
in	IN
it	PRP
.	.

In	IN
contrast	NN
,	,
if	IN
dist	NN
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
âˆ	NN
'd	MD
ist	VB
-LRB-	-LRB-
q	RB
,	,
r	NN
-RRB-	-RRB-
is	VBZ
reasonably	RB
small	JJ
,	,
NR	NN
classiï	NN
¬	CD
ers	NNPS
would	MD
behave	VB
similarly	RB
to	TO
kNN	NN
,	,
as	IN
shown	VBN
in	IN
Fig.	NN
1	CD
-LRB-	-LRB-
b	NN
-RRB-	-RRB-
.	.


In	IN
Deï	NN
¬	CD
nition	NN
1	CD
,	,
we	PRP
only	RB
consider	VBP
queries	NNS
lying	VBG
outside	IN
of	IN
the	DT
rectangle	NN
r.This	NN
is	VBZ
because	IN
some	DT
inside	IN
query	NN
may	MD
falsely	RB
invalidate	VB
a	DT
â	JJ
$	$
œgoodâ	JJ
$	$
r	NN
.	.

In	IN
Fig.	NN
2	CD
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
,	,
even	RB
if	IN
dist	NN
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
âˆ	NN
'	''
dist	NN
-LRB-	-LRB-
q	NN
,	,
r	NN
-RRB-	-RRB-
is	VBZ
rather	RB
large	JJ
,	,
r	NN
is	VBZ
good	JJ
because	IN
q	NN
would	MD
not	RB
be	VB
closer	JJR
to	TO
other	JJ
instances/rectangles	NNS
of	IN
diï	NN
¬	CD
$	$
erent	JJ
classes	NNS
,	,
say	VBP
r.	NN
Recall	VB
that	IN
overlapping	VBG
of	IN
rectangles	NNS
is	VBZ
allowed	VBN
only	RB
if	IN
they	PRP
have	VBP
the	DT
same	JJ
class	NN
label	NN
.	.

On	IN
the	DT
other	JJ
hand	NN
,	,
for	IN
a	DT
â	JJ
$	$
œbadâ	JJ
$	$
r	NN
as	IN
shown	VBN
in	IN
Fig.	NN
2	CD
-LRB-	-LRB-
b	NN
-RRB-	-RRB-
,	,
not	RB
considering	VBG
q	NN
or	CC
other	JJ
queries	NNS
in	IN
r	NN
would	MD
not	RB
falsely	RB
validate	VB
r	NN
since	IN
if	IN
q	NN
should	MD
invalidate	VB
r	NN
-LRB-	-LRB-
closer	JJR
to	TO
r	NN
-RRB-	-RRB-
,	,
there	EX
would	MD
be	VB
another	DT
q	NN
outside	IN
of	IN
r	NN
that	WDT
also	RB
invalidates	VBZ
r	NN
.	.

We	PRP
can	MD
easily	RB
ï	VB
¬	CD
nd	NN
such	JJ
q	NN
,	,
say	VBP
,	,
somewhere	RB
close	RB
to	TO
r	NN
and	CC
on	IN
the	DT
line	NN
joining	VBG
q	NN
and	CC
r.	NN


In	IN
Deï	NN
¬	CD
nition	NN
1	CD
,	,
it	PRP
is	VBZ
also	RB
reasonable	JJ
to	TO
use	VB
the	DT
average	NN
of	IN
distances	NNS
from	IN
q	NN
to	TO
its	PRP$
k	NN
nearest	JJS
instances	NNS
in	IN
r	NN
for	IN
dist	NN
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
.	.

k	NN
is	VBZ
limited	VBN
by	IN
the	DT
number	NN
of	IN



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
4	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



642	CD
B.J.	NNP
Gao	NNP
and	CC
M.	NNP
Ester	NNP


instances	NNS
in	IN
r	NN
,	,
and	CC
the	DT
choice	NN
of	IN
k	NN
can	MD
be	VB
a	DT
legitimate	JJ
research	NN
issue	NN
just	RB
as	RB
in	IN
the	DT
case	NN
of	IN
kNN	NN
classiï	NN
¬	CD
cation	NN
.	.

The	DT
distance	NN
threshold	NN
Î	NN
´	NN
has	VBZ
a	DT
direct	JJ
impact	NN
on	IN
how	WRB
closely	RB
NR	NN
classiï	NN
¬	CD
ers	NNPS
would	MD
behave	VB
to	TO
kNN.If	NN
Î	NN
´	NN
is	VBZ
too	RB
large	JJ
,	,
the	DT
rectangles	NNS
tend	VBP
to	TO
be	VB
very	RB
large	JJ
as	RB
well	RB
making	VBG
unconstrained	JJ
inferences	NNS
.	.

If	IN
Î	NN
´	NN
is	VBZ
too	RB
small	JJ
,	,
NR	IN
learning	VBG
would	MD
induce	VB
too	RB
many	JJ
rectangles	NNS
and	CC
become	VB
â	JJ
$	$
œlazyâ	JJ
$	$
,	,
losing	VBG
the	DT
desirable	JJ
properties	NNS
as	IN
a	DT
hybrid	NN
learner	NN
.	.

In	IN
the	DT
extreme	JJ
case	NN
of	IN
Î	NN
´	NN
=	JJ
0	CD
,	,
NR	IN
learning	VBG
would	MD
lose	VB
the	DT
generalization	NN
capacity	NN
completely	RB
and	CC
essentially	RB
become	VBN
1	LS
-	:
NN	NNP
.	.


2.2	CD
Enforcing	VBG
the	DT
Right	NNP
of	IN
Inference	NNP


It	PRP
is	VBZ
not	RB
straightforward	JJ
to	TO
enforce	VB
the	DT
right	NN
of	IN
inference	NN
deï	NN
¬	CD
ned	VBD
in	IN
Deï	NN
¬	CD
nition	NN
1	CD
since	IN
there	EX
are	VBP
potentially	RB
inï	JJ
¬	NN
nite	JJ
number	NN
of	IN
queries	NNS
to	TO
examine	VB
.	.

In	IN
the	DT
following	VBG
,	,
we	PRP
discuss	VBP
some	DT
inspiring	JJ
observations	NNS
and	CC
practical	JJ
implications	NNS
.	.


Theorem	NNP
1	CD
.	.

If	IN
for	IN
any	DT
query	NN
q	NN
that	WDT
is	VBZ
on	IN
the	DT
surface	NN
of	IN
a	DT
rectangler	NN
,	,
dist	NN
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
â	NN
‰	CD
$	$
Î	JJ
´	NN
,	,
where	WRB
qk	NN
is	VBZ
the	DT
kth	NN
nearest	JJS
instance	NN
of	IN
q	NN
in	IN
r	NN
,	,
then	RB
r	NN
has	VBZ
the	DT
right	NN
of	IN
inference	NN
deï	NN
¬	CD
ned	VBD
in	IN
Deï	NN
¬	CD
nition	NN
1	CD
with	IN
respect	NN
to	TO
Î	NN
´	NN
.	.


Proof	NN
.	.

Let	VB
p	NN
be	VB
any	DT
query	NN
outside	IN
of	IN
r.Let	NNP
pk	NN
be	VB
the	DT
kth	NN
nearest	JJS
instance	NN
of	IN
p	NN
in	IN
r	NN
and	CC
q	VB
the	DT
projected	VBN
p	NN
on	IN
the	DT
nearest	JJS
face	NN
of	IN
r	NN
,	,
asdepictedinFig	NN
.3	NN
.	.


According	VBG
to	TO
the	DT
deï	NN
¬	NN
nition	NN
of	IN
point-to-rectangle	JJ
distance	NN
,	,
dist	NN
-LRB-	-LRB-
p	NN
,	,
q	NN
-RRB-	-RRB-
=	JJ
dist	NN
-LRB-	-LRB-
p	NN
,	,
r	NN
-RRB-	-RRB-
.	.

We	PRP
usearcp	VBP
to	TO
denote	VB
the	DT
intersection	NN
of	IN
r	NN
and	CC
the	DT
sphere	NN
with	IN
radius	NN
dist	NN
-LRB-	-LRB-
p	NN
,	,
pk	NN
-RRB-	-RRB-
centered	VBN
at	IN
p	NN
,	,
and	CC
arcq	NN
to	TO
denote	VB
the	DT
intersection	NN
of	IN
r	NN
and	CC
the	DT
sphere	NN
with	IN
radius	NN
dist	NN
-LRB-	-LRB-
p	NN
,	,
pk	NN
-RRB-	-RRB-
âˆ	NN
'	''
dist	NN
-LRB-	-LRB-
p	NN
,	,
q	NN
-RRB-	-RRB-
centered	VBN
at	IN
q.	NNP
Clearly	RB
,	,
arcq	IN
âŠ	NN
†	CD
arcp.k	NN


Since	IN
p	NN
is	VBZ
the	DT
kth	NN
nearest	JJS
instance	NN
of	IN
p	NN
in	IN
r	NN
,	,
the	DT
number	NN
of	IN
instances	NNS
in	IN
arcp	NN
is	VBZ
less	RBR
or	CC
equal	JJ
to	TO
k	NN
if	IN
not	RB
considering	VBG
ties	NNS
.	.

Since	IN
arcp	NN
and	CC
arcq	NN
intersect	VBP
on	IN
only	RB
one	CD
point	NN
,	,
the	DT
number	NN
of	IN
instances	NNS
in	IN
arcq	NN
is	VBZ
less	RBR
or	CC
equal	JJ
to	TO
k	NN
evenk	NN


considering	VBG
ties	NNS
.	.

That	DT
is	VBZ
to	TO
say	VB
,	,
q	VB
,	,
the	DT
kth	NN
nearest	JJS
instance	NN
of	IN
q	NN
in	IN
r	NN
,	,
lies	VBZ
outside	JJ
or	CC
on	IN
the	DT
surface	NN
of	IN
arcq.Inotherwords	NNS
,	,
k	NN
dist	NN
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
â	NN
‰	CD
¥	NN
dist	NN
-LRB-	-LRB-
p	NN
,	,
pk	NN
-RRB-	-RRB-
âˆ	NN
'	''
dist	NN
-LRB-	-LRB-
p	NN
,	,
q	NN
-RRB-	-RRB-
=	JJ
dist	NN
-LRB-	-LRB-
p	NN
,	,
p	NN
-RRB-	-RRB-
âˆ	NN
'	''
dist	NN
-LRB-	-LRB-
p	NN
,	,
r	NN
-RRB-	-RRB-
.	.

Therefore	RB
,	,
Î	NN
´	CD
â	NN
‰	CD
¥	NN
dist	NN
-LRB-	-LRB-
q	NN
,	,
qk	NN
-RRB-	-RRB-
â	NN
‡	NN
'	''
Î	NN
´	CD
â	NN
‰	CD
¥	NN
dist	NN
-LRB-	-LRB-
p	NN
,	,
pk	NN
-RRB-	-RRB-
âˆ	NN
'	''
dist	NN
-LRB-	-LRB-
p	NN
,	,
r	NN
-RRB-	-RRB-
,	,
and	CC
the	DT
conclusion	NN
of	IN
Theorem	NNP
1	CD
follows	VBZ
.	.


The	DT
implication	NN
of	IN
Theorem	NNP
1	CD
is	VBZ
that	IN
,	,
we	PRP
only	RB
need	VBP
to	TO
consider	VB
queries	NNS
on	IN
the	DT
surface	NN
of	IN
r	NN
to	TO
test	VB
its	PRP$
right	NN
of	IN
inference	NN
.	.

In	IN
the	DT
prototype	NN
NR	NN
learner	NN
LearnCov	NNP
-	:
ers	NNPS
,	,
to	TO
be	VB
proposed	VBN
shortly	RB
,	,
a	DT
simple	JJ
recursive	JJ
testing	NN
and	CC
bisecting	NN
enforcement	NN
heuristic	NN
is	VBZ
embedded	JJ
.	.

For	IN
testing	NN
,	,
the	DT
query	NN
pool	NN
consists	VBZ
of	IN
a	DT
constant	JJ
num	NN
-	:
ber	NN
of	IN
queries	NNS
generated	VBN
according	VBG
to	TO
a	DT
ranking	JJ
scheme	NN
that	WDT
gives	VBZ
high	JJ
ranks	NNS
to	TO
queries	NNS
with	IN
high	JJ
probability	NN
of	IN
invalidating	VBG
r.	NNP
Generally	RB
,	,
highly	RB
ranked	VBD
queries	NNS
include	VBP
vertices	NNS
that	WDT
are	VBP
far	RB
away	RB
from	IN
the	DT
mean	NN
of	IN
the	DT
instances	NNS
in	IN
r.Certain	NN
positions	NNS
-LRB-	-LRB-
say	VB
,	,
centers	NNS
-RRB-	-RRB-
on	IN
long	JJ
edges	NNS
or	CC
large	JJ
faces	NNS
have	VBP
the	DT
next	JJ
priority	NN
to	TO
be	VB
inserted	VBN
in	IN
the	DT
query	NN
pool	NN
,	,
and	CC
then	RB
uncertain	JJ
-LRB-	-LRB-
random	JJ
-RRB-	-RRB-
positions	NNS
on	IN
the	DT
surface	NN
of	IN
r.	NN
r	NN
is	VBZ
validated	VBN
-LRB-	-LRB-
passes	VBZ
the	DT
test	NN
-RRB-	-RRB-
if	IN
it	PRP
is	VBZ
not	RB
invalidated	VBN
by	IN
any	DT
query	NN
in	IN
the	DT
query	NN
pool	NN
.	.

If	IN
r	NN
is	VBZ
invalidated	VBN
,	,
the	DT
k-means	JJ
clustering	NN
algorithm	NN
with	IN
k	NN
=	JJ
2is	JJ
applied	VBN
to	TO
bisect	VB
the	DT
instances	NNS
in	IN
r	NN
,	,
and	CC
the	DT
newly	RB
generated	VBN
rectangles	NNS
-LRB-	-LRB-
bound	VBN
-	:
ing	NN
boxes	NNS
of	IN
the	DT
two	CD
sections	NNS
-RRB-	-RRB-
are	VBP
tested	VBN
separately	RB
.	.

This	DT
recursive	JJ
testing	NN
and	CC
bisecting	VBG
process	NN
terminates	VBZ
until	IN
all	PDT
the	DT
rectangles	NNS
pass	VBP
the	DT
test	NN
.	.



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
5	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



Right	RB
of	IN
Inference	NNP
:	:
Nearest	JJS
Rectangle	NNP
Learning	NNP
Revisited	NNP
643	CD


3	LS
LearnCovers	NNPS
:	:
Learning	VBG
the	DT
â	NN
$	$
œRightâ	JJ
$	$
Rectangles	NNPS


LearnCovers	NNS
heuristically	RB
constructs	NNS
a	DT
set	NN
of	IN
rectangles	NNS
with	IN
minimized	VBN
cardinal	NN
-	:
ity	NN
and	CC
enforced	VBD
right	NN
of	IN
inference	NN
.	.

The	DT
rectangles	NNS
generalize	VBP
the	DT
given	VBN
training	NN
instances	NNS
with	IN
100	CD
%	NN
accuracy	NN
,	,
and	CC
same-class	JJ
rectangles	NNS
are	VBP
allowed	VBN
to	TO
overlap	VB
.	.


Algorithm	NN
1	CD
.	.

LearnCovers	NNS


1	LS
.	.

R	NN
=	JJ
âˆ	NN
...	:
;	:
/	:
/	:
R	NN
:	:
the	DT
set	NN
of	IN
generated	VBN
rectangles	NNS


2	LS
.	.

sort	NN
T	NN
;	:
/	:
/	:
T	NN
:	:
the	DT
given	VBN
training	NN
set	NN


3	LS
.	.

for	IN
each	DT
t	NN
âˆˆ	NN
T	NN
-LCB-	-LRB-
/	:
/	:
process	NN
each	DT
training	NN
instance	NN
t	NN
in	IN
the	DT
sorted	VBN
order	NN


4	LS
.	.

for	IN
each	DT
r	NN
âˆˆ	NN
R	NN
-LCB-	-LRB-


5	CD
.	.

calculate	VB
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
;	:
/	:
/	:
r	NN
with	IN
smaller	JJR
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
isfavoredincovering	NN
t	NN
6	CD
.	.

if	IN
-LRB-	-LRB-
r.class	NN
!	.

=	JJ
t.class	NN
&	CC
&	CC
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
=	JJ
=	JJ
0	CD
-RRB-	-RRB-


7	CD
.	.

validateToclose	NN
-LRB-	-LRB-
r	NN
-RRB-	-RRB-
;	:
/	:
/	:
r	NN
can	MD
be	VB
closed	VBN
only	RB
after	IN
validation	NN


8	CD
.	.

if	IN
-LRB-	-LRB-
r.class	NN
=	JJ
=	JJ
t.class	NN
&	CC
&	CC
r	NN
is	VBZ
not	RB
closed	VBN
&	CC
&	CC
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
=	JJ
=	JJ
0	CD
-RRB-	-RRB-


9	CD
.	.

extend	VB
r	NN
to	TO
cover	VB
t	NN
and	CC
continue	VB
to	TO
process	VB
the	DT
next	JJ
t	NN
;	:
-RCB-	-RRB-
/	:
/	:
back	RB
to	TO
line	NN
3	CD
10	CD
.	.

for	IN
each	DT
r	NN
âˆˆ	NN
R	NN
-LCB-	-LRB-
/	:
/	:
t	NN
was	VBD
not	RB
covered	VBN
;	:
fetchr	NN
in	IN
ascending	VBG
order	NN
of	IN
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
11	CD
.	.

if	IN
-LRB-	-LRB-
r.class	NN
=	JJ
=	JJ
t.class	NN
&	CC
&	CC
r	NN
is	VBZ
not	RB
closed	VBN
&	CC
&	CC
violationCheck	NN
-LRB-	-LRB-
r	NN
,	,
R	NN
-RRB-	-RRB-
=	JJ
=	JJ
no	DT
-RRB-	-RRB-
12	CD
.	.

expand	VB
r	NN
to	TO
cover	VB
t	NN
and	CC
continue	VB
to	TO
process	VB
the	DT
next	JJ
t	NN
;	:
-RCB-	-RRB-
/	:
/	:
back	RB
to	TO
line	NN
3	CD
13	CD
.	.

insert	NN
-LRB-	-LRB-
R	NN
,	,
rnew	NN
-RRB-	-RRB-
-RCB-	-RRB-
;	:
/	:
/	:
t	NN
can	MD
not	RB
be	VB
covered	VBN
;	:
insert	VB
the	DT
trivial	JJ
rectangle	NN
rnew	NN
to	TO
R	NN
14	CD
.	.

enforce	VB
-LRB-	-LRB-
R	NN
-RRB-	-RRB-
;	:


The	DT
pseudocode	NN
is	VBZ
presented	VBN
in	IN
Algorithm	NN
1	CD
.	.

R	NN
,	,
the	DT
rectangle	NN
set	NN
,	,
is	VBZ
ini	SYM
-	:
tialized	VBN
to	TO
be	VB
empty	JJ
-LRB-	-LRB-
line	NN
1	CD
-RRB-	-RRB-
.	.

Instances	NNS
in	IN
the	DT
given	VBN
training	NN
set	VBN
T	NN
are	VBP
sorted	VBN
along	IN
a	DT
selected	VBN
feature	NN
-LRB-	-LRB-
line	NN
2	CD
-RRB-	-RRB-
and	CC
processed	VBN
in	IN
the	DT
sorted	VBN
order	NN
.	.

For	IN
each	DT
training	NN
instance	NN
t	NN
-LRB-	-LRB-
line	NN
3	CD
-RRB-	-RRB-
,	,
we	PRP
search	VBP
through	IN
R	NN
-LRB-	-LRB-
line	NN
4	CD
-RRB-	-RRB-
for	IN
the	DT
best	JJS
rectangle	NN
to	TO
accommodate	VB
it	PRP
.	.

Expanding	VBG
rectangles	NNS
would	MD
incur	VB
covering	VBG
violations	NNS
,	,
i.e.	FW
,	,
overlapping	VBG
of	IN
rectangles	NNS
of	IN
diï	NN
¬	CD
$	$
erent	JJ
classes	NNS
,	,
which	WDT
are	VBP
not	RB
allowed	VBN
.	.

The	DT
best	JJS
rectangle	NN
to	TO
cover	VB
t	NN
is	VBZ
the	DT
one	CD
with	IN
the	DT
smallest	JJS
covering	VBG
cost	NN
with	IN
respect	NN
to	TO
t	NN
,	,
which	WDT
is	VBZ
deï	NN
¬	NN
ned	VBD
such	JJ
that	IN
the	DT
number	NN
of	IN
generated	VBN
rectangles	NNS
can	MD
be	VB
minimized	VBN
.	.


In	IN
line	NN
5	CD
,	,
the	DT
cost	NN
of	IN
r	NN
in	IN
covering	VBG
t	NN
,	,
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
,	,
is	VBZ
calculated	VBN
.	.

cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
=	JJ
0only	RB
if	IN
t	NN
lies	VBZ
straightly	RB
under	IN
r	NN
,	,
i.e.	FW
,	,
by	IN
simply	RB
extending	VBG
r	NN
along	IN
the	DT
selected	VBN
sorting	VBG
feature	NN
,	,
t	NN
will	MD
be	VB
covered	VBN
by	IN
r.If	NN
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
=	JJ
0and	NN
r	NN
and	CC
t	NN
are	VBP
of	IN
diï	NN
¬	CD
$	$
erent	JJ
classes	NNS
-LRB-	-LRB-
line	NN
6	CD
-RRB-	-RRB-
,	,
r	NN
is	VBZ
closed	VBN
on	IN
condition	NN
that	IN
it	PRP
can	MD
be	VB
validated	VBN
;	:
otherwise	RB
,	,
r	NN
is	VBZ
bisected	VBN
and	CC
the	DT
two	CD
propagated	VBN
rectangles	NNS
are	VBP
inserted	VBN
into	IN
R	NN
-LRB-	-LRB-
line	NN
7	CD
-RRB-	-RRB-
.	.

Closed	JJ
rectangles	NNS
will	MD
not	RB
be	VB
considered	VBN
in	IN
the	DT
remaining	VBG
procedures	NNS
,	,
since	IN
they	PRP
can	MD
not	RB
be	VB
used	VBN
to	TO
cover	VB
any	DT
further	JJ
instances	NNS
without	IN
causing	VBG
violations	NNS
.	.


If	IN
a	DT
non-closed	JJ
r	NN
has	VBZ
the	DT
same	JJ
class	NN
label	NN
as	IN
t	NN
with	IN
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
=	JJ
0	CD
-LRB-	-LRB-
line	NN
8	CD
-RRB-	-RRB-
,	,
r	NN
is	VBZ
an	DT
optimal	JJ
rectangle	NN
to	TO
cover	VB
t	NN
.	.

We	PRP
can	MD
simply	RB
stop	VB
searching	VBG
and	CC
continue	VB
to	TO
process	VB
the	DT
next	JJ
instance	NN
-LRB-	-LRB-
line	NN
9	CD
-RRB-	-RRB-
.	.

Note	VB
that	IN
in	IN
this	DT
case	NN
,	,
violation	NN
checking	NN
is	VBZ
unnecessary	JJ
since	IN
instances	NNS
in	IN
T	NN
are	VBP
sorted	VBN
and	CC
we	PRP
only	RB
need	VBP
to	TO
extend	VB
r	NN
along	IN
the	DT
sorting	VBG
feature	NN
to	TO
cover	VB
t.	IN


If	IN
t	NN
has	VBZ
not	RB
been	VBN
covered	VBN
by	IN
such	PDT
an	DT
optimal	JJ
r	NN
-LRB-	-LRB-
line	NN
10	CD
-RRB-	-RRB-
,	,
we	PRP
need	VBP
to	TO
search	VB
through	IN
R	NN
for	IN
the	DT
best	JJS
r	NN
with	IN
the	DT
smallest	JJS
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
.	.

The	DT
rectangles	NNS
in	IN
R	NN
will	MD
be	VB
considered	VBN
in	IN
the	DT
ascending	VBG
order	NN
of	IN
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
,	,
the	DT
ï	NN
¬	NN
rst	NN
available	JJ
one	CD
-LRB-	-LRB-
line	NN
11	CD
-RRB-	-RRB-
will	MD
be	VB
used	VBN
to	TO
cover	VB
t	NN
and	CC
we	PRP
can	MD
continue	VB
to	TO
process	VB
the	DT
next	JJ
instance	NN
-LRB-	-LRB-
line	NN
12	CD
-RRB-	-RRB-
.	.



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
6	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



644	CD
B.J.	NNP
Gao	NNP
and	CC
M.	NNP
Ester	NNP


If	IN
there	EX
is	VBZ
no	DT
such	JJ
r	NN
âˆˆ	NN
R	NN
that	WDT
can	MD
cover	VB
t	NN
without	IN
incurring	VBG
a	DT
violation	NN
,	,
a	DT
trivial	JJ
rectangle	NN
rnew	NN
for	IN
t	NN
will	MD
be	VB
constructed	VBN
and	CC
inserted	VBN
into	IN
R	NN
-LRB-	-LRB-
line	NN
13	CD
-RRB-	-RRB-
.	.


Upon	IN
reaching	VBG
line	NN
14	CD
,	,
all	PDT
the	DT
training	NN
instances	NNS
in	IN
T	NN
have	VBP
been	VBN
processed	VBN
and	CC
generalized	VBN
.	.

The	DT
enforcement	NN
heuristic	NN
discussed	VBN
previously	RB
is	VBZ
applied	VBN
to	TO
all	DT
non-closed	JJ
rectangles	NNS
in	IN
R	NN
-LRB-	-LRB-
closed	JJ
ones	NNS
must	MD
have	VB
been	VBN
validated	VBN
-RRB-	-RRB-
,	,
and	CC
all	PDT
the	DT
recursively	RB
propagated	VBN
rectangles	NNS
will	MD
be	VB
inserted	VBN
into	IN
R	NN
after	IN
validation	NN
.	.

In	IN
the	DT
actual	JJ
implementation	NN
,	,
we	PRP
have	VBP
chosen	VBN
k	NN
=	JJ
1	CD
for	IN
testing	VBG
the	DT
right	NN
of	IN
inference	NN
,	,
that	WDT
is	VBZ
,	,
any	DT
query	NN
q	VB
on	IN
the	DT
surface	NN
of	IN
r	NN
with	IN
dist	NN
-LRB-	-LRB-
q	NN
,	,
q1	NN
-RRB-	-RRB-
>	JJR
Î	NN
´	CD
will	MD
invalidate	VB
r.	NN


As	IN
for	IN
the	DT
choice	NN
of	IN
Î	NN
´	NN
,	,
we	PRP
randomly	RB
sample	NN
a	DT
series	NN
of	IN
queries	NNS
.	.

For	IN
each	DT
query	NN
q	NN
,	,
we	PRP
record	VBP
difq	NN
=	JJ
dist	NN
-LRB-	-LRB-
q	NN
,	,
tq	NN
-RRB-	-RRB-
âˆ	NN
'	''
dist	NN
-LRB-	-LRB-
q	NN
,	,
tq	NN
-RRB-	-RRB-
,	,
where	WRB
tq	NN
is	VBZ
the	DT
nearest	JJS
training	NN
instance	NN
of	IN
q	NN
and	CC
tq	NN
is	VBZ
the	DT
nearest	JJS
training	NN
instance	NN
of	IN
q	NN
that	WDT
has	VBZ
a	DT
diï	NN
¬	CD
$	$
erent	JJ
class	NN
label	NN
from	IN
tq.Ifweset	NN
Î	NN
´	NN
=	JJ
difq	NN
,	,
the	DT
resulting	VBG
NR	NN
classiï	NN
¬	CD
er	NN
behaves	VBZ
the	DT
same	JJ
as	IN
1-NN	NN
on	IN
q	NN
and	CC
q	NN
will	MD
not	RB
be	VB
assigned	VBN
a	DT
class	NN
label	NN
other	JJ
than	IN
the	DT
one	CD
of	IN
tq	NN
.	.


To	TO
see	VB
why	WRB
,	,
letrt	NN


q	SYM


and	CC
rt	NN


q	SYM


be	VB
any	DT
two	CD
rectangles	NNS
covering	VBG
tq	NN
and	CC
tq	NN
respectively	RB
,	,
then	RB
dist	NN
-LRB-	-LRB-
q	NN
,	,
rt	NN


q	SYM


-RRB-	-RRB-
â	NN
‰	CD
$	$
dist	CD
-LRB-	-LRB-
q	NN
,	,
tq	NN
-RRB-	-RRB-
and	CC
dist	NN
-LRB-	-LRB-
q	NN
,	,
tq	NN
-RRB-	-RRB-
âˆ	NN
'	''
dist	NN
-LRB-	-LRB-
q	NN
,	,
rt	NN


q	SYM


-RRB-	-RRB-
â	NN
‰	CD
$	$
Î	CD
´	CD
if	IN
rt	NN


q	SYM


is	VBZ
enforced	VBN
the	DT
right	NN
of	IN
inference	NN
,	,
from	IN
which	WDT
dist	NN
-LRB-	-LRB-
q	NN
,	,
rt	NN


q	SYM


-RRB-	-RRB-
â	NN
‰	CD
$	$
dist	CD
-LRB-	-LRB-
q	NN
,	,
rt	NN


q	SYM


-RRB-	-RRB-
follows	VBZ
.	.

Intuitively	RB
,	,
since	IN
the	DT
right	NN
of	IN
inference	NN
is	VBZ
enforced	VBN
on	IN
rt	NN


q	SYM


,	,
tq	NN
will	MD
not	RB
be	VB
brought	VBN
close	RB
enough	RB
by	IN
the	DT
rectangular	JJ
generalization	NN
to	TO
challenge	VB
the	DT
locality	NN
of	IN
tq	NN
with	IN
respect	NN
to	TO
q.Notethat	NN
tq	NN
is	VBZ
also	RB
brought	VBN
closer	RBR
to	TO
q	VB
by	IN
rt	NN


q	SYM


.	.

After	IN
obtaining	VBG
a	DT
series	NN
of	IN
difq	NN
â	NN
$	$
™	CD
s	NNS
,	,
we	PRP
use	VBP
the	DT
average	JJ
value	NN
as	IN
Î	NN
´	CD
.	.

While	IN
how	WRB
to	TO
decide	VB
Î	NNP
´	CD
deserves	VBZ
further	JJ
investigations	NNS
,	,
a	DT
more	RBR
practical	JJ
situation	NN
would	MD
be	VB
,	,
selecting	VBG
Î	NNP
´	CD
so	RB
as	IN
to	TO
meet	VB
a	DT
given	VBN
constraint	NN
on	IN
the	DT
maximum	NN
number	NN
of	IN
rectangles	NNS
allowed	VBN
.	.


The	DT
proposed	VBN
NR	NN
learner	NN
LearnCovers	NNP
is	VBZ
an	DT
extension	NN
of	IN
Learn2Cover	NN
-LSB-	-LRB-
5	CD
-RSB-	-RRB-
,	,
a	DT
discriminative	JJ
summarization	NN
heuristic	NN
for	IN
labeled	VBN
data	NNS
,	,
from	IN
2	CD
class	NN
to	TO
multi	NNS
-	:
class	NN
and	CC
with	IN
the	DT
right	NN
of	IN
inference	NN
enforcement	NN
mechanism	NN
embedded	JJ
.	.

Some	DT
re	SYM
-	:
lated	JJ
issues	NNS
,	,
such	JJ
as	IN
selecting	VBG
the	DT
sorting	VBG
feature	NN
,	,
handling	VBG
ties	NNS
,	,
deï	NN
¬	CD
ning	JJ
cost	NN
-LRB-	-LRB-
r	NN
,	,
t	NN
-RRB-	-RRB-
and	CC
so	RB
on	IN
,	,
are	VBP
discussed	VBN
in	IN
-LSB-	-LRB-
5	CD
-RSB-	-RRB-
with	IN
more	JJR
details	NNS
.	.


4	CD
Empirical	JJ
Results	NNS


A	DT
series	NN
of	IN
experiments	NNS
were	VBD
conducted	VBN
to	TO
evaluate	VB
the	DT
accuracy	NN
performance	NN
of	IN
the	DT
proposed	VBN
NR	NN
learner	NN
LearnCovers	NNS
.	.

The	DT
notion	NN
of	IN
rectangle	NN
can	MD
be	VB
extended	VBN
to	TO
tolerate	VB
categorical	JJ
features	NNS
but	CC
not	RB
in	IN
this	DT
prototype	NN
version	NN
;	:
thus	RB
20	CD
nu	SYM
-	:
merical	JJ
benchmark	JJ
datasets	NNS
without	IN
missing	VBG
values	NNS
from	IN
the	DT
UCI	NNP
repository	NN
-LSB-	-LRB-
3	CD
-RSB-	-RRB-
were	VBD
used	VBN
to	TO
run	VB
C4	NN
.5	NN
-LSB-	-LRB-
8	CD
-RSB-	-RRB-
,	,
1-NN	NN
,	,
kNN	NN
and	CC
LearnCovers	NNS
.	.

For	IN
kNN	NN
,	,
the	DT
highest	JJS
accuracy	NN
was	VBD
recorded	VBN
.	.

The	DT
datasets	NNS
were	VBD
normalized	VBN
on	IN
each	DT
feature	NN
.	.

For	IN
each	DT
of	IN
the	DT
datasets	NNS
where	WRB
cross-validation	NN
was	VBD
needed	VBN
,	,
the	DT
averaged	VBD
result	NN
over	IN
3	CD
runs	NNS
of	IN
stratiï	NN
¬	CD
ed	VBD
10-fold	RB
cross-validation	NN
was	VBD
taken	VBN
.	.


In	IN
Table	NNP
1	CD
,	,
â	RB
$	$
œAttâ	JJ
$	$
,	,
â	VB
$	$
œInsâ	JJ
$	$
and	CC
â	VB
$	$
œClaâ	JJ
$	$
indicate	VBP
the	DT
numbers	NNS
of	IN
attributes	NNS
,	,
in	IN
-	:
stances	NNS
and	CC
classes	NNS
respectively	RB
for	IN
the	DT
datasets	NNS
.	.

The	DT
results	NNS
show	VBP
that	IN
,	,
Learn	VB
-	:
Covers	VBZ
outperforms	VBZ
C4	NN
.5	CD
in	IN
19	CD
,	,
1-NN	NN
in	IN
12	CD
,	,
and	CC
kNN	NN
in	IN
8	CD
of	IN
the	DT
20	CD
datasets	NNS
.	.

It	PRP
has	VBZ
the	DT
averaged	VBN
accuracy	NN
of	IN
0.857	CD
,	,
signiï	NN
¬	NN
cantly	RB
higher	JJR
than	IN
C4	NN
.5	CD
-LRB-	-LRB-
0.817	CD
-RRB-	-RRB-
,	,
better	JJR
than	IN
1-NN	NN
-LRB-	-LRB-
0.843	CD
-RRB-	-RRB-
and	CC
comparable	JJ
to	TO
kNN	NN
-LRB-	-LRB-
0.864	CD
-RRB-	-RRB-
.	.

Recall	VB
that	IN
,	,
without	IN
consid	NN
-	:
ering	VBG
the	DT
right	NN
of	IN
inference	NN
,	,
but	CC
assisted	VBN
by	IN
some	DT
other	JJ
sophisticated	JJ
techniques	NNS
such	JJ
as	IN
rectangle	NN
weighting	NN
and	CC
feature	NN
weighting	NN
using	VBG
mutual	JJ
information	NN
,	,
the	DT



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
7	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



Right	RB
of	IN
Inference	NNP
:	:
Nearest	JJS
Rectangle	NNP
Learning	NNP
Revisited	NNP
645	CD


Table	NNP
1	CD
.	.

Accuracy	NNP
:	:
C4	NN
.5	CD
,	,
1-NN	NN
,	,
kNN	NN
,	,
and	CC
LearnCovers	NNP
-LRB-	-LRB-
LC	NNP
-RRB-	-RRB-


Dataset	NNP
Att	NNP
Ins	NNP
Cla	NNP
C4	NN
.5	CD
1-NN	NN
kNN	NN
balance	NN
4	CD
625	CD
3	CD


bupa	NN
6	CD
345	CD
2	CD


car	NN
6	CD
1728	CD
4	CD


ecoli	NNS
7	CD
336	CD
8	CD


glass	NN
10	CD
214	CD
6	CD


iono	NN
34	CD
351	CD
2	CD


iris	NN
4	CD
150	CD
3	CD


letter	NN


new-thyr	NN
5	CD
215	CD
3	CD


page-blo	JJ
10	CD
5473	CD
5	CD


0.758	CD
0.790	CD
0.900	CD
0.828	CD


0.655	CD
0.632	CD
0.652	CD
0.672	CD


0.917	CD
0.917	CD
0.951	CD
0.938	CD


0.841	CD
0.806	CD
0.871	CD
0.869	CD


0.687	CD
0.701	CD
0.712	CD
0.739	CD


0.900	CD
0.869	CD
0.869	CD
0.937	CD


0.953	CD
0.953	CD
0.967	CD
0.973	CD
16	CD
20000	CD
26	CD
0.868	CD
0.955	CD
0.955	CD
0.925	CD


0.916	CD
0.968	CD
0.968	CD
0.953	CD


0.965	CD
0.957	CD
0.959	CD
0.971	CD


LC	NN


Dataset	NNP
Att	NNP
Ins	NNP
Cla	NNP
C4	NN
.5	CD
1-NN	NN
kNN	NN
LC	NN


pima	FW
8	CD
768	CD
2	CD
0.737	CD
0.701	CD
0.738	CD
0.752	CD
satimage	NN
36	CD
6435	CD
6	CD
0.850	CD
0.894	CD
0.906	CD
0.878	CD
segment	NN
19	CD
2310	CD
7	CD
0.960	CD
0.974	CD
0.974	CD
0.966	CD


sonar	NN
60	CD
208	CD
2	CD
0.702	CD
0.865	CD
0.865	CD
0.794	CD
spambase	NN
57	CD
4601	CD
2	CD
0.895	CD
0.908	CD
0.908	CD
0.897	CD
vehicle	NN
18	CD
846	CD
4	CD
0.734	CD
0.696	CD
0.725	CD
0.709	CD
vowel	NN
10	CD
990	CD
11	CD
0.788	CD
0.989	CD
0.989	CD
0.973	CD
waveform	NN
21	CD
5000	CD
3	CD
0.781	CD
0.809	CD
0.833	CD
0.808	CD


wine	NN
13	CD
178	CD
3	CD
0.936	CD
0.949	CD
0.972	CD
0.977	CD


yeast	NN
8	CD
1484	CD
10	CD
0.494	CD
0.526	CD
0.574	CD
0.581	CD


Average	JJ
0.817	CD
0.843	CD
0.864	CD
0.857	CD


remedies	NNS
proposed	VBN
in	IN
-LSB-	-LRB-
10,11	CD
-RSB-	-RRB-
only	RB
achieved	VBD
moderate	JJ
accuracy	NN
improvement	NN
on	IN
the	DT
original	JJ
NR	NN
learner	NN
,	,
remaining	VBG
â	JJ
$	$
œsigniï	JJ
¬	NN
cantly	RB
inferior	JJ
to	TO
kNNâ	VB
$	$
.	.


5Conclusion	NN


In	IN
this	DT
paper	NN
,	,
we	PRP
revisited	VBD
NR	NN
learning	NN
,	,
seeking	VBG
for	IN
its	PRP$
accuracy	NN
improvement	NN
through	IN
imposing	VBG
the	DT
right	NN
of	IN
reference	NN
on	IN
rectangles	NNS
.	.

Experiments	NNS
on	IN
bench	NN
-	:
mark	NN
datasets	NNS
demonstrated	VBD
the	DT
eï	NN
¬	CD
$	$
ectiveness	JJ
of	IN
the	DT
proposed	VBN
approach	NN
.	.

For	IN
future	JJ
work	NN
,	,
more	JJR
eï	NN
¬	CD
$	$
ective	JJ
and	CC
eï	NN
¬	NN
ƒcient	JJ
testing	NN
and	CC
enforcement	NN
mechanisms	NNS
should	MD
be	VB
investigated	VBN
.	.

Grounded	VBN
on	IN
the	DT
right	NN
of	IN
inference	NN
of	IN
rectangles	NNS
,	,
there	EX
are	VBP
several	JJ
interesting	JJ
directions	NNS
to	TO
further	RBR
extend	VB
NR	NN
learning	NN
.	.

One	CD
is	VBZ
to	TO
con	VB
-	:
sider	NN
k	NN
nearest	JJS
-LRB-	-LRB-
weighted	JJ
-RRB-	-RRB-
rectangles	NNS
in	IN
classiï	NN
¬	CD
cation	NN
;	:
another	DT
is	VBZ
to	TO
consider	VB
creating	VBG
a	DT
classiï	NN
¬	CD
er	NN
ensemble	NN
with	IN
multiple	JJ
rectangle	NN
sets	VBZ
that	IN
,	,
for	IN
example	NN
,	,
can	MD
be	VB
obtained	VBN
from	IN
LearnCovers	NNPS
by	IN
varying	VBG
the	DT
sorting	VBG
feature	NN
.	.


References	NNS


1	LS
.	.

D.	NNP
Aha	NNP
.	.

Lazy	JJ
learning	NN
.	.

Artiï	NNP
¬	CD
cial	JJ
Intelligence	NNP
Review	NNP
,	,
11:7	CD
-10	CD
,	,
1997	CD
.	.


2	LS
.	.

C.	NNP
Apte	NNP
and	CC
S.	NNP
Weiss	NNP
.	.

Data	NNS
mining	VBG
with	IN
decision	NN
trees	NNS
and	CC
decision	NN
rules	NNS
.	.

Future	JJ


Generation	NNP
Computer	NNP
Systems	NNPS
,	,
1997	CD
.	.


3	LS
.	.

C.L.	NNP
Blake	NNP
and	CC
C.J.	NNP
Merz	NNP
.	.

UCI	NN
repository	NN
of	IN
machine	NN
learning	NN
databases	NNS
,	,
1998	CD
.	.

4	LS
.	.

B.V.	NNP
Dasarathy	NNP
.	.

Nearest	JJS
Neighbor	NN
-LRB-	-LRB-
NN	NNP
-RRB-	-RRB-
norms	NNS
:	:
NN	NNP
pattern	NN
classiï	NN
¬	CD
cation	NN
tech	NN
-	:


niques	NNS
.	.

IEEE	NNP
Computer	NNP
Society	NNP
Press	NNP
,	,
1991	CD
.	.


5	CD
.	.

B.J.	NNP
Gao	NNP
and	CC
M.	NNP
Ester	NNP
.	.

Cluster	NN
description	NN
formats	NNS
,	,
problems	NNS
,	,
and	CC
algorithms	NNS
.	.

In	IN


SIAM	NNP
International	NNP
Conference	NNP
on	IN
Data	NNP
Mining	NNP
,	,
2006	CD
.	.


6	CD
.	.

S.K.	NNP
Murthy	NNP
.	.

Automatic	NNP
construction	NN
of	IN
decision	NN
trees	NNS
from	IN
data	NNS
:	:
a	DT
multi	NNS
-	:


disciplinary	JJ
survey	NN
.	.

Data	NNS
Mining	NN
and	CC
Knowledge	NN
Discovery	NNP
,	,
2	CD
-LRB-	-LRB-
4	CD
-RRB-	-RRB-
:345	CD
-389	CD
,	,
1998	CD
.	.

7	CD
.	.

J.R.	NNP
Quinlan	NNP
.	.

Combining	VBG
instance-based	JJ
and	CC
model-based	JJ
learning	NN
.	.

In	IN
ICML	NN
,	,
1993	CD
.	.

8	CD
.	.

J.R.	NNP
Quinlan	NNP
.	.

C4	NN
.5	CD
:	:
programs	NNS
for	IN
machine	NN
learning	NN
.	.

Morgan	NNP
Kaufmann	NNP
,	,
1993	CD
.	.

9	CD
.	.

S.	NNP
Salzberg	NNP
.	.

A	DT
nearest	JJS
hyperrectanhgle	NN
learning	NN
method	NN
.	.

Machine	NN
Learning	NNP
,	,
6:251	CD
-	:


276	CD
,	,
1991	CD
.	.


10	CD
.	.

D.	NNP
Wettschereck	NNP
.	.

A	DT
hybrid	NN
nearest-neighbor	NN
and	CC
nearest-hyperrectangle	JJ
algorithm	NN
.	.


In	IN
ECML	NN
,	,
1994	CD
.	.


11	CD
.	.

D.	NNP
Wettschereck	NNP
and	CC
T.G.	NNP
Dietterich	NNP
.	.

An	DT
experimental	JJ
comparison	NN
of	IN
the	DT
nearest	JJS
-	:


neighbor	NN
and	CC
nearest-hyperrectangle	JJ
algorithms.Machine	NN
Learning	NNP
,	,
19:5	CD
-27	CD
,	,
1995	CD
.	.



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
8	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



