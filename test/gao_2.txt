Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


Contents	NNS
lists	NNS
available	JJ
at	IN
SciVerse	NNP
ScienceDirect	NNP


Neurocomputing	VBG


journal	NN
homepage	NN
:	:
www.elsevier.com/locate/neucom	NNP


A	DT
framework	NN
for	IN
application-driven	JJ
classiÔ	NN
¨	NN
cation	NN
of	IN
data	NNS
streams	NNS


Peng	NNP
Zhanga	NNP
,	,
b	NN
,	,
n	NN
,	,
Byron	NNP
J.	NNP
Gaob	NNP
,	,
Ping	VBP
Liua	NNP
,	,
Yong	NNP
Shic	NNP
,	,
Li	NNP
Guoa	NNP


a	DT


Institute	NNP
of	IN
Computing	NNP
Technology	NNP
,	,
Chinese	NNP
Academy	NNP
of	IN
Sciences	NNPS
,	,
Beijing	NNP
100190	CD
,	,
China	NNP
b	NN


Department	NNP
of	IN
Computer	NNP
Science	NNP
,	,
Texas	NNP
State	NNP
University	NNP
,	,
San	NNP
Marcos	NNP
,	,
TX	NNP
78666	CD
,	,
USA	NNP
c	NN


FEDS	NNP
Center	NNP
,	,
Graduate	NNP
University	NNP
,	,
Chinese	NNP
Academy	NNP
of	IN
Sciences	NNPS
,	,
Beijing	NNP
100190	CD
,	,
China	NNP


article	NN
info	NN


abstract	JJ


Available	JJ
online	NN
13	CD
March	NNP
2012	CD


Keywords	NNS
:	:


Data	NNP
stream	NN
classiÔ	NN
¨	CD
cation	NN
Transfer	NN
learning	VBG
Semi-supervised	JJ
learning	NN
Relational	JJ
k-means	NNS
Concept	NN
drifting	VBG


Data	NNP
stream	NN
classiÔ	NN
¨	CD
cation	NN
has	VBZ
drawn	VBN
increasing	VBG
attention	NN
from	IN
the	DT
data	NNS
mining	NN
community	NN
in	IN
recent	JJ
years	NNS
.	.

Relevant	JJ
applications	NNS
include	VBP
network	NN
trafÔ	NN
¨	CD
c	NN
monitoring	NN
,	,
sensor	NN
network	NN
data	NN
analysis	NN
,	,
Web	NN
click	VBP
stream	NN
mining	NN
,	,
power	NN
consumption	NN
measurement	NN
,	,
dynamic	JJ
tracing	VBG
of	IN
stock	NN
Ô	NN
¨	CD
Ç	NN
uctuations	NNS
,	,
to	TO
name	VB
a	DT
few	JJ
.	.

Data	NNP
stream	NN
classiÔ	NN
¨	CD
cation	NN
in	IN
such	JJ
real-world	JJ
applications	NNS
is	VBZ
typically	RB
subject	JJ
to	TO
three	CD
major	JJ
challenges	NNS
:	:
concept	NN
drifting	VBG
,	,
large	JJ
volumes	NNS
,	,
and	CC
partial	JJ
labeling	NN
.	.

As	IN
a	DT
result	NN
,	,
training	NN
examples	NNS
in	IN
data	NNS
streams	NNS
can	MD
be	VB
very	RB
diverse	JJ
and	CC
it	PRP
is	VBZ
very	RB
hard	JJ
to	TO
learn	VB
accurate	JJ
models	NNS
with	IN
efÔ	NN
¨	CD
ciency	NN
.	.

In	IN
this	DT
paper	NN
,	,
we	PRP
propose	VBP
a	DT
novel	JJ
framework	NN
that	WDT
Ô	VBD
¨	CD
rst	NN
categorizes	VBZ
diverse	JJ
training	NN
examples	NNS
into	IN
four	CD
types	NNS
and	CC
assign	VB
learning	VBG
priorities	NNS
to	TO
them	PRP
.	.

Then	RB
,	,
we	PRP
derive	VBP
four	CD
learning	VBG
cases	NNS
based	VBN
on	IN
the	DT
proportion	NN
and	CC
priority	NN
of	IN
the	DT
different	JJ
types	NNS
of	IN
training	NN
examples	NNS
.	.

Finally	RB
,	,
for	IN
each	DT
learning	VBG
case	NN
,	,
we	PRP
employ	VBP
one	CD
of	IN
the	DT
four	CD
SVM-based	JJ
training	NN
models	NNS
:	:
classical	JJ
SVM	NNP
,	,
semi-supervised	JJ
SVM	NN
,	,
transfer	NN
semi-supervised	JJ
SVM	NN
,	,
and	CC
relational	JJ
k-means	NNS
transfer	NN
semi-supervised	JJ
SVM	NN
.	.

We	PRP
perform	VBP
comprehensive	JJ
experiments	NNS
on	IN
real-world	JJ
data	NNS
streams	NNS
that	WDT
validate	VBP
the	DT
utility	NN
of	IN
our	PRP$
approach	NN
.	.


1	LS
.	.

Introduction	NN


Recent	JJ
advances	NNS
in	IN
computing	VBG
technology	NN
and	CC
networking	NN
architectures	NNS
have	VBP
enabled	VBN
generation	NN
and	CC
collection	NN
of	IN
unprece	NN
-	:
dented	VBN
amount	NN
of	IN
data	NNS
streams	NNS
of	IN
various	JJ
kinds	NNS
,	,
such	JJ
as	IN
network	NN
trafÔ	NN
¨	CD
c	NN
data	NNS
,	,
wireless	JJ
sensor	NN
readings	NNS
,	,
Web	NN
page	NN
visits	NNS
,	,
online	JJ
Ô	NN
¨	NN
nancial	JJ
transactions	NNS
and	CC
phone	NN
call	NN
records	NNS
-LSB-	-LRB-
5	CD
-RSB-	-RRB-
.	.

Consequently	RB
,	,
data	NNS
stream	NN
mining	NN
has	VBZ
emerged	VBN
to	TO
be	VB
one	CD
of	IN
the	DT
most	RBS
important	JJ
research	NN
frontiers	NNS
in	IN
data	NNS
mining	NN
.	.

Common	JJ
stream	NN
mining	NN
tasks	NNS
include	VBP
classiÔ	NN
¨	CD
cation	NN
-LSB-	-LRB-
34,30	CD
-RSB-	-RRB-
,	,
clustering	NN
-LSB-	-LRB-
3	CD
-RSB-	-RRB-
and	CC
frequent	JJ
pattern	NN
mining	NN
-LSB-	-LRB-
15	CD
-RSB-	-RRB-
.	.

Among	IN
them	PRP
,	,
data	NNS
stream	NN
classiÔ	NN
¨	CD
cation	NN
has	VBZ
drawn	VBN
particular	JJ
attention	NN
due	JJ
to	TO
its	PRP$
vast	JJ
real-world	JJ
applications	NNS
.	.


Example	NN
.	.

In	IN
wireless	JJ
sensor	NN
networks	NNS
,	,
data	NNS
stream	NN
classiÔ	NN
¨	CD
cation	NN
has	VBZ
been	VBN
used	VBN
to	TO
monitor	VB
environment	NN
changes	NNS
.	.

For	IN
example	NN
,	,
in	IN
the	DT
sensor	NN
data	NNS
collected	VBN
by	IN
the	DT
Intel	NNP
Berkeley	NNP
Research	NNP
Lab	NN
-LSB-	-LRB-
37	CD
-RSB-	-RRB-
,	,
each	DT
sensor	NN
reading	NN
contains	VBZ
information	NN
-LRB-	-LRB-
temperature	NN
,	,
humidity	NN
,	,
light	NN
and	CC
sensor	NN
voltage	NN
-RRB-	-RRB-
collected	VBN
from	IN
54	CD
sensors	NNS
deployed	VBN
in	IN
the	DT
lab	NN
.	.

The	DT
whole	JJ
stream	NN
contains	VBZ
consecutive	JJ
information	NN
recorded	VBN
over	IN
a	DT
2-month	JJ
period	NN
-LRB-	-LRB-
one	CD
reading	NN
per	IN
1‚	NN
$	$
``	``
3	CD
min	NN
-RRB-	-RRB-
.	.

By	IN
using	VBG
the	DT
sensor	NN
ID	NN
as	IN
class	NN
label	NN
,	,
the	DT
learning	VBG
task	NN
is	VBZ
to	TO
correctly	RB
identify	VB
the	DT
sensor	NN
ID	NN
-LRB-	-LRB-
one	CD
out	IN
of	IN
54	CD
sensors	NNS
-RRB-	-RRB-
purely	RB
based	VBN
on	IN
the	DT
sensor	NN
data	NNS
and	CC
the	DT
corresponding	JJ
recording	NN
time	NN
.	.


n	NN


Corresponding	VBG
author	NN
at	IN
:	:
Institute	NNP
of	IN
Computing	NNP
Technology	NNP
,	,
Chinese	NNP
Academy	NNP
of	IN
Sciences	NNPS
,	,
Beijing	NNP
100190	CD
,	,
China	NNP
.	.


E-mail	NN
addresses	NNS
:	:
zhangpeng@ict.ac.cn	NN
-LRB-	-LRB-
P.	FW
Zhang	NNP
-RRB-	-RRB-
,	,
bgao@txstate.edu	NN
-LRB-	-LRB-
B.J.	NNP
Gao	NNP
-RRB-	-RRB-
,	,
liuping@ict.ac.cn	NN
-LRB-	-LRB-
P.	NNP
Liu	NNP
-RRB-	-RRB-
,	,
yshi@gucas.ac.cn	NN
-LRB-	-LRB-
Y.	NNP
Shi	NNP
-RRB-	-RRB-
,	,
guoli@ict.ac.cn	NN
-LRB-	-LRB-
L.	FW
Guo	FW
-RRB-	-RRB-
.	.


0925-2312	CD
/	:
$	$
-	:
see	VB
front	JJ
matter	NN
&	CC
2012	CD
Elsevier	NNP
B.V.	NNP
All	NNP
rights	NNS
reserved	VBD
.	.

doi	FW
:10.1016	CD
/	:
j.neucom	NNP
.2011.11.026	CD


&	CC
2012	CD
Elsevier	NNP
B.V.	NNP
All	NNP
rights	NNS
reserved	VBD
.	.


Example	NN
.	.

In	IN
power	NN
consumption	NN
analysis	NN
,	,
data	NNS
stream	NN
classiÔ	NN
¨	CD
ca	MD
-	:
tion	NN
has	VBZ
been	VBN
used	VBN
to	TO
measure	VB
power	NN
consumptions	NNS
.	.

For	IN
example	NN
,	,
the	DT
power	NN
supply	NN
stream	NN
collected	VBN
by	IN
an	DT
Italian	JJ
electricity	NN
company	NN
-LSB-	-LRB-
37	CD
-RSB-	-RRB-
contains	VBZ
hourly	JJ
power	NN
supply	NN
of	IN
the	DT
company	NN
recording	VBG
the	DT
power	NN
from	IN
two	CD
sources	NNS
:	:
power	NN
supplied	VBN
from	IN
main	JJ
grid	NN
and	CC
power	NN
transformed	VBN
from	IN
other	JJ
grids	NNS
.	.

The	DT
stream	NN
contains	VBZ
3-year	JJ
power	NN
supply	NN
records	NNS
from	IN
1995	CD
to	TO
1998	CD
,	,
and	CC
the	DT
learning	VBG
task	NN
is	VBZ
to	TO
predict	VB
which	WDT
hour	NN
-LRB-	-LRB-
1	CD
out	IN
of	IN
24	CD
h	NN
-RRB-	-RRB-
the	DT
current	JJ
power	NN
supply	NN
belongs	VBZ
to	TO
.	.


Example	NN
.	.

In	IN
information	NN
security	NN
,	,
data	NNS
stream	NN
classiÔ	NN
¨	CD
cation	NN
has	VBZ
been	VBN
widely	RB
used	VBN
to	TO
monitor	VB
Web	NN
trafÔ	NN
¨	CD
c	NN
streams	NNS
.	.

For	IN
example	NN
,	,
the	DT
KDDCUP‚	NNP
$	$
ô	CD
99	CD
intrusion	NN
detection	NN
dataset	NN
-LSB-	-LRB-
4	CD
-RSB-	-RRB-
was	VBD
provided	VBN
by	IN
the	DT
MIT	NNP
Lincoln	NNP
Labs	NNPS
collecting	VBG
9	CD
weeks	NNS
of	IN
raw	JJ
TCP	NN
dump	NN
data	NNS
for	IN
a	DT
local	JJ
area	NN
network	NN
.	.

The	DT
learning	NN
task	NN
is	VBZ
to	TO
build	VB
a	DT
predictive	JJ
model	NN
capable	JJ
of	IN
distinguishing	VBG
between	IN
normal	JJ
connections	NNS
and	CC
intrusive	JJ
connections	NNS
such	JJ
as	IN
DOS	NNP
-LRB-	-LRB-
denial-of-service	JJ
-RRB-	-RRB-
,	,
R2L	NN
-LRB-	-LRB-
unauthorized	JJ
access	NN
from	IN
a	DT
remote	JJ
machine	NN
-RRB-	-RRB-
,	,
U2R	NN
-LRB-	-LRB-
unauthorized	JJ
access	NN
to	TO
local	JJ
super	JJ
user	NN
privileges	NNS
-RRB-	-RRB-
,	,
and	CC
Probing	VBG
-LRB-	-LRB-
surveillance	NN
and	CC
other	JJ
probing	VBG
-RRB-	-RRB-
attacks	NNS
.	.


In	IN
these	DT
applications	NNS
,	,
the	DT
essential	JJ
goal	NN
is	VBZ
to	TO
efÔ	VB
¨	CD
ciently	RB
build	VB
classiÔ	NN
¨	NN
cation	NN
models	NNS
from	IN
data	NNS
streams	NNS
for	IN
accurate	JJ
prediction	NN
.	.

Compared	VBN
to	TO
traditional	JJ
stationary	JJ
data	NNS
,	,
building	VBG
prediction	NN
models	NNS
from	IN
stream	NN
data	NNS
faces	VBZ
three	CD
additional	JJ
challenges	NNS
:	:


Concept	NN
drifting	VBG
:	:
In	IN
data	NNS
streams	NNS
,	,
hidden	VBN
patterns	NNS
continuously	RB


change	NN
with	IN
time	NN
-LSB-	-LRB-
26	CD
-RSB-	-RRB-
.	.

For	IN
example	NN
,	,
in	IN
the	DT
wireless	JJ
sensor	NN



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
1	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


b1	NN


b1	NN
b2	NN


b2	NN


b3	NN


Time	NNP
T1	NN


Time	NNP
T2	NN


Time	NNP
T3	NN


Fig.	NN
1	CD
.	.

An	DT
illustration	NN
of	IN
concept	NN
drifting	VBG
in	IN
data	NNS
streams	NNS
.	.

In	IN
the	DT
three	CD
consecutive	JJ
time	NN
stamps	NNS
T1	NN
,	,
T2	NN
and	CC
T3	NN
,	,
the	DT
classiÔ	NN
¨	NN
cation	NN
boundary	NN
gradually	RB
drifts	VBZ
from	IN
b1	NN
to	TO
b2	NN
and	CC
Ô	NN
¨	CD
nally	RB
to	TO
b3	NN
.	.


stream	NN
,	,
lighting	NN
during	IN
working	VBG
hours	NNS
is	VBZ
generally	RB
stronger	JJR


than	IN
off-hours	NNS
.	.

Fig.	NN
1	CD
illustrates	VBZ
the	DT
concept	NN
drifting	VBG
problem	NN
,	,


where	WRB
the	DT
classiÔ	NN
¨	NN
cation	NN
boundary	NN
-LRB-	-LRB-
concept	NN
-RRB-	-RRB-
continuously	RB


drifts	VBZ
from	IN
b1	NN
to	TO
b2	NN
,	,
and	CC
Ô	NN
¨	CD
nally	RB
to	TO
b3	VB
down	RP
the	DT
streams	NNS
.	.

Large	JJ
volumes	NNS
:	:
Stream	NNP
data	NNS
come	VBP
rapidly	RB
and	CC
continuously	RB
in	IN


large	JJ
volumes	NNS
.	.

For	IN
example	NN
,	,
the	DT
wireless	JJ
sensor	NN
stream	NN
con	NN
-	:


tains	NNS
2,219,803	CD
examples	NNS
recorded	VBN
over	IN
a	DT
2-month	JJ
period	NN
-LRB-	-LRB-
one	CD


reading	VBG
per	IN
1‚	NN
$	$
``	``
3	CD
min	NN
-RRB-	-RRB-
.	.

It	PRP
is	VBZ
impossible	JJ
to	TO
maintain	VB
all	DT
historical	JJ


stream	NN
records	NNS
for	IN
in-depth	JJ
analysis	NN
.	.


Partial	JJ
labeling	NN
:	:
Due	JJ
to	TO
large	JJ
volumes	NNS
of	IN
stream	NN
data	NNS
,	,
it	PRP
is	VBZ


infeasible	JJ
to	TO
label	VB
all	DT
stream	NN
examples	NNS
for	IN
building	VBG
classiÔ	NN
¨	NN
cation	NN


models	NNS
.	.

Thus	RB
data	NNS
streams	NNS
are	VBP
typically	RB
partially	RB
labeled	VBN
and	CC


training	NN
data	NNS
contain	VBP
both	CC
labeled	VBN
and	CC
unlabeled	JJ
examples	NNS
.	.


As	IN
a	DT
result	NN
,	,
training	NN
examples	NNS
in	IN
data	NNS
streams	NNS
are	VBP
very	RB
diverse	JJ
.	.

To	TO
see	VB
why	WRB
,	,
let	VB
us	PRP
assume	VB
data	NNS
streams	NNS
are	VBP
buffered	VBN
chunk	NN
by	IN
chunk	NN
.	.

Examples	NNS
in	IN
the	DT
most	RBS
recent	JJ
up-to-date	JJ
chunk	NN
are	VBP
training	VBG
data	NNS
,	,
and	CC
examples	NNS
in	IN
the	DT
yet-to-come	JJ
chunk	NN
are	VBP
testing	VBG
data	NNS
-LSB-	-LRB-
31	CD
-RSB-	-RRB-
.	.

Due	JJ
to	TO
the	DT
concept	NN
drifting	VBG
,	,
training	NN
examples	NNS
in	IN
the	DT
up-to-date	JJ
chunk	NN
often	RB
exhibit	VBP
two	CD
distributions	NNS
:	:
target	NN
domain	NN
and	CC
similar	JJ
domain	NN
,	,
where	WRB
the	DT
former	JJ
represents	VBZ
the	DT
distribution	NN
of	IN
the	DT
testing	NN
data	NNS
,	,
and	CC
the	DT
latter	JJ
represents	VBZ
a	DT
distribution	NN
similar	JJ
to	TO
the	DT
target	NN
domain	NN
-LSB-	-LRB-
9	CD
-RSB-	-RRB-
.	.

Then	RB
,	,
training	NN
examples	NNS
can	MD
be	VB
categorized	VBN
into	IN
four	CD
types	NNS
:	:
labeled	VBN
and	CC
from	IN
the	DT
target	NN
domain	NN
-LRB-	-LRB-
Type	NN
I	CD
-RRB-	-RRB-
,	,
labeled	VBN
and	CC
from	IN
a	DT
similar	JJ
domain	NN
-LRB-	-LRB-
Type	NN
II	CD
-RRB-	-RRB-
,	,
unlabeled	JJ
and	CC
from	IN
the	DT
target	NN
domain	NN
-LRB-	-LRB-
Type	NN
III	CD
-RRB-	-RRB-
and	CC
unlabeled	JJ
and	CC
from	IN
a	DT
similar	JJ
domain	NN
-LRB-	-LRB-
Type	NN
IV	CD
-RRB-	-RRB-
.	.


In	IN
order	NN
to	TO
build	VB
accurate	JJ
prediction	NN
models	NNS
from	IN
such	JJ
diverse	JJ
training	NN
examples	NNS
with	IN
efÔ	NN
¨	CD
ciency	NN
,	,
it	PRP
is	VBZ
necessary	JJ
to	TO
closely	RB
examine	VB
the	DT
characteristics	NNS
,	,
in	IN
particular	JJ
,	,
proportion	NN
and	CC
learning	VBG
priority	NN
,	,
of	IN
the	DT
different	JJ
types	NNS
of	IN
examples	NNS
in	IN
the	DT
training	NN
chunk	NN
.	.


Proportion	NN
:	:
The	DT
proportion	NN
of	IN
training	NN
examples	NNS
from	IN
different	JJ


types	NNS
is	VBZ
determined	VBN
by	IN
the	DT
concept	NN
drifting	VBG
probability	NN
and	CC


labeling	VBG
percentage	NN
-LRB-	-LRB-
percentage	NN
of	IN
labeled	VBN
examples	NNS
-RRB-	-RRB-
.	.

For	IN


example	NN
,	,
when	WRB
concept	NN
drifting	VBG
is	VBZ
low	JJ
and	CC
labeling	NN
percentage	NN


is	VBZ
high	JJ
-LRB-	-LRB-
low	JJ
-RRB-	-RRB-
,	,
the	DT
training	NN
chunk	NN
will	MD
have	VB
a	DT
large	JJ
portion	NN
of	IN


Type	NN
I	CD
-LRB-	-LRB-
III	CD
-RRB-	-RRB-
examples	NNS
.	.

When	WRB
concept	NN
drifting	VBG
is	VBZ
high	JJ
and	CC


labeling	VBG
percentage	NN
is	VBZ
high	JJ
-LRB-	-LRB-
low	JJ
-RRB-	-RRB-
,	,
the	DT
training	NN
chunk	NN
will	MD
have	VB


a	DT
large	JJ
portion	NN
of	IN
Type	NN
II	CD
-LRB-	-LRB-
IV	CD
-RRB-	-RRB-
examples	NNS
.	.


Learning	NNP
priority	NN
:	:
Generally	RB
,	,
examples	NNS
from	IN
the	DT
target	NN
domain	NN


-LRB-	-LRB-
Types	NNS
I	CD
and	CC
III	CD
-RRB-	-RRB-
are	VBP
capable	JJ
of	IN
capturing	VBG
the	DT
genuine	JJ
concept	NN


of	IN
the	DT
testing	NN
data	NNS
,	,
and	CC
have	VBP
a	DT
higher	JJR
priority	NN
than	IN
examples	NNS


from	IN
similar	JJ
domains	NNS
-LRB-	-LRB-
Types	NNS
II	CD
and	CC
IV	CD
-RRB-	-RRB-
.	.

Besides	IN
,	,
since	IN
Type	NN
I	CD


examples	NNS
are	VBP
labeled	VBN
,	,
they	PRP
have	VBP
a	DT
higher	JJR
priority	NN
than	IN
Type	NN
III	CD


examples	NNS
.	.

Similarly	RB
,	,
Type	NN
II	CD
examples	NNS
have	VBP
a	DT
higher	JJR
priority	NN


than	IN
Type	NN
IV	CD
examples	NNS
.	.


We	PRP
take	VBP
an	DT
example	NN
to	TO
explain	VB
how	WRB
our	PRP$
framework	NN
can	MD
achieve	VB
accuracy	NN
with	IN
efÔ	NN
¨	CD
ciency	NN
in	IN
building	NN
prediction	NN
models	NNS
.	.

If	IN
the	DT
Type	NN
I	CD
examples	NNS
dominate	VBP
the	DT
training	NN
chunk	NN
,	,
according	VBG
to	TO
the	DT
learning	NN
priority	NN
,	,
we	PRP
do	VBP
not	RB
use	VB
the	DT
remaining	VBG
three	CD
types	NNS
of	IN
examples	NNS
for	IN
training	NN
.	.

By	IN
doing	VBG
so	RB
,	,
we	PRP
gain	VBP
in	IN
efÔ	NN
¨	CD
ciency	NN
by	IN
building	VBG
a	DT
simple	JJ
model	NN
,	,
comparing	VBG
to	TO
a	DT
very	RB
complex	JJ
model	NN
if	IN


171	CD


we	PRP
have	VBP
to	TO
learn	VB
from	IN
all	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
.	.

On	IN
the	DT
other	JJ
hand	NN
,	,
the	DT
most	RBS
informative	JJ
examples	NNS
,	,
i.e.	FW
,	,
the	DT
ones	NNS
in	IN
Type	NN
I	CD
,	,
are	VBP
utilized	VBN
in	IN
model	NN
construction	NN
and	CC
the	DT
learning	VBG
accuracy	NN
is	VBZ
not	RB
sacriÔ	JJ
¨	NN
ced	VBD
comparing	VBG
to	TO
some	DT
sophisticated	JJ
model	NN
,	,
e.g.	FW
,	,
TS3VM	NN
,	,
a	DT
very	RB
accurate	JJ
yet	RB
complex	JJ
learning	NN
model	NN
that	IN
we	PRP
propose	VBP
in	IN
this	DT
paper	NN
.	.


Based	VBN
on	IN
the	DT
same	JJ
observation	NN
and	CC
argument	NN
,	,
we	PRP
categorize	VBP
learning	VBG
from	IN
data	NNS
streams	NNS
into	IN
four	CD
cases	NNS
:	:
Type	NN
I	CD
dominates	VBZ
-LRB-	-LRB-
Case	NN
1	CD
-RRB-	-RRB-
,	,
Type	NN
III	CD
dominates	VBZ
-LRB-	-LRB-
Case	NN
2	CD
-RRB-	-RRB-
,	,
Type	NN
II	CD
dominates	VBZ
-LRB-	-LRB-
Case	NNP
3	LS
-RRB-	-RRB-
and	CC
Type	NN
IV	CD
dominates	VBZ
-LRB-	-LRB-
Case	NNP
4	LS
-RRB-	-RRB-
.	.

For	IN
Cases	NNS
1	CD
and	CC
2	CD
,	,
we	PRP
apply	VBP
classical	JJ
SVM	NN
and	CC
semi-supervised	JJ
SVM	NN
,	,
respectively	RB
,	,
for	IN
training	NN
.	.

For	IN
Cases	NNS
3	CD
and	CC
4	CD
,	,
we	PRP
propose	VBP
two	CD
novel	JJ
learning	VBG
models	NNS
,	,
transfer	NN
semi-supervised	JJ
SVM	NN
-LRB-	-LRB-
TS3VM	NN
-RRB-	-RRB-
and	CC
relational	JJ
k-means-based	JJ
TS3VM	NN
-LRB-	-LRB-
RK-TS3VM	NN
-RRB-	-RRB-
,	,
for	IN
training	NN
.	.


The	DT
rest	NN
of	IN
the	DT
paper	NN
is	VBZ
organized	VBN
as	IN
follows	VBZ
:	:
Section	NN
2	CD
introduces	VBZ
categorization	NN
of	IN
training	NN
examples	NNS
and	CC
learning	VBG
cases	NNS
.	.

Sections	NNS
3	CD
describes	VBZ
the	DT
corresponding	JJ
learning	NN
models	NNS
for	IN
the	DT
four	CD
learning	NN
cases	NNS
.	.

Section	NN
4	CD
reports	NNS
experimental	JJ
results	NNS
.	.

Section	NN
5	CD
surveys	NNS
the	DT
related	JJ
work	NN
.	.

We	PRP
conclude	VBP
the	DT
paper	NN
in	IN
Section	NN
6	CD
.	.


2	LS
.	.

Categorization	NN
of	IN
training	NN
examples	NNS
and	CC
learning	VBG
cases	NNS


Consider	VB
a	DT
data	NN
stream	NN
S	NN
consisting	VBG
of	IN
an	DT
inÔ	NN
¨	NN
nite	JJ
sequence	NN
of	IN
examples	NNS
fxi	NNS
,	,
yig	NN
,	,
where	WRB
xiARd	NN
,	,
d	NN
is	VBZ
the	DT
dimensionality	NN
and	CC
yiAf1	NN
,	,
√	NN
3/4	CD
1g	NN
indicates	VBZ
the	DT
class	NN
label	NN
of	IN
xi	NN
.	.

Note	VB
that	DT
yi	NN
may	MD
not	RB
be	VB
always	RB
observed	VBN
.	.

Assume	VB
that	IN
the	DT
stream	NN
S	NN
arrives	VBZ
at	IN
a	DT
speed	NN
of	IN
n	NN
examples	NNS
per	IN
second	NN
.	.

The	DT
decision	NN
boundary	NN
-LRB-	-LRB-
concept	NN
-RRB-	-RRB-
underneath	IN
drifts	NNS
with	IN
a	DT
probability	NN
of	IN
c	NN
,	,
where	WRB
0rcr1	NN
.	.

Besides	IN
,	,
assume	VB
that	DT
at	IN
each	DT
time	NN
stamp	NN
,	,
a	DT
training	NN
chunk	NN
D	NN
¬	NN
1/4	CD
fx1	NN
,	,
...	:
,	,
xng	NN
is	VBZ
buffered	VBN
and	CC
labeled	VBN
by	IN
experts	NNS
with	IN
a	DT
labeling	NN
rate	NN
of	IN
l	NN
per	IN
chunk	NN
where	WRB
0olo1	NN
.	.


Categorization	NN
of	IN
training	NN
examples	NNS
:	:
As	IN
discussed	VBN
previously	RB
,	,
due	JJ
to	TO
the	DT
concept	NN
drifting	VBG
,	,
not	RB
all	DT
examples	NNS
in	IN
the	DT
up-to-date	JJ
chunk	NN
share	NN
the	DT
same	JJ
distribution	NN
with	IN
the	DT
testing	NN
data	NNS
in	IN
the	DT
yet-to-come	JJ
chunk	NN
.	.

In	IN
other	JJ
words	NNS
,	,
examples	NNS
in	IN
the	DT
up-to-date	JJ
chunk	NN
could	MD
be	VB
generated	VBN
from	IN
some	DT
similar	JJ
domain	NN
instead	RB
of	IN
the	DT
target	NN
domain	NN
.	.

Besides	IN
,	,
since	IN
it	PRP
is	VBZ
impractical	JJ
to	TO
label	VB
all	DT
examples	NNS
in	IN
the	DT
up-to-date	JJ
training	NN
chunk	NN
,	,
the	DT
training	NN
chunk	NN
will	MD
contain	VB
both	DT
labeled	VBN
and	CC
unlabeled	JJ
examples	NNS
.	.

By	IN
combining	VBG
these	DT
two	CD
factors	NNS
,	,
we	PRP
categorize	VBP
training	NN
examples	NNS
in	IN
data	NNS
streams	NNS
into	IN
four	CD
types	NNS
.	.


DeÔ	NN
¨	CD
nition	NN
-LRB-	-LRB-
Four	CD
types	NNS
of	IN
training	NN
examples	NNS
-RRB-	-RRB-
.	.

In	IN
an	DT
up-to-date	JJ
training	NN
chunk	NN
,	,
there	EX
are	VBP
four	CD
types	NNS
of	IN
examples	NNS
:	:
labeled	VBN
and	CC
from	IN
the	DT
target	NN
domain	NN
-LRB-	-LRB-
Type	NN
I	CD
-RRB-	-RRB-
,	,
labeled	VBN
and	CC
from	IN
a	DT
similar	JJ
domain	NN
-LRB-	-LRB-
Type	NN
II	CD
-RRB-	-RRB-
,	,
unlabeled	JJ
and	CC
from	IN
the	DT
target	NN
domain	NN
-LRB-	-LRB-
Type	NN
III	CD
-RRB-	-RRB-
and	CC
unlabeled	JJ
and	CC
from	IN
a	DT
similar	JJ
domain	NN
-LRB-	-LRB-
Type	NN
IV	CD
-RRB-	-RRB-
.	.


Fig.	NN
2	CD
illustrates	VBZ
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
,	,
where	WRB
blue	JJ
solid	JJ
circles	NNS
denote	VBP
the	DT
Type	NN
I	CD
examples	NNS
,	,
red	JJ
solid	JJ
circles	NNS
denote	VBP
the	DT
Type	NN
II	CD
examples	NNS
,	,
blue	JJ
hollow	JJ
circles	NNS
denote	VBP
the	DT
Type	NN
III	CD
examples	NNS
,	,
and	CC
red	JJ
hollow	JJ
circles	NNS
denote	VBP
the	DT
Type	NN
IV	CD
examples	NNS
.	.

Due	JJ
to	TO
the	DT
temporal	JJ
correlation	NN
of	IN
concepts	NNS
-LSB-	-LRB-
18	CD
-RSB-	-RRB-
,	,
Type	NN
I	CD
and	CC
III	CD
examples	NNS
are	VBP
usually	RB
located	VBN
at	IN
the	DT
tail	NN
of	IN
a	DT
training	NN
chunk	NN
and	CC
close	NN
to	TO
the	DT
yet-to-come	JJ
chunk	NN
.	.

Type	NN
II	CD
and	CC
IV	CD
examples	NNS
are	VBP
usually	RB
located	VBN
at	IN
the	DT
head	NN
of	IN
a	DT
training	NN
chunk	NN
and	CC
relatively	RB
far	RB
away	RB
from	IN
the	DT
yet-to-come	JJ
chunk	NN
.	.


Estimation	NN
of	IN
number	NN
of	IN
examples	NNS
:	:
By	IN
estimating	VBG
the	DT
number	NN
of	IN
examples	NNS
of	IN
each	DT
type	NN
,	,
we	PRP
can	MD
gain	VB
insights	NNS
into	IN
the	DT
training	NN
chunk	NN
and	CC
apply	VB
an	DT
appropriate	JJ
learning	NN
model	NN
.	.

Intuitively	RB
,	,
the	DT
percentage	NN
of	IN
labeled	VBN
examples	NNS
depends	VBZ
on	IN
how	WRB
fast	JJ
labeling	NN
can	MD
be	VB
done	VBN
by	IN
the	DT
experts	NNS
,	,
and	CC
the	DT
number	NN
of	IN
target	NN
domain	NN
examples	NNS
depends	VBZ
on	IN
the	DT
concept	NN
drifting	VBG
probability	NN
.	.

By	IN
considering	VBG
the	DT
two	CD
factors	NNS
,	,
the	DT
number	NN
of	IN
examples	NNS
of	IN
each	DT
type	NN
can	MD
be	VB
estimated	VBN
as	IN
follows	VBZ
.	.



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
2	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



172	CD


P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


Historical	JJ
stream	NN
data	NNS


Up-to-date	JJ
chunk	NN
Yet-to-come	NN
chunk	NN


‚	RB
$	$
¶	CD
‚	NN
$	$
¶	CD


Training	VBG
chunk	NN


Test	NN
chunk	NN


Type	NN
I	CD


Type	NN
IV	CD


Type	NN
II	CD


Type	NN
III	CD


Fig.	NN
2	CD
.	.

An	DT
illustration	NN
of	IN
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
in	IN
an	DT
up-to-date	JJ
training	NN
chunk	NN
.	.

-LRB-	-LRB-
For	IN
interpretation	NN
of	IN
the	DT
references	NNS
to	TO
color	NN
in	IN
this	DT
Ô	NN
¨	NN
gure	NN
legend	NN
,	,
the	DT
reader	NN
is	VBZ
referred	VBN
to	TO
the	DT
web	NN
version	NN
of	IN
this	DT
article	NN
.	.
-RRB-	-RRB-


Theorem	NNP
1	CD
.	.

Let	VB
L1	NN
,	,
L2	NN
,	,
L3	NN
and	CC
L4	NN
be	VB
the	DT
number	NN
of	IN
examples	NNS
of	IN
Type	NN
I	CD
,	,
Type	NN
II	CD
,	,
Type	NN
III	CD
and	CC
Type	NN
IV	CD
respectively	RB
in	IN
the	DT
up-to-date	JJ
chunk	NN
.	.

Then	RB


L1pg	NN
c1	NN
l	NN
n	NN


L2p√	NN
∞	CD
1g	NN
c1√ûl	NN
n	NN


L3pg	NN
c1	NN
1l√ûn	NN


L4p√	NN
∞	CD
1g	NN
c1√û1l√ûn	NN


where	WRB
g40	NN
is	VBZ
a	DT
constant	JJ
coefÔ	NN
¨	NN
cient	NN
.	.


√	NN
∞	CD
1√û	NN


Proof	NN
.	.

Recall	VB
that	DT
stream	NN
S	NN
Ô	NN
¨	CD
Ç	CD
ows	NNS
at	IN
a	DT
speed	NN
of	IN
n	NN
examples	NNS
per	IN
second	JJ
,	,
the	DT
concept	NN
drifting	VBG
probability	NN
is	VBZ
c	NN
,	,
and	CC
the	DT
labeling	NN
rate	NN
is	VBZ
l	NN
.	.

The	DT
number	NN
of	IN
target	NN
domain	NN
examples	NNS
is	VBZ
inversely	RB
proportional	JJ
to	TO
the	DT
concept	NN
drifting	VBG
rate	NN
c	NN
with	IN
a	DT
coefÔ	NN
¨	NN
cient	NN
of	IN
g	NN
,	,
so	IN
it	PRP
can	MD
be	VB
easily	RB
estimated	VBN
that	IN
gc1	NN
n	NN
examples	NNS
in	IN
the	DT
up-to	JJ
-	:
date	NN
chunk	NN
have	VBP
the	DT
same	JJ
distribution	NN
as	IN
the	DT
testing	NN
data	NNS
.	.

The	DT
remaining	VBG
√	NN
∞	CD
1g	NN
c1√ûn	NN
examples	NNS
have	VBP
a	DT
similar	JJ
distribution	NN
to	TO
the	DT
testing	NN
examples	NNS
.	.

From	IN
the	DT
estimates	NNS
the	DT
theorem	NN
follows	VBZ
immediately	RB
.	.

&	CC


Learning	NNP
priority	NN
:	:
Not	RB
all	PDT
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
have	VBP
to	TO
be	VB
used	VBN
in	IN
model	NN
construction	NN
.	.

For	IN
example	NN
,	,
consider	VB
a	DT
data	NN
stream	NN
where	WRB
the	DT
concept	NN
drifting	VBG
is	VBZ
low	JJ
and	CC
the	DT
labeling	NN
rate	NN
is	VBZ
high	JJ
,	,
the	DT
training	NN
chunk	NN
will	MD
have	VB
a	DT
large	JJ
portion	NN
of	IN
Type	NN
I	CD
examples	NNS
.	.

In	IN
this	DT
case	NN
,	,
we	PRP
are	VBP
able	JJ
to	TO
build	VB
a	DT
satisfactory	JJ
model	NN
by	IN
training	NN
only	RB
on	IN
the	DT
Type	NN
I	CD
examples	NNS
.	.

We	PRP
observe	VBP
that	IN
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
have	VBP
the	DT
following	VBG
learning	NN
priorities	NNS
.	.


Observation	NN
1	CD
.	.

The	DT
learning	NN
priority	NN
of	IN
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
is	VBZ


Type	NN
I4Type	NN
III4Type	NN
II4Type	NN
IV	CD


√	NN
∞	CD
2√û	NN


What	WP
is	VBZ
the	DT
intuition	NN
behind	IN
Observation	NN
1	CD
?	.

Generally	RB
,	,
exam	NN
-	:
ples	NNS
from	IN
the	DT
target	NN
domain	NN
-LRB-	-LRB-
Types	NNS
I	CD
and	CC
III	CD
-RRB-	-RRB-
are	VBP
capable	JJ
of	IN
capturing	VBG
the	DT
genuine	JJ
concept	NN
of	IN
the	DT
testing	NN
data	NNS
,	,
and	CC
thus	RB
have	VBP
a	DT
high	JJ
priority	NN
than	IN
examples	NNS
from	IN
similar	JJ
domains	NNS
-LRB-	-LRB-
Types	NNS
II	CD
and	CC
IV	CD
-RRB-	-RRB-
.	.

Besides	IN
,	,
since	IN
Type	NN
I	CD
examples	NNS
are	VBP
labeled	VBN
,	,
they	PRP
have	VBP
a	DT
higher	JJR
priority	NN
than	IN
Type	NN
III	CD
examples	NNS
.	.

Similarly	RB
,	,
Type	NN
II	CD
examples	NNS
have	VBP
a	DT
higher	JJR
priority	NN
than	IN
Type	NN
IV	CD
examples	NNS
.	.


Based	VBN
on	IN
Observation	NN
1	CD
,	,
when	WRB
a	DT
particular	JJ
type	NN
dominates	VBZ
the	DT
training	NN
examples	NNS
,	,
examples	NNS
with	IN
lower	JJR
priorities	NNS
will	MD
not	RB
be	VB
used	VBN
for	IN
training	NN
.	.

For	IN
example	NN
,	,
if	IN
Type	NN
III	CD
dominates	VBZ
the	DT
training	NN
examples	NNS
,	,
only	RB
Type	NN
I	CD
and	CC
Type	NN
III	CD
examples	NNS
will	MD
be	VB
used	VBN
for	IN
training	NN
.	.

This	DT
is	VBZ
because	IN
Type	NN
I	CD
examples	NNS
have	VBP
a	DT
higher	JJR
priority	NN
than	IN
Type	NN
III	CD
examples	NNS
,	,
and	CC
the	DT
remaining	VBG
two	CD
types	NNS
have	VBP
lower	JJR
priorities	NNS
.	.

By	IN
doing	VBG
so	RB
,	,
we	PRP
gain	VBP
in	IN
efÔ	NN
¨	CD
ciency	NN
by	IN
building	VBG
a	DT
simple	JJ
model	NN
,	,
comparing	VBG
to	TO
a	DT
very	RB
complex	JJ
model	NN
if	IN
we	PRP
have	VBP
to	TO
learn	VB
from	IN
all	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
.	.

On	IN
the	DT
other	JJ
hand	NN
,	,
the	DT


II	NNP


I	PRP


II	NNP


I	PRP


IV	CD


III	NNP


IV	CD


III	NNP


II	NNP


I	PRP


II	NNP


I	PRP


IV	CD


III	NNP


IV	CD


III	NNP


Fig.	NN
3	CD
.	.

The	DT
proportion	NN
of	IN
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
with	IN
respect	NN
to	TO
different	JJ
labeling	NN
rate	NN
l	NN
and	CC
concept	NN
drifting	VBG
probability	NN
c.	NN
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
l	NN
is	VBZ
high	JJ
and	CC
c	NN
is	VBZ
low	JJ
.	.

Case	NNP
1	CD
,	,
-LRB-	-LRB-
b	LS
-RRB-	-RRB-
both	CC
l	NN
and	CC
c	NN
are	VBP
low	JJ
.	.

Case	NN
2	CD
,	,
-LRB-	-LRB-
c	NN
-RRB-	-RRB-
Both	CC
l	NN
and	CC
l	NN
are	VBP
high	JJ
.	.

Case	NNP
3	CD
and	CC
-LRB-	-LRB-
d	LS
-RRB-	-RRB-
l	NN
is	VBZ
low	JJ
and	CC
c	NN
is	VBZ
high	JJ
.	.

Case	NNP
4	CD
.	.


most	RBS
informative	JJ
examples	NNS
are	VBP
utilized	VBN
in	IN
model	NN
construction	NN
and	CC
the	DT
learning	VBG
accuracy	NN
is	VBZ
not	RB
sacriÔ	JJ
¨	NN
ced	VBD
.	.


Learning	NNP
cases	NNS
:	:
Aiming	VBG
at	IN
both	DT
accuracy	NN
and	CC
efÔ	NN
¨	CD
ciency	NN
in	IN
learning	VBG
prediction	NN
models	NNS
,	,
we	PRP
categorize	VBP
learning	VBG
from	IN
data	NNS
streams	NNS
into	IN
the	DT
following	VBG
four	CD
cases	NNS
:	:


Case	NNP
1	CD
:	:
Type	NN
I	CD
dominates	VBZ
.	.

When	WRB
labeling	VBG
rate	NN
is	VBZ
high	JJ
and	CC
the	DT


concept	NN
drifting	VBG
probability	NN
is	VBZ
low	JJ
,	,
Type	NN
I	CD
dominates	VBZ
the	DT


training	NN
examples	NNS
.	.

In	IN
this	DT
case	NN
,	,
we	PRP
can	MD
train	VB
a	DT
satisfactory	JJ


model	NN
by	IN
using	VBG
only	RB
Type	NN
I	CD
examples	NNS
.	.


Case	NN
2	CD
:	:
Type	NN
III	CD
dominates	VBZ
.	.

When	WRB
both	DT
labeling	NN
rate	NN
and	CC


concept	NN
drifting	VBG
probability	NN
are	VBP
low	JJ
,	,
Type	NN
III	CD
dominates	VBZ
the	DT


training	NN
examples	NNS
.	.

According	VBG
to	TO
the	DT
learning	NN
priority	NN
,	,
it	PRP
is	VBZ


necessary	JJ
to	TO
combine	VB
both	CC
Type	NN
I	CD
and	CC
Type	NN
III	CD
examples	NNS
for	IN


training	NN
.	.


Case	NNP
3	CD
:	:
Type	NN
II	CD
dominates	VBZ
.	.

When	WRB
both	DT
labeling	NN
rate	NN
and	CC


concept	NN
drifting	VBG
probability	NN
are	VBP
high	JJ
,	,
Type	NN
II	CD
dominates	VBZ
the	DT


training	NN
examples	NNS
,	,
and	CC
we	PRP
will	MD
use	VB
Type	NN
I	CD
,	,
Type	NN
II	CD
and	CC
Type	NN
III	CD


examples	NNS
for	IN
training	NN
.	.


Case	NNP
4	CD
:	:
Type	NN
IV	CD
dominates	VBZ
.	.

When	WRB
labeling	VBG
rate	NN
is	VBZ
low	JJ
and	CC
the	DT


concept	NN
drifting	VBG
probability	NN
is	VBZ
high	JJ
,	,
Type	NN
IV	CD
dominates	VBZ
the	DT


training	NN
examples	NNS
.	.

This	DT
is	VBZ
the	DT
most	RBS
difÔ	JJ
¨	NN
cult	NN
case	NN
because	IN
most	JJS


examples	NNS
are	VBP
unlabeled	JJ
and	CC
not	RB
from	IN
the	DT
target	NN
domain	NN
.	.


According	VBG
to	TO
the	DT
learning	NN
priority	NN
,	,
we	PRP
need	VBP
to	TO
use	VB
all	PDT
the	DT
four	CD


types	NNS
of	IN
training	NN
examples	NNS
for	IN
training	NN
.	.


These	DT
learning	VBG
cases	NNS
are	VBP
further	JJ
illustrated	VBD
in	IN
Fig.	NNP
3	CD
.	.


3	LS
.	.

Learning	NNP
models	NNS


We	PRP
have	VBP
introduced	VBN
the	DT
four	CD
learning	NN
cases	NNS
.	.

In	IN
this	DT
section	NN
,	,
we	PRP
present	VBP
their	PRP$
corresponding	JJ
learning	NN
models	NNS
.	.


Throughout	IN
the	DT
section	NN
,	,
T1	NN
¬	NN
1/4	CD
√	NN
∞	CD
x1	NN
,	,
y1√û	NN
,	,
...	:
,	,
√	NN
∞	CD
xL	NN


1	CD


,	,
yL	NN
√û	NN
denotes	VBZ
the	DT


1	CD


set	NN
of	IN
Type	NN
I	CD
examples	NNS
.	.

T2	NN
¬	NN
1/4	CD
f√	NN
∞	CD
xL	NN


1	CD


√	NN
3/4	CD
1	CD
,	,
yL1	NN
√	NN
3/4	CD
1√û	NN
,	,


...	:
,	,
√	NN
∞	CD
xL	NN
,	,
yL√ûgdenotes	VBZ
the	DT
set	NN
of	IN
Type	NN
II	CD
examples	NNS
,	,
where	WRB
L	NN
¬	NN
1/4	CD
L1√	NN
3/4	CD
L2	NN
.	.

T3	NN
¬	NN
1/4	CD
fxL√	NN
3/4	CD
1	CD
,	,
...	:
,	,
xL√	NN
3/4	CD
Ug	NN
denotes	VBZ
the	DT
set	NN
of	IN
Type	NN
III	CD
examples	NNS
,	,
where	WRB
U	NNP
is	VBZ
the	DT
set	NN
of	IN
unlabeled	JJ
examples	NNS
.	.

T4	NN
¬	NN
1/4	CD
fxL√	NN
3/4	CD
U√	NN
3/4	CD
1	CD
,	,
...	:
,	,
xL√	NN
3/4	CD
U√	NN
3/4	CD
Ngdenotes	NNS
the	DT
set	NN
of	IN
Type	NN
IV	CD
examples	NNS
,	,
where	WRB
N	NN
is	VBZ
the	DT
set	NN
of	IN
unlabeled	JJ
examples	NNS
.	.


3.1	CD
.	.

Case	NNP
1	CD
:	:
Type	NN
I	CD
dominates	VBZ


In	IN
this	DT
case	NN
,	,
Type	NN
I	CD
examples	NNS
T1	NN
dominate	VB
the	DT
training	NN
chunk	NN
and	CC
has	VBZ
the	DT
highest	JJS
learning	NN
priority	NN
.	.

Thus	RB
,	,
only	RB
T1	NN
will	MD
be	VB
used	VBN
for	IN
training	NN
.	.

Formally	RB
,	,
to	TO
learn	VB
from	IN
T1	NN
¬	NN
1/4	CD
f√	NN
∞	CD
x1	NN
,	,
y1√û	NN
,	,
...	:
,	,
√	NN
∞	CD
xL	NN


1	CD


,	,
yL	NN
√ûg	NN
,	,


1	CD
a	DT
generic	JJ
SVM	NN
model	NN
can	MD
be	VB
trained	VBN
by	IN
maximizing	VBG
the	DT
margin	NN



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
3	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


Fig.	NN
4	CD
.	.

An	DT
illustration	NN
of	IN
the	DT
Hinge	NNP
loss	NN
function	NN
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
H√	NN
∞	CD
t√û¬	NN
1/4	CD
max√	NN
∞	NN
0	CD
;	:
1t√û	NN
,	,
and	CC
the	DT
Symmetric	JJ
Hinge	NN
loss	NN
function	NN
-LRB-	-LRB-
b	NN
-RRB-	-RRB-
H√	NN
∞	CD
t√û¬	NN
1/4	CD
max√	NN
∞	NN
0	CD
;	:
19t9√û	NN
.	.

The	DT
Hinge	NNP
loss	NN
function	NN
is	VBZ
equivalent	JJ
to	TO
the	DT
following	VBG
optimization	NN
problem	NN
:	:
min	NN
x	NN
,	,
s	NNS
:	:
t	NN
:	:
:	:
xZ0	NN
,	,
xZ1t	NN
.	.


distance	NN
between	IN
classes	NNS
while	IN
minimizing	VBG
the	DT
error	NN
rates	NNS
as	IN


XL	NNP
min	NN


1JwJ2	NN


1	CD


2	CD


√	NN
3/4	CD
C	NN
xi	NN


i	LS
¬	NN
1/4	CD
1	CD


s	NNS
:	:
t	NN
:	:
:	:
yi√	NN
∞	CD
wxi√	NN
3/4	CD
b√ûZ1xi	NN


xiZ0	NN
,	,
1rirL1	NN


√	NN
∞	CD
3√û	NN


where	WRB
w	NN
is	VBZ
the	DT
projection	NN
direction	NN
,	,
b	NN
is	VBZ
the	DT
classiÔ	NN
¨	NN
cation	NN
boundary	NN
,	,
xi	NN
is	VBZ
the	DT
error	NN
distance	NN
from	IN
xi	NN
to	TO
b	NN
,	,
and	CC
parameter	NN
C	NN
is	VBZ
the	DT
penalty	NN
for	IN
the	DT
examples	NNS
inside	IN
the	DT
margin	NN
.	.


The	DT
SVM	NNP
model	NN
given	VBN
in	IN
Eq	NN
.	.

-LRB-	-LRB-
3	LS
-RRB-	-RRB-
is	VBZ
a	DT
constrained	VBN
convex	NN
optimization	NN
problem	NN
.	.

To	TO
simplify	VB
the	DT
expression	NN
,	,
the	DT
Hinge	NNP
loss	NN
function	NN
-LSB-	-LRB-
8	CD
-RSB-	-RRB-
in	IN
Fig.	NN
4	CD
can	MD
be	VB
used	VBN
to	TO
transform	VB
Eq	NN
.	.

-LRB-	-LRB-
3	LS
-RRB-	-RRB-
into	IN
an	DT
unconstrained	JJ
convex	NN
optimization	NN
problem	NN
as	IN


miny	NN


1JwJ2	NN


XL	NNP
1	CD


2	CD


√	NN
3/4	CD
C	NN
H√	NN
∞	CD
yify√	NN
∞	CD
xi√û√û	NN
√	NN
∞	CD
4√û	NN


i	LS
¬	NN
1/4	CD
1	CD


where	WRB
y¬	NN
1/4	CD
√	NN
∞	CD
w	NN
,	,
b√ûand	NN
fy√	NN
∞	CD
x√û¬	NN
1/4	CD
√	NN
∞	CD
wx√	NN
3/4	CD
b√û	NN
.	.


3.2	CD
.	.

Case	NN
2	CD
:	:
Type	NN
III	CD
dominates	VBZ


In	IN
this	DT
case	NN
,	,
Type	NN
III	CD
examples	NNS
T3	NN
dominate	VB
the	DT
training	NN
chunk	NN
and	CC
Type	NN
I	CD
examples	NNS
T1	NN
have	VBP
a	DT
higher	JJR
learning	NN
priority	NN
than	IN
Type	NN
III	CD
examples	NNS
.	.

Thus	RB
,	,
both	DT
T1	NN
and	CC
T3	NN
will	MD
be	VB
used	VBN
for	IN
training	NN
.	.


Learning	NNP
from	IN
T1	NN
and	CC
T3	NN
is	VBZ
a	DT
semi-supervised	JJ
learning	NN
problem	NN
-LSB-	-LRB-
27	CD
-RSB-	-RRB-
.	.

Generally	RB
speaking	VBG
,	,
adding	VBG
unlabeled	JJ
T3	NN
examples	NNS
into	IN
learning	VBG
will	MD
further	RB
improve	VB
the	DT
performance	NN
for	IN
the	DT
following	VBG
reasons	NNS
:	:
-LRB-	-LRB-
1	LS
-RRB-	-RRB-
labeled	VBN
examples	NNS
in	IN
T1	NN
are	VBP
too	RB
few	JJ
to	TO
build	VB
a	DT
satisfactory	JJ
model	NN
.	.

-LRB-	-LRB-
2	LS
-RRB-	-RRB-
T3	NN
contains	VBZ
a	DT
relatively	RB
large	JJ
number	NN
of	IN
examples	NNS
that	WDT
come	VBP
from	IN
the	DT
target	NN
domain	NN
,	,
which	WDT
can	MD
greatly	RB
help	VB
in	IN
differentiating	VBG
the	DT
genuine	JJ
classiÔ	NN
¨	NN
cation	NN
boundaries	NNS
.	.


Formally	RB
,	,
in	IN
order	NN
to	TO
learn	VB
from	IN
both	DT
T1	NN
and	CC
T3	NN
,	,
semi-super	NN
-	:
vised	VBN
SVM	NN
-LRB-	-LRB-
S3VM	NN
-RRB-	-RRB-
-LSB-	-LRB-
7	CD
-RSB-	-RRB-
can	MD
be	VB
used	VBN
as	IN
the	DT
learning	NN
model	NN
.	.

The	DT
logic	NN
behind	IN
S3VM	NN
is	VBZ
to	TO
Ô	VB
¨	CD
nd	VBD
a	DT
classiÔ	NN
¨	NN
cation	NN
boundary	NN
that	WDT
achieves	VBZ
a	DT
maximum	JJ
margin	NN
not	RB
only	RB
between	IN
labeled	JJ
examples	NNS
,	,
but	CC
alsoPL√	NNP
3/4	CD
U	NNP
unlabeled	JJ
examples	NNS
.	.

That	DT
is	VBZ
,	,
adding	VBG
an	DT
extra	JJ
term	NN
Cn	NN


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD


H	NN
√	NN
∞	CD
9fy√	NN
∞	CD
xi√û9√û	NN
to	TO
penalize	VB
the	DT
misclassiÔ	NN
¨	NN
cation	NN
of	IN
unlabeled	JJ
examples	NNS
located	JJ
inside	IN
the	DT
margin	NN
as	IN


LX√	NN
3/4	CD
U	NNP


173	CD


where	WRB
L	NN
denotes	VBZ
the	DT
number	NN
of	IN
labeled	VBN
examples	NNS
and	CC
U	NNP
denotes	VBZ
the	DT
number	NN
of	IN
unlabeled	JJ
examples	NNS
.	.


By	IN
taking	VBG
account	NN
of	IN
the	DT
balance	NN
constraint	NN
,	,
we	PRP
can	MD
derive	VB
a	DT
modiÔ	NN
¨	NN
ed	VBD
semi-supervised	JJ
SVM	NNP
model	NN
as	IN


LX√	NN
3/4	CD
U	NNP


miny	NN


1JwJ2	NN


XL	NNP
1	CD


2	CD


√	NN
3/4	CD
C	NN
H√	NN
∞	CD
yify√	NN
∞	CD
xi√û√û√	NN
3/4	CD
Cn	NN


i	LS
¬	NN
1/4	CD
1	CD


H√	NN
∞	CD
9fy√	NN
∞	CD
xi√û9√û	NN


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD


s	NNS
:	:
t	NN
:	:
:	:


1	CD


LX√	NN
3/4	CD
U	NNP


fy√	NN
∞	CD
xi√û¬	NN
1/4	CD


1	CD


XL	NNP
1	CD
U	NNP
L	NNP


yi1	NN


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD
i	FW
¬	FW
1/4	CD
1	CD


√	NN
∞	CD
7√û	NN


where	WRB
y¬	NN
1/4	CD
√	NN
∞	CD
w	NN
,	,
b√û	NN
.	.


Obviously	RB
,	,
Eq	NN
.	.

-LRB-	-LRB-
7	CD
-RRB-	-RRB-
is	VBZ
a	DT
standard	JJ
S3VM	NN
model	NN
and	CC
can	MD
be	VB
easily	RB
solved	VBN
by	IN
using	VBG
off-the-shelf	JJ
tools	NNS
-LSB-	-LRB-
19	CD
-RSB-	-RRB-
.	.


3.3	CD
.	.

Case	NNP
3	CD
:	:
Type	NN
II	CD
dominates	VBZ


In	IN
this	DT
case	NN
,	,
Type	NN
II	CD
examples	NNS
T2	NN
dominate	VB
the	DT
training	NN
chunk	NN
,	,
and	CC
Type	NN
I	CD
and	CC
Type	NN
III	CD
examples	NNS
T1	NN
and	CC
T3	NN
have	VBP
higher	JJR
learning	VBG
priorities	NNS
than	IN
Type	NN
II	CD
examples	NNS
.	.

Thus	RB
,	,
T1	NN
,	,
T2	NN
and	CC
T3	NN
will	MD
be	VB
used	VBN
for	IN
training	NN
.	.


Accurately	RB
learning	VBG
from	IN
these	DT
three	CD
types	NNS
of	IN
examples	NNS
is	VBZ
non	JJ
-	:
trivial	JJ
.	.

For	IN
this	DT
purpose	NN
,	,
we	PRP
design	VBP
a	DT
novel	JJ
transfer	NN
semi-super	NN
-	:
vised	VBN
SVM	NNP
model	NN
-LRB-	-LRB-
TS3VM	NN
for	IN
short	JJ
-RRB-	-RRB-
.	.

Intuitively	RB
,	,
the	DT
TS3VM	NN
model	NN
can	MD
be	VB
formulated	VBN
by	IN
incorporating	VBG
examples	NNS
in	IN
T1	NN
,	,
T2	NN
and	CC
T3	NN
sequentially	RB
.	.

SpeciÔ	NN
¨	NN
cally	RB
,	,
we	PRP
can	MD
Ô	VB
¨	CD
rst	NN
formulate	VBP
a	DT
generic	JJ
SVM	NN
model	NN
by	IN
taking	VBG
T1	NN
into	IN
consideration	NN
.	.

Then	RB
,	,
a	DT
transfer	NN
SVM	NN
model	NN
can	MD
be	VB
formulated	VBN
by	IN
taking	VBG
T2	NN
into	IN
consideration	NN
.	.

Finally	RB
,	,
we	PRP
can	MD
include	VB
T2	NN
and	CC
formulate	VB
the	DT
TS3VM	NN
model	NN
.	.


Learning	NNP
from	IN
T1	NN
has	VBZ
been	VBN
discussed	VBN
in	IN
Eq	NN
.	.

-LRB-	-LRB-
4	LS
-RRB-	-RRB-
,	,
based	VBN
on	IN
which	WDT
T2	NN
can	MD
be	VB
incorporated	VBN
by	IN
applying	VBG
the	DT
transfer	NN
learning	NN
strategy	NN
.	.

Practically	RB
,	,
transfer	NN
learning	NN
can	MD
use	VB
labeled	JJ
examples	NNS
in	IN
T2	NN
to	TO
reÔ	NN
¨	CD
ne	NN
the	DT
classiÔ	NN
¨	NN
cation	NN
boundary	NN
by	IN
transferring	VBG
the	DT
knowledge	NN
from	IN
T2	NN
to	TO
T1	NN
.	.

An	DT
effective	JJ
way	NN
of	IN
doing	VBG
so	RB
is	VBZ
to	TO
consider	VB
the	DT
problem	NN
as	IN
a	DT
multi-task	JJ
learning	NN
procedure	NN
-LSB-	-LRB-
13	CD
-RSB-	-RRB-
.	.

A	DT
common	JJ
two-task	JJ
learning	NN
SVM	NN
model	NN
on	IN
T1	NN
and	CC
T2	NN
can	MD
be	VB
formulated	VBN
as	IN


XL	NNP
min	NN


1JwJ2√	NN
3/4	CD
C1Jv1J2√	NN
3/4	CD
C2Jv2J2	NN


2	CD


√	NN
3/4	CD
C	NN
xi	NN


i	LS
¬	NN
1/4	CD
1	CD


s	NNS
:	:
t	NN
:	:
:	:
yi√	NN
∞	CD
√	NN
∞	CD
w√	NN
3/4	CD
v1√ûxi√	NN
3/4	CD
b√ûZ1xi	NN
,	,
1rirL1	NN


yi√	NN
∞	CD
√	NN
∞	CD
w√	NN
3/4	CD
v2√ûxi√	NN
3/4	CD
b√ûZ1xi	NN
,	,
L1√	NN
3/4	CD
1rirL	NN


xiZ0	NN
,	,
1rirL	NN


√	NN
∞	CD
8√û	NN


where	WRB
parameters	NNS
C1	NN
and	CC
C2	NN
are	VBP
the	DT
penalties	NNS
on	IN
the	DT
two	CD
tasks	NNS
,	,
and	CC
v1	NN
and	CC
v2	NN
are	VBP
the	DT
discrepancies	NNS
between	IN
the	DT
global	JJ
optimal	JJ
decision	NN
boundary	NN
w	NN
and	CC
the	DT
local	JJ
optimal	JJ
decision	NN
boundary	NN
-LRB-	-LRB-
i.e.	FW
,	,
w√	NN
3/4	CD
v1	NN
for	IN
the	DT
task	NN
of	IN
learning	VBG
from	IN
T1	NN
and	CC
w√	NN
3/4	CD
v2	NN
for	IN
the	DT
task	NN
of	IN
learning	VBG
from	IN
T2	NN
-RRB-	-RRB-
.	.


In	IN
Eq	NN
.	.

-LRB-	-LRB-
8	CD
-RRB-	-RRB-
,	,
parameters	NNS
C1	NN
and	CC
C2	NN
control	VBP
the	DT
preference	NN
between	IN
the	DT
two	CD
tasks	NNS
.	.

If	IN
C14C2	NN
,	,
task	NN
1	CD
is	VBZ
preferred	VBN
over	IN
task	NN
2	CD
;	:
otherwise	RB
,	,
task	NN
2	CD
is	VBZ
preferred	VBN
over	IN
task	NN
1	CD
.	.

The	DT
relationship	NN
between	IN
C1	NN
and	CC
C2	NN
is	VBZ
furthered	VBN
studied	VBN
in	IN
the	DT
Experiments	NNS


miny	NN


1JwJ2	NN


XL	NNP
1	CD


2	CD


√	NN
3/4	CD
C	NN
H√	NN
∞	CD
yify√	NN
∞	CD
xi√û√û√	NN
3/4	CD
Cn	NN


i	LS
¬	NN
1/4	CD
1	CD


H√	NN
∞	CD
9fy√	NN
∞	CD
xi√û9√û√	NN
∞	CD
5√ûsection	NN
.	.

By	IN
using	VBG
the	DT
Hinge	NNP
loss	NN
function	NN
,	,
Eq	NN
.	.

-LRB-	-LRB-
8	CD
-RRB-	-RRB-
can	MD
be	VB
trans	JJ
-	:


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD


Balance	NN
constraint	NN
:	:
A	DT
possible	JJ
limitation	NN
of	IN
the	DT
TS3VM	NN
model	NN
is	VBZ
that	IN
all	DT
unlabeled	JJ
examples	NNS
in	IN
T3	NN
may	MD
be	VB
classiÔ	JJ
¨	NN
ed	VBD
into	IN
one	CD
class	NN
with	IN
a	DT
very	RB
large	JJ
margin	NN
,	,
leading	VBG
to	TO
deteriorated	JJ
performance	NN
.	.

To	TO
address	VB
this	DT
issue	NN
,	,
an	DT
additional	JJ
balance	NN
constraint	NN
should	MD
be	VB
added	VBN
to	TO
ensure	VB
that	IN
unlabeled	JJ
examples	NNS
in	IN
T3	NN
be	VB
assigned	VBN
into	IN
both	CC
classes	NNS
.	.

In	IN
the	DT
case	NN
that	IN
we	PRP
do	VBP
not	RB
have	VB
any	DT
prior	JJ
knowledge	NN
about	IN
the	DT
class	NN
ratio	NN
in	IN
T3	NN
,	,
a	DT
reasonable	JJ
approach	NN
-LSB-	-LRB-
8	CD
-RSB-	-RRB-
is	VBZ
to	TO
estimate	VB
its	PRP$
class	NN
ratio	NN
from	IN
T1	NN
and	CC
T2	NN
as	IN


1	CD


LX√	NN
3/4	CD
U	NNP


fy√	NN
∞	CD
xi√û¬	NN
1/4	CD


1	CD


XL	NNP
1	CD
U	NNP
L	NNP


yi1	NN


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD
i	FW
¬	FW
1/4	CD
1	CD


√	NN
∞	CD
6√û	NN


formed	VBN
into	IN
an	DT
unconstrained	JJ
form	NN


miny	NN


1JwJ2√	NN
3/4	CD
C1JV1J2√	NN
3/4	CD
C2JV	NN


2	CD


XL	NNP


2	CD


2J	NN


√	NN
3/4	CD
C	NN
H√	NN
∞	CD
yify√	NN
∞	CD
xi√û√û	NN
√	NN
∞	CD
9√û	NN


i	LS
¬	NN
1/4	CD
1	CD


where	WRB
y¬	NN
1/4	CD
√	NN
∞	CD
w	NN
,	,
v1	NN
,	,
v2	NN
,	,
b√û	NN
,	,
fy√	NN
∞	CD
x√û¬	NN
1/4	CD
√	NN
∞	CD
w√	NN
3/4	CD
v1√ûx√	NN
3/4	CD
b	NN
for	IN
task	NN
1	CD
and	CC
fy√	NN
∞	CD
x√û¬	NN
1/4	CD
√	NN
∞	CD
w√	NN
3/4	CD
v2√ûx√	NN
3/4	CD
b	NN
for	IN
task	NN
2	CD
.	.


In	IN
addition	NN
to	TO
T1	NN
and	CC
T2	NN
,	,
the	DT
additional	JJ
semi-supervised	JJ
learning	NN
method	NN
can	MD
be	VB
used	VBN
to	TO
learn	VB
from	IN
the	DT
remainingP	NN
T3.AsL√	NN
3/4	CD
U	NNP


discussed	VBN
in	IN
Eq	NN
.	.

-LRB-	-LRB-
5	LS
-RRB-	-RRB-
,	,
by	IN
adding	VBG
an	DT
extra	JJ
term	NN
Cn	NN


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD


H√	NN
∞	CD
9fy√	NN
∞	CD
xi√û9√û	NN
to	TO
penalize	VB
the	DT
misclassiÔ	NN
¨	NN
cation	NN
of	IN
unlabeled	JJ
examples	NNS
in	IN
T3	NN
located	JJ
inside	IN
the	DT
margin	NN
decided	VBN
by	IN
Eq	NN
.	.

-LRB-	-LRB-
9	CD
-RRB-	-RRB-
,	,
as	RB
well	RB
as	IN
the	DT
balance	NN
constraint	NN
in	IN
Eq	NN
.	.

-LRB-	-LRB-
6	CD
-RRB-	-RRB-
,	,
we	PRP
can	MD
Ô	VB
¨	CD
nally	RB
get	VB
the	DT
TS3VM	NN



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
4	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



174	CD


P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


model	NN
as	IN


miny	NN


1JwJ2√	NN
3/4	CD
C1Jv1J2√	NN
3/4	CD
C2Jv2J2	NN
2	CD


√	NN
3/4	CD
C	NN


XL	NNP


H√	NN
∞	CD
yify√	NN
∞	CD
xi√û√û√	NN
3/4	CD
Cn	NN
i	FW
¬	FW
1/4	CD
1	CD


LX√	NN
3/4	CD
U	NNP


H√	NN
∞	CD
9fy√	NN
∞	CD
xi√û9√û	NN


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD


s	NNS
:	:
t	NN
:	:
:	:


1	CD


LX√	NN
3/4	CD
U	NNP


XL	NNP
U	NNP


fy√	NN
∞	CD
xi√û¬	NN
1/4	CD
1	CD


L	NN


yi	NN


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD
i	FW
¬	FW
1/4	CD
1	CD


√	NN
∞	CD
10√û	NN


where	WRB
y¬	NN
1/4	CD
√	NN
∞	CD
w	NN
,	,
v1	NN
,	,
v2	NN
,	,
b√û	NN
,	,
fy√	NN
∞	CD
xi√û¬	NN
1/4	CD
√	NN
∞	CD
w√	NN
3/4	CD
v1√ûxi√	NN
3/4	CD
b	NN
for	IN
1rirL1	NN
,	,
fy√	NN
∞	CD
xi√û¬	NN
1/4	CD
√	NN
∞	CD
w√	NN
3/4	CD
v2√ûxi√	NN
3/4	CD
b	NN
for	IN
L1√	NN
3/4	CD
1rirL	NN
,	,
and	CC
fy√	NN
∞	CD
xi√û¬	NN
1/4	CD
wxi√	NN
3/4	CD
b	NN
for	IN
L√	NN
3/4	CD
1rirL√	NN
3/4	CD
U.	NNP


Solution	NN
to	TO
the	DT
TS3VM	NN
objective	JJ
function	NN
:	:
AsshowninEq	NN
.	.

-LRB-	-LRB-
10	CD
-RRB-	-RRB-
,	,
optimizing	VBG
the	DT
objective	JJ
function	NN
of	IN
TS3VM	NN
is	VBZ
a	DT
non-convex	JJ
optimi	NN
-	:
zation	NN
problem	NN
,	,
which	WDT
is	VBZ
difÔ	JJ
¨	NN
cult	NN
to	TO
Ô	VB
¨	CD
nd	NN
global	JJ
minima	NN
especially	RB
for	IN
large-scale	JJ
problems	NNS
.	.

We	PRP
propose	VBP
to	TO
solve	VB
this	DT
non-convex	JJ
problem	NN
by	IN
using	VBG
Concave‚	NNP
$	$
``	``
Convex	NNP
Procedure	NNP
-LRB-	-LRB-
CCCP	NNP
-RRB-	-RRB-
,	,
which	WDT
has	VBZ
been	VBN
devel	JJ
-	:
oped	VBN
by	IN
the	DT
optimization	NN
community	NN
-LSB-	-LRB-
29,8,7	CD
-RSB-	-RRB-
.	.

CCCP	NN
decomposes	VBZ
a	DT
non-convex	JJ
function	NN
into	IN
the	DT
sum	NN
of	IN
a	DT
convex	NN
function	NN
and	CC
a	DT
concave	NN
function	NN
,	,
and	CC
then	RB
approximates	VBZ
the	DT
concave	JJ
part	NN
by	IN
using	VBG
a	DT
linear	JJ
function	NN
-LRB-	-LRB-
a	DT
tangential	JJ
approximation	NN
-RRB-	-RRB-
.	.

By	IN
doing	VBG
so	RB
,	,
the	DT
whole	JJ
optimization	NN
procedure	NN
can	MD
be	VB
carried	VBN
out	RP
iteratively	RB
by	IN
solving	VBG
a	DT
sequence	NN
of	IN
convex	NN
problems	NNS
.	.

Algorithm	NN
1	CD
describes	VBZ
the	DT
CCCP	NNP
algorithm	NN
in	IN
detail	NN
.	.


Algorithm	NN
1	CD
.	.

CCCP	NNP
Algorithm	NNP
.	.


Require	VB
:	:
objective	JJ
function	NN
J√	NN
∞	CD
y√û	NN


generate	VB
an	DT
initial	JJ
point	NN
y0	NN
with	IN
a	DT
best	JJS
guess	NN


J√	NN
∞	CD
y√û¬	NN
1/4	CD
Jvex√	NN
∞	CD
y√û√	NN
3/4	CD
Jcav√	NN
∞	CD
y√û	NN


repeat	NN


yt√	NN
3/4	CD
1	CD
¬	NN
1/4	CD
argminy	NN
Jvex√	NN
∞	CD
y√û√	NN
3/4	CD
J0cav√	NN
∞	CD
yt√ûy	NN


until	IN
convergence	NN
of	IN
y	NN


return	VB
a	DT
local	JJ
minima	NN
solution	NN
yn	NN


From	IN
the	DT
CCCP	NN
perspective	NN
,	,
we	PRP
can	MD
observe	VB
that	IN
the	DT
Ô	NN
¨	CD
rst	NN
four	CD
terms	NNS
of	IN
TS	NN


3VM	NN
are	VBP
convex	JJ
functions	NNS
,	,
whereas	IN
the	DT
last	JJ
Symmetric	JJ
Hinge	NN
loss	NN
part	NN
Cn	NN


PL√	NN
3/4	CD
U	NNP


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD


H√	NN
∞	CD
9fy√	NN
∞	CD
xi√û9√û	NN
makes	VBZ
it	PRP
a	DT
non-convex	JJ
model	NN
.	.

Thus	RB
,	,
we	PRP
will	MD
decompose	VB
and	CC
analyze	VB
the	DT
last	JJ
part	NN
by	IN
using	VBG
the	DT
CCCP	NN
method	NN
.	.

To	TO
simplify	VB
the	DT
notation	NN
,	,
we	PRP
denotePL√	VBP
3/4	CD
U	NNP
zi	NNP
¬	NNP
1/4	CD
fy√	NN
∞	CD
xi√û	NN
,	,
so	IN
the	DT
last	JJ
part	NN
can	MD
be	VB
rewritten	VBN
as	IN
Cn	NN


i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD


H√	NN
∞	CD
9zi9√û	NN
.	.

Considering	VBG
a	DT
speciÔ	NN
¨	NN
c	NN
zi	NN
-LRB-	-LRB-
without	IN
loss	NN
of	IN
generality	NN
,	,
we	PRP
denote	VBP
it	PRP
as	IN
z	SYM
here	RB
-RRB-	-RRB-
,	,
the	DT
Symmetric	JJ
Hinge	NN
loss	NN
on	IN
z	SYM
can	MD
be	VB
denoted	VBN
by	IN
J	NN
-LRB-	-LRB-
z	SYM
-RRB-	-RRB-
as	IN


If	IN
zo0	NN
in	IN
the	DT
current	JJ
iteration	NN
,	,
then	RB
in	IN
the	DT
next	JJ
iteration	NN
,	,
the	DT
current	JJ
effective	JJ
loss	NN
can	MD
be	VB
denoted	VBN
as	IN


8	CD


>	JJR
2Cn	NN
<	JJR
z	SYM
,	,
zZ1	NN


L√	NN
∞	CD
z	SYM
,1	CD
√û¬	NN
1/4	CD
Cn√	NN
∞	CD
1√	NN
3/4	CD
z√û	NN
,	,
9z9o1	NN
√	NN
∞	CD
15√û	NN


:	:
>	JJR


0	CD
,	,
zr1	NN


On	IN
the	DT
other	JJ
hand	NN
,	,
if	IN
zZ0	NN
,	,
then	RB
in	IN
the	DT
next	JJ
iteration	NN
,	,
the	DT
current	JJ
effective	JJ
loss	NN
can	MD
be	VB
denoted	VBN
as	IN


8	CD


<	JJR
>	JJR


0	CD
,	,
zZ1	NN


L√	NN
∞	CD
z	SYM
,	,
√	NN
3/4	CD
1√û¬	NN
1/4	CD
>	JJR
Cn√	NN
∞	CD
1z√û	NN
,	,
9z9o1	NN
√	NN
∞	CD
16√û	NN


:	:


2Cnz	NN
,	,
zr1	NN


By	IN
doing	VBG
so	RB
,	,
within	IN
each	DT
iteration	NN
,	,
when	WRB
taking	VBG
all	DT
zi	FW
¬	FW
1/4	CD
fy√	NN
∞	CD
xi√ûinto3	NN


consideration	NN
,	,
solving	VBG
the	DT
TS	NN
VM	NN
model	NN
is	VBZ
equivalent	JJ
to	TO
solving	VBG
Eq	NN
.	.

-LRB-	-LRB-
17	CD
-RRB-	-RRB-
under	IN
the	DT
balance	NN
constraint	NN
equation	NN
-LRB-	-LRB-
6	CD
-RRB-	-RRB-


miny	NN


1JwJ2√	NN
3/4	CD
√	NN
3/4	CD
C1Jv1J2√	NN
3/4	CD
C2Jv2J2	NN


2	CD


XL	NNP


LX√	NN
3/4	CD
U	NNP


√	NN
3/4	CD
C	NN
H√	NN
∞	CD
yify√	NN
∞	CD
xi√û√û√	NN
3/4	CD
L√	NN
∞	CD
fy√	NN
∞	CD
xi√û	NN
,	,
yi√û√	NN
∞	CD
17√û	NN


i	LS
¬	NN
1/4	CD
1	CD
i	FW
¬	FW
1/4	CD
L√	NN
3/4	CD
1	CD


where	WRB
yi	NN
-LRB-	-LRB-
L√	NN
3/4	CD
1rirL√	NN
3/4	CD
U	NNP
-RRB-	-RRB-
is	VBZ
the	DT
class	NN
label	NN
of	IN
xi	NN
that	WDT
has	VBZ
been	VBN
assigned	VBN
in	IN
the	DT
previous	JJ
iteration	NN
.	.

If	IN
yio0	NN
,	,
Eq	NN
.	.

-LRB-	-LRB-
15	CD
-RRB-	-RRB-
will	MD
be	VB
used	VBN
to	TO
calculate	VB
the	DT
loss	NN
function	NN
;	:
otherwise	RB
,	,
Eq	NN
.	.

-LRB-	-LRB-
16	CD
-RRB-	-RRB-
will	MD
be	VB
used	VBN
to	TO
calculate	VB
the	DT
loss	NN
function	NN
.	.

The	DT
detailed	JJ
description	NN
of	IN
solving	VBG
TS3VM	NN
is	VBZ
given	VBN
in	IN
Algorithm	NN
2	CD
.	.


Algorithm	NN
2	CD
.	.

TS3VM	NN
learning	NN
model	NN
.	.


Require	VB
:	:
T1	NN
,	,
T2	NN
and	CC
T3	NN


use	NN
T1	NN
and	CC
T2	NN
to	TO
build	VB
a	DT
transfer	NN
SVM	NN
model	NN
as	IN
shown	VBN
in	IN
Eq	NN
.	.

-LRB-	-LRB-
8	CD
-RRB-	-RRB-
,	,
and	CC
generate	VBP
an	DT
initial	JJ
point	NN
y0	NN
¬	NN
1/4	CD
√	NN
∞	CD
w0	NN
,	,
v10	NN
,	,
v20	NN
,	,
b0√û	NN


repeat	NN


yi‚	NN
$	$
ô	CD
sgn√	NN
∞	CD
wxi√	NN
3/4	CD
b√û	NN
,	,
8L√	NN
3/4	CD
1rirL√	NN
3/4	CD
U	NNP


y‚	NN
$	$
ô	CD
calculate	VBP
Eq	NN
.	.

-LRB-	-LRB-
17	CD
-RRB-	-RRB-
under	IN
the	DT
balance	NN
constraint	NN
equation	NN
-LRB-	-LRB-
6	CD
-RRB-	-RRB-


until	IN
yi	NN
remains	VBZ
unchanged	JJ
,	,
8L√	NN
3/4	CD
1rirL√	NN
3/4	CD
U	NNP


return	NN
f√	NN
∞	CD
x√û¬	NN
1/4	CD
sgn√	NN
∞	CD
wx√	NN
3/4	CD
b√û	NN


Theorem	NNP
2	CD
-LRB-	-LRB-
Convergence	NN
of	IN
TS	NN


3VM	NN
-RRB-	-RRB-
.	.


The	DT
TS3VM	NN
learning	VBG
model	NN
in	IN
Algorithm	NN
2	CD
converges	VBZ
after	IN
a	DT
limited	JJ
number	NN
of	IN
iterations	NNS
.	.


Proof	NN
.	.

In	IN
Algorithm	NN
2	CD
,	,
in	IN
each	DT
iteration	NN
t	NN
,	,
the	DT
objective	JJ
function	NN
J√	NN
∞	CD
yt√ûis	NN
split	NN
into	IN
a	DT
convex	NN
part	NN
Jvex√	NN
∞	CD
yt√ûand	NN
a	DT
concave	JJ
part	NN
Jcav√	NN
∞	CD
yt√û	NN
.	.

Then	RB
,	,
in	IN
the	DT
next	JJ
iteration	NN
t√	NN
3/4	CD
1	CD
,	,
the	DT
point	NN
yt√	NN
3/4	CD
1	CD
is	VBZ
the	DT
minimal	JJ
solution	NN
of	IN
the	DT
current	JJ
objective	JJ
function	NN
,	,
and	CC
we	PRP
have	VBP


Jvex√	NN
∞	CD
yt√	NN
3/4	CD
1√û√	NN
3/4	CD
J0cav√	NN
∞	CD
yt√ûy	NN


0t√	NN
3/4	CD
1	CD


rJvex√	NN
∞	CD
yt√û√	NN
3/4	CD
Jcav√	NN
∞	CD
yt√ûyt	NN


√	NN
∞	CD
18√û	NN


Meanwhile	RB
,	,
because	IN
the	DT
concavity	NN
of	IN
J	NN


cav√	NN
∞	CD
y√û	NN
,	,
we	PRP
have	VBP


J√	NN
∞	CD
z√û¬	NN
1/4	CD
CnH√	NN
∞	CD
9z9√û√	NN
∞	CD
11√ûJ	NN


cav√	NN
∞	CD
y	NN


0t√	NN
3/4	CD
1√ûrJ	NN


cav√	NN
∞	CD
yt√û√	NN
3/4	CD
Jcav√	NN
∞	CD
yt√û√	NN
∞	CD
yt√	NN
3/4	CD
1yt√û√	NN
∞	CD
19√û	NN


Eq	NN
.	.

-LRB-	-LRB-
11	CD
-RRB-	-RRB-
is	VBZ
a	DT
non-convex	JJ
function	NN
,	,
which	WDT
can	MD
be	VB
split	VBN
into	IN
a	DT
convex	NN
part	NN
and	CC
a	DT
concave	JJ
part	NN
as	IN


J√	NN
∞	CD
z√û¬	NN
1/4	CD
CnH√	NN
∞	CD
9z9√û¬	NN
1/4	CD
Cn	NNP
|	CD
Ô	NN
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
-LCB-	-LRB-
zÔ	NN
¨	CD
Ñ	CD
Ô	NN
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
Ô	FW
¨	FW
Ñ	FW
-RCB-	-RRB-
max√	NN
∞	NN
0	CD
;	:
19z9√û√	NN
3/4	CD
Cn9z9Cn	NN
|	CD
Ô	NN
¨	CD
Ñ	CD
Ô	NN
¨	CD
Ñ	CD
Ô	NN
¨	CD
Ñ	CD
Ô	NN
¨	CD
Ñ	CD
-LCB-	-LRB-
zÔ	NN
¨	CD
Ñ	CD
Ô	NN
¨	CD
Ñ	CD
Ô	NN
¨	CD
Ñ	CD
Ô	NN
¨	CD
Ñ	CD
-RCB-	-RRB-
9z9	SYM


Jvex√	NN
∞	CD
t√û	NN
Jcav√	NN
∞	CD
t√û	NN


√	NN
∞	CD
12√û	NN


According	VBG
to	TO
Algorithm	NNP
1	CD
,	,
the	DT
next	JJ
iterative	JJ
point	NN
can	MD
be	VB
calcu	NN
-	:
lated	VBN
by	IN
the	DT
approximation	NN
of	IN
the	DT
concave	JJ
part	NN
Jcav	NNP
as	IN


-LRB-	-LRB-


@Jcav	NN
√	NN
∞	CD
z√ûz	NN
Cnz	NN
,	,
zo0	NN


@z	NN


¬	NN
1/4	CD


Cnz	NNP
,	,
zZ0	NN


√	NN
∞	CD
13√û	NN


and	CC
then	RB
minimizing	VBG


J√	NN
∞	CD
z√û¬	NN
1/4	CD
Cn	NN
max√∞0;19z9√û√æCn9z9√æ@Jcav√∞z√û@z	NN
z	SYM


√	NN
∞	CD
14√û	NN


By	IN
adding	VBG
both	DT
sides	NNS
of	IN
Eqs	NNS
.	.

-LRB-	-LRB-
18	CD
-RRB-	-RRB-
and	CC
-LRB-	-LRB-
19	CD
-RRB-	-RRB-
,	,
we	PRP
have	VBP


Jvex√	NN
∞	CD
yt√	NN
3/4	CD
1√û√	NN
3/4	CD
Jcav√	NN
∞	CD
yt√	NN
3/4	CD
1√û√	NN
3/4	CD
J0cav√	NN
∞	CD
yt√ûyt√	NN
3/4	CD
1	CD


rJvex√	NN
∞	CD
yt√û√	NN
3/4	CD
J0	NN


0	CD


cav√	NN
∞	CD
yt√ûyt	NN


√	NN
3/4	CD
Jcav√	NN
∞	CD
yt√û√	NN
3/4	CD
Jcav√	NN
∞	CD
yt√û√	NN
∞	CD
yt√	NN
3/4	CD
1yt√û√	NN
∞	CD
20√û	NN


Move	VB
the	DT
third	JJ
item	NN
on	IN
the	DT
left-hand	JJ
side	NN
of	IN
Eq	NN
.	.

-LRB-	-LRB-
20	CD
-RRB-	-RRB-
to	TO
the	DT
right-hand	JJ
side	NN
,	,
we	PRP
have	VBP


Jvex√	NN
∞	CD
yt√	NN
3/4	CD
1√û√	NN
3/4	CD
Jcav√	NN
∞	CD
yt√	NN
3/4	CD
1√ûrJvex√	NN
∞	CD
yt√û√	NN
3/4	CD
J0cav√	NN
∞	CD
yt√ûyt	NN


√	NN
3/4	CD
Jcav√	NN
∞	CD
yt√û√	NN
3/4	CD
J0cav√	NN
∞	CD
yt√û√	NN
∞	CD
yt√	NN
3/4	CD
1yt√ûJ0cav√	NN
∞	CD
yt√	NN
3/4	CD
1√ûyt√	NN
3/4	CD
1	CD


√	NN
∞	CD
21√û	NN


The	DT
right-hand	JJ
side	NN
of	IN
the	DT
above	JJ
inequation	NN
equals	VBZ
to	TO
Jvex√	VB
∞	CD
√	NN
∞	CD
yt√û√û√	NN
3/4	CD
Jcav√	NN
∞	CD
yt√û	NN
.	.

Therefore	RB
,	,
the	DT
objective	JJ
function	NN
will	MD
decrease	VB
after	IN
each	DT
iteration	NN
Jvex√	NN
∞	CD
yt√	NN
3/4	CD
1√ûrJ√	NN
∞	CD
yt√û	NN
.	.

&	CC



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
5	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


Consequently	RB
,	,
Algorithm	NN
2	CD
will	MD
converge	VB
after	IN
a	DT
limited	JJ
number	NN
of	IN
iterations	NNS
.	.

In	IN
fact	NN
,	,
as	RB
long	RB
as	IN
the	DT
initial	JJ
point	NN
is	VBZ
carefully	RB
selected	VBN
-LRB-	-LRB-
i.e.	FW
,	,
using	VBG
a	DT
multi-task	JJ
SVM	NNP
model	NN
built	VBN
on	IN
T1	NN
and	CC
T2	NN
as	IN
the	DT
initial	JJ
point	NN
-RRB-	-RRB-
,	,
Algorithm	NN
2	CD
will	MD
converge	VB
very	RB
fast	RB
.	.


3.4	CD
.	.

Case	NNP
4	CD
:	:
Type	NN
IV	CD
dominates	VBZ


This	DT
is	VBZ
the	DT
most	RBS
complex	JJ
learning	NN
case	NN
.	.

In	IN
this	DT
case	NN
,	,
Type	NN
IV	CD
examples	NNS
T4	NN
dominate	VB
the	DT
training	NN
chunk	NN
and	CC
has	VBZ
the	DT
lowest	JJS
learning	NN
priority	NN
.	.

Thus	RB
,	,
it	PRP
is	VBZ
necessary	JJ
to	TO
use	VB
all	DT
T1	NN
,	,
T2	NN
,	,
T3	NN
and	CC
T4	NN
for	IN
training	NN
.	.


To	TO
solve	VB
this	DT
learning	NN
problem	NN
,	,
we	PRP
design	VBP
a	DT
novel	JJ
Relational	JJ
K-means-based	JJ
Transfer	NN
Semi-Supervised	JJ
learning	NN
model	NN
-LRB-	-LRB-
RK-TS3VM	NN
for	IN
short	JJ
-RRB-	-RRB-
.	.

The	DT
TS3VM	NN
model	NN
,	,
as	IN
discussed	VBN
previously	RB
,	,
is	VBZ
used	VBN
to	TO
learn	VB
from	IN
T1	NN
,	,
T2	NN
and	CC
T3	NN
.	.

Now	RB
we	PRP
discuss	VBP
how	WRB
to	TO
learn	VB
from	IN
T4	NN
using	VBG
a	DT
Relational	JJ
K-means	NN
model	NN
-LSB-	-LRB-
38	CD
-RSB-	-RRB-
-LRB-	-LRB-
RK	NN
for	IN
short	JJ
-RRB-	-RRB-
.	.


Learning	NNP
from	IN
T4	NN
is	VBZ
more	RBR
challenging	JJ
than	IN
from	IN
other	JJ
three	CD
types	NNS
of	IN
training	NN
examples	NNS
,	,
mainly	RB
because	IN
examples	NNS
in	IN
T4	NN
are	VBP
unlabeled	JJ
and	CC
have	VBP
different	JJ
distributions	NNS
from	IN
the	DT
target	NN
domain	NN
.	.

The	DT
aim	NN
of	IN
the	DT
RK	NN
model	NN
is	VBZ
to	TO
transfer	VB
knowledge	NN
from	IN
T4	NN
to	TO
T1	NN
,	,
T2	NN
and	CC
T3	NN
by	IN
constructing	VBG
some	DT
new	JJ
features	NNS
for	IN
the	DT
three	CD
types	NNS
of	IN
examples	NNS
using	VBG
the	DT
relational	JJ
information	NN
between	IN
T1	NN
,	,
T2	NN
,	,
T3	NN
and	CC
T4	NN
.	.


An	DT
example	NN
of	IN
RK	NN
learning	NN
is	VBZ
shown	VBN
in	IN
Fig.	NNP
5	CD
,	,
where	WRB
T4	NN
examples	NNS
are	VBP
Ô	NN
¨	CD
rst	NN
clustered	VBN
into	IN
k	NN
clusters	NNS
,	,
G1	NN
,	,
...	:
,	,
Gk	NNP
based	VBN
on	IN
a	DT
relational	JJ
matrix	NN
built	VBN
between	IN
T1	NN
and	CC
T4	NN
.	.

After	IN
that	DT
,	,
k	NN
new	JJ
features	NNS
f√	NN
∞	CD
xi	NN
,	,
Gt√û	NN
-LRB-	-LRB-
t¬	NN
1/4	CD
1	CD
,	,
...	:
,	,
k	NN
-RRB-	-RRB-
are	VBP
added	VBN
to	TO
each	DT
example	NN
xi	NN
in	IN
T1	NN
to	TO
construct	VB
a	DT
new	JJ
data	NNS
set	VBN
T01	NN
by	IN
calculating	VBG
the	DT
relationship	NN
between	IN
xi	NN
and	CC
each	DT
cluster	NN
center	NN
.	.

By	IN
doing	VBG
so	RB
,	,
the	DT
new	JJ
data	NNS
set	VBN
T01	NN
will	MD
contain	VB
information	NN
transferred	VBN
from	IN
T4	NN
,	,
which	WDT
can	MD
help	VB
to	TO
build	VB
a	DT
more	RBR
accurate	JJ
prediction	NN
model	NN
.	.


Given	VBN
L1	NN
examples	NNS
in	IN
T1	NN
and	CC
N	NN
examples	NNS
in	IN
T4	NN
,	,
the	DT
purpose	NN
of	IN
the	DT
relational	JJ
k-means	NNS
clustering	NN
is	VBZ
to	TO
cluster	VB
instances	NNS
in	IN
T4	NN
into	IN
k	NN
groups	NNS
,	,
by	IN
taking	VBG
the	DT
relationships	NNS
between	IN
instances	NNS
in	IN
T1	NN
andL	NN


T4	NN
into	IN
consideration	NN
.	.

Let	VB
WAR	NN


1N	NN


denote	VB
the	DT
similarity	NN
matrix	NN
between	IN
T1	NN
and	CC
T4	NN
with	IN
each	DT
wi	NN
,	,
j	NN
indicating	VBG
the	DT
similarity	NN
-LRB-	-LRB-
which	WDT
can	MD
be	VB
calculated	VBN
according	VBG
to	TO
the	DT
Euclidian	JJ
distance	NN
-RRB-	-RRB-
between	IN
instance	NN
xi	NN
in	IN
T1	NN
and	CC
instance	NN
xj	NN
in	IN
T4	NN
.	.

For	IN
each	DT
cluster	NN
Gt	NN
on	IN
W	NN
the	DT
average	JJ
pairwise	JJ
similarity	NN
for	IN
all	DT
examples	NNS
in	IN
Gt	NN
can	MD
be	VB
deÔ	NN
¨	NN
ned	VBD
as	IN


1	CD


X	NN
X	NN


175	CD


Explicitly	RB
solving	VBG
Eq	NN
.	.

-LRB-	-LRB-
24	CD
-RRB-	-RRB-
is	VBZ
very	RB
difÔ	JJ
¨	NN
cult	NN
.	.

Alternatively	RB
,	,
we	PRP
can	MD
use	VB
a	DT
recursive	JJ
hill-climbing	NN
search	NN
process	NN
as	IN
an	DT
approxima	NN
-	:
tion	NN
solution	NN
.	.

Assume	VB
that	DT
examples	NNS
in	IN
T4	NN
are	VBP
clustered	VBN
into	IN
k	NN
clusters	NNS
,	,
G1	NN
,	,
...	:
,	,
Gk	NNP
.	.

Moving	VBG
an	DT
instance	NN
x	NN
from	IN
cluster	NN
Gi	NN
to	TO
cluster	VB
Gj	NN
changes	NNS
only	RB
the	DT
cluster	NN
objective	NN
values	NNS
JG	NNP
and	CC
J	NNP


i	LS


G	NN


.	.


j	NN
Therefore	RB
,	,
in	IN
order	NN
to	TO
maximize	VB
Eq	NN
.	.

-LRB-	-LRB-
24	CD
-RRB-	-RRB-
,	,
at	IN
each	DT
step	NN
t	NN
,	,
we	PRP
randomly	RB
select	VBP
an	DT
example	NN
x	NN
from	IN
a	DT
cluster	NN
Gi	NN
,	,
and	CC
move	VB
it	PRP
to	TO
cluster	VB
Gj	NN
.	.

Such	PDT
a	DT
move	NN
is	VBZ
accepted	VBN
only	RB
if	IN
the	DT
inequity	NN
-LRB-	-LRB-
25	CD
-RRB-	-RRB-
achieves	VBZ
a	DT
higher	JJR
value	NN
at	IN
step	NN
t√	NN
3/4	CD
1	CD


JG	NN
√	NN
∞	CD
t√û√	NN
3/4	CD
J	NN


i	LS


G	NN


√	NN
∞	CD
t√ûoJ	NN


j	NN


G	NN


√	NN
∞	CD
t√	NN
3/4	CD
1√û√	NN
3/4	CD
J	NN


i	LS


G	NN


√	NN
∞	CD
t√	NN
3/4	CD
1√û√	NN
∞	CD
25√û	NN


j	NN


Based	VBN
on	IN
the	DT
search	NN
process	NN
in	IN
inequity	NN
-LRB-	-LRB-
25	CD
-RRB-	-RRB-
,	,
major	JJ
steps	NNS
of	IN
the	DT
relational	JJ
k-means	NNS
are	VBP
listed	VBN
in	IN
Algorithm	NNP
3	CD
.	.


Algorithm	NN
3	CD
.	.

Relational	JJ
k-means	NNS
clustering	NN
.	.


Require	VB
:	:
T1	NN
,	,
T4	NN
,	,
number	NN
of	IN
clusters	NNS
k	NN
,	,
and	CC
number	NN
of	IN
iterations	NNS
T	NN


W	NNP
‚	VBD
$	$
ô	CD
calculate	VBP
similarity	NN
matrix	NN
between	IN
T1	NN
and	CC
T4	NN


G1	NN
,	,
...	:
,	,
Gk‚	NNP
$	$
ô	CD
apply	VB
k-means	NNS
to	TO
W	NN


for	IN
t‚	NN
$	$
ô	CD
1toT	NN
do	VBP


x‚	NN
$	$
ô	CD
randomly	RB
select	VBP
an	DT
example	NN
fromT4	NN


Gi‚	NNP
$	$
ô	CD
current	JJ
cluster	NN
of	IN
examplex	NN


JG	NN
√	NN
∞	CD
t√û‚	NN
$	$
ô	CD
calculateG	NN


i	LS


i‚	NN
$	$
ô	CD
s	NNS
objective	JJ
value	NN
in	IN
Eq	NN
.	.

-LRB-	-LRB-
24	CD
-RRB-	-RRB-


JG	NN
√	NN
∞	CD
t√	NN
3/4	CD
1√û‚	NN
$	$
ô	CD
G	NN


i	LS


i‚	NN
$	$
ô	CD
s	NNS
new	JJ
value	NN
after	IN
excludingx	NN


for	IN
j‚	NN
$	$
ô	CD
1tok	NN
,	,
jai	NN
do	VBP


JG	NN
√	NN
∞	CD
t√û‚	NN
$	$
ô	CD
calculateG	NN


j	NN


j‚	NN
$	$
ô	CD
s	NNS
objective	JJ
value	NN


JG	NN
√	NN
∞	CD
t√	NN
3/4	CD
1√û‚	NN
$	$
ô	CD
G	NN


j	NN


j‚	NN
$	$
ô	CD
s	NNS
new	JJ
value	NN
after	IN
includingx	NN


if	IN
inequity	NN
-LRB-	-LRB-
25	CD
-RRB-	-RRB-
istrue	NN
then	RB


Gj‚	NNP
$	$
ô	CD
Gj	NN
-LSB-	-LRB-
x	NN
;	:
Gi‚	NNP
$	$
ô	CD
Gi	NN
\	CD
x	NN


break	NN


end	NN
if	IN


end	NN
for	IN


end	NN
for	IN


m1	NN
,	,
...	:
,	,
mk‚	NN
$	$
ô	CD
calculate	VBP
cluster	NN
centers	NNS
forG1	NN
,	,
...	:
,	,
Gk	NNP


return	NN
m1	NN
,	,
...	:
,	,
mk	NN


Algorithm	NN
3has	NNS
three	CD
tiers	NNS
of	IN
loops	NNS
.	.

Within	IN
each	DT
tier	NN
,	,
it	PRP
needs	VBZ


0	CD


to	TO
frequently	RB
recalculateJ	NN


SGt	NN
¬	NN
1/4	CD
√û√	NN
∞	CD
22√ûG	NN


√	NN
∞	CD
t√ûwhen	NN
the	DT
current	JJ
examples	NNS
are	VBP


S√	NN
∞	CD
x	NN
,	,
x	NN


c	NN


9Gt92	NN


removed	VBN
from	IN
its	PRP$
current	JJ
group	NN
to	TO
another	DT
.	.

Nevertheless	RB
,	,
becausexAG	NN


tx0	NN
AGt	NN


JG	NN
√	NN
∞	CD
t√û	NN
,	,
as	IN
shown	VBN
in	IN
Eq	NN
.	.

-LRB-	-LRB-
24	CD
-RRB-	-RRB-
,	,
contains	VBZ
information	NN
from	IN
both	CC
the	DT


c	NN


similaritySG	NN


i	LS


and	CC
variancedG	NN


i	LS


in	IN
the	DT
relationship	NN
matrix	NN
,	,
fre	NN
-	:


quently	RB
recalculatingJG	NN
√	NN
∞	CD
t√ûwill	NN
be	VB
time-consuming	JJ
.	.

To	TO
alleviate	VB


c	NN


this	DT
problem	NN
,	,
we	PRP
introduce	VBP
an	DT
addictive	JJ
update	VBP
method	NN
and	CC
a	DT


where	WRB
S√	NNP
∞	CD
x	NN
,	,
x0√ûdenotes	NNPS
the	DT
similarity	NN
between	IN
two	CD
examples	NNS
of	IN
x	NN
and	CC
x0	NN
.	.

On	IN
the	DT
other	JJ
hand	NN
,	,
the	DT
variance	NN
of	IN
the	DT
relationship	NN
values	NNS
of	IN
all	DT
examples	NNS
in	IN
Gt	NN
can	MD
be	VB
calculated	VBN
as	IN


where	WRB
bGt	NN
denotes	VBZ
the	DT
average	JJ
relationship	NN
vector	NN
of	IN
all	DT
instances	NNS
in	IN
Gt	NN
,	,
and	CC
biAR1L	NN


1	CD


denotes	VBZ
the	DT
relationships	NNS
of	IN
instance	NN
xj	NN
with	IN
respect	NN
to	TO
all	DT
examples	NNS
in	IN
T1	NN
.	.

The	DT
objective	NN
of	IN
the	DT
relational	JJ
k-means	NN
is	VBZ
to	TO
Ô	VB
¨	CD
nd	NN
k	NN
groups	NNS
,	,
Gt	NN
,	,
t¬	NN
1/4	CD
1	CD
,	,
...	:
,	,
k	NN
,	,
such	JJ
that	IN
the	DT
sum	NN
of	IN
the	DT
similarities	NNS
is	VBZ
maximized	VBN
while	IN
the	DT
sum	NN
of	IN
variances	NNS
is	VBZ
minimized	VBN
as	IN


X	NN


subtractive	JJ
update	VBP
method	NN
to	TO
recalculateJG	NN
√	NN
∞	CD
t√û	NN
.	.


c	NN


d	NN


1G	NN


t	NN


¬	NN
1/4	CD
9G	NN
√	NN
∞	CD


t	NN


jb	NN
t	NN


√ûT9	NN
b	NN


G	NN


√	NN
∞	CD
bjbGt√û√	NN
∞	CD
23√ûConsider	NN
an	DT
examplex	JJ
inT4that	NN
moves	NNS
from	IN
groupGi	NN
toGj	NN
.	.


yi	NN
AGt	NN


Before	IN
the	DT
move	NN
,	,
bG	NN
andbG	NN
are	VBP
the	DT
mean	NN
vectors	NNS
,	,
d	NN


i	FW
j	FW


Gi	NN


anddG	NN


j	NN


are	VBP


the	DT
variance	NN
vectors	NNS
.	.

After	IN
the	DT
move	NN
,	,
the	DT
new	JJ
groups	NNS
areG0i	NN
andG0j	NN
.	.


Then	RB
the	DT
addictive	JJ
update	VBP
is	VBZ
given	VBN
in	IN
the	DT
following	VBG
theorem	NN
:	:


Theorem	NNP
3	CD
-LRB-	-LRB-
Additive	JJ
update	VBP
-RRB-	-RRB-
.	.

When	WRB
adding	VBG
an	DT
example	NN
x	NN
into	IN
Gj	NN
,	,


the	DT
mean	NN
vector	NN
of	IN
Gj	NN
,	,
bG	NN
,	,
can	MD
be	VB
updated	VBN
to	TO
b0	VB


i	LS
G	NN


as	IN
follows	VBZ
:	:


i	LS


X	NN


b0G	NN
¬	NN
1/4	CD
1	CD


j	NN


9G0j9	NN


bl	NN


b	NN
bG	NN


¬	NN
1/4	CD
b	NN


G	NN


√	NN
3/4	CD
k	NN


j	NN


i	LS


xi	NN
A	NN


nj√	NN
3/4	CD
1	CD


√	NN
∞	CD
26√û	NN


Xk	NN
Xk	NN


J0	NN


e	SYM


¬	NN
1/4	CD
max	NN
JGt	NN
¬	NN
1/4	CD
max	NN


SGt	SYM


t	NN
¬	NN
1/4	CD
1	CD
t	NN
¬	NN
1/4	CD
1	CD


dGt	NN


√	NN
∞	CD
24√ûMeanwhile	NN
,	,
the	DT
variance	NN


dG	NN


j	NN


can	MD
be	VB
updated	VBN
to	TO
d0G	NN
as	IN
follows	VBZ
:	:


j	NN


Information	NN
from	IN
T1	NN


Information	NN
from	IN
T4	NN


Class	NNP
label	NN
for	IN
T1	NN


A1	NN
A	NN


2	CD


.	.
.	.

Ad	NN
G	NN


1	CD


.	.
.	.

Gk	NNP
Y	NN
1	CD
2	CD
.	.
.	.

5	CD
f	FW
-LRB-	-LRB-
x1	NN
,	,
G1	NN
-RRB-	-RRB-
.	.
.	.

f	LS
-LRB-	-LRB-
x1	NN
,	,
Gk	NN
-RRB-	-RRB-
1	CD
.	.
.	.
.	.
.	.
.	.
.	.
.	.
.	.
.	.
.	.
.	.
.	.
.	.
.	.
.	.
.	.

3	CD
7	CD
.	.
.	.

1	LS
f	FW
-LRB-	-LRB-
xL	NN


1	CD
,	,


G1	NN
-RRB-	-RRB-
.	.
.	.

f	LS
-LRB-	-LRB-
xL	NN


1	CD
,	,


Gk	NN
-RRB-	-RRB-
2	CD


Fig.	NN
5	CD
.	.

An	DT
illustration	NN
of	IN
the	DT
RK	NN
learning	VBG
model	NN
.	.


X	NN


d0G	NN
¬	NN
1/4	CD
19G09	NN
√	NN
∞	CD
b	NN


0	CD


j	NN


lb	NN
G	NN


√ûT√	NN
∞	CD
b	NN


0	CD


j	NN


lb	NN
G	NN


√û	NN


j	NN


j	NN
yl	NN
AG0j	NN


¬	NN
1/4	CD
njnj√	NN
3/4	CD
1dG	NN


j	NN


√	NN
3/4	CD
nj	NN
√û√	NN
∞	CD
b	NN


T	NN


√	NN
∞	CD
n	NN
√	NN
3/4	CD
1√û2√	NN
∞	CD
bkbG	NN


j	NN


kbG	NN


√û√	NN
∞	CD
27√û	NN


j	NN


j	NN


where	WRB
nj	NN
is	VBZ
the	DT
number	NN
of	IN
examples	NNS
in	IN
Gj	NN
.	.


Therefore	RB
,	,
the	DT
updated	VBN
mean	NN
and	CC
variance	NN
vectors	NNS
of	IN
group	NN
Gj	NN
can	MD
be	VB
incrementally	RB
calculated	VBN
,	,
without	IN
recalculating	VBG
Eq	NN
.	.

-LRB-	-LRB-
24	CD
-RRB-	-RRB-
.	.



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
6	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



176	CD


P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


Similarly	RB
,	,
for	IN
a	DT
group	NN
Gi	NN
,	,
where	WRB
an	DT
example	NN
x	NN
is	VBZ
removed	VBN
,	,
its	PRP$
mean	NN
and	CC
variance	NN
vectors	NNS
can	MD
be	VB
updated	VBN
using	VBG
the	DT
following	VBG
theorem	NN
.	.


Theorem	NNP
4	CD
-LRB-	-LRB-
Subtractive	JJ
update	VBP
-RRB-	-RRB-
.	.

When	WRB
an	DT
example	NN
x	NN
is	VBZ
removed	VBN
from	IN
group	NN
Gi	NN
,	,
the	DT
mean	NN
vector	NN
bG	NN
can	MD
be	VB
updated	VBN
to	TO
b0	VB


i	LS
G	NN


as	IN
follows	VBZ
:	:


i	LS


1	CD


X	NN


b0G	NN
¬	NN
1/4	CD


9G09	NN


bl	NN
¬	NN
1/4	CD


1	CD


i	LS


i	LS


n	NN


b	NN
bkbG	NN


i	LS


i	LS


1√	NN
∞	CD
n	NN


ibG	NN
k√û¬	NN
1/4	CD
bG	NN


yl	NN
AG0	NN


i	LS


i	LS


ni1	NN


√	NN
∞	CD
28√û	NN


i	LS


Meanwhile	RB
,	,
the	DT
variance	NN
dG	NN


i	LS


can	MD
be	VB
updated	VBN
to	TO
d0G	NN
as	IN
follows	VBZ
:	:


i	LS


examples	NNS
is	VBZ
a	DT
desirable	JJ
trade-off	NN
solution	NN
.	.

-LRB-	-LRB-
3	LS
-RRB-	-RRB-
When	WRB
T2	NN
dominates	VBZ
the	DT
training	NN
examples	NNS
,	,
using	VBG
TS	NN


3VM	CD
to	TO
train	VB
on	IN


T1	NN
,	,
T2	NN
and	CC
T3	NN
examples	NNS
is	VBZ
a	DT
desirable	JJ
trade-off	NN
solution	NN
.	.

-LRB-	-LRB-
4	LS
-RRB-	-RRB-
When	WRB
T4	NN
dominates	VBZ
the	DT
training	NN
examples	NNS
,	,
using	VBG
RK-TS	NN


3VM	NN
is	VBZ
a	DT
desirable	JJ
trade-off	NN
solution	NN
.	.


4.1	CD
.	.

Experimental	JJ
settings	NNS


Comparison	NN
partners	NNS
:	:
We	PRP
implemented	VBD
all	PDT
the	DT
learning	NN
models	NNS


SVM	NNP
,	,
S3VM	NN
,	,
TS3VM	NN
and	CC
RK-TS	NN


d	NN


1	CD


.	.

To	TO
solve	VB
the	DT
quadratic0	NN
X	NN


3VM	NN
in	IN
C√	NN
3/4	CD
√	NN
3/4	CD


G	NN


¬	NN
1/4	CD
9G09	NN
√	NN
∞	CD
blb0G	NN
√ûT√	NN
∞	CD
blb0G	NN
√û	NN


i	FW
i	FW
i	FW


programming	NN
problem	NN
for	IN
the	DT
RK-TS3VM	NN
model	NN
as	IN
in	IN
Eq	NN
.	.

-LRB-	-LRB-
17	CD
-RRB-	-RRB-
,	,
wei	FW


y	NN
AG0l	NN


i	LS


used	VBN
the	DT
optimization	NN
package	NN
in	IN
the	DT
IMSL	NNP
Fortran	NNP
Library	NNP
.1	CD
Whilen	NNP


i	LS


dG	NN


i	LS



ni	NNS


2	CD


√	NN
∞	CD
bkb	NN


T	NN


G	NN


√û	NN
√	NN
∞	CD
b	NN
√û√	NN
∞	CD
n	NN


G	NN


29√û√	JJ
∞	NN


i1√û	NN


i	LS


kb	NN


our	PRP$
proposed	VBN
RK-TS3VM	NN
model	NN
is	VBZ
the	DT
most	RBS
accurate	JJ
,	,
it	PRP
is	VBZ
also	RB
the	DT


i	LS


most	RBS
sophisticated	JJ
and	CC
time-consuming	JJ
.	.

Other	JJ
simpler	JJR
models	NNS


¬	NN
1/4	CD
ni1	NN


where	WRB
ni	NNS
is	VBZ
the	DT
number	NN
of	IN
examples	NNS
in	IN
Gi	NN
.	.


Time	NNP
complexity	NN
:	:
Now	RB
we	PRP
analyze	VBP
the	DT
time	NN
complexity	NN
of	IN
Algorithm	NN
3	CD
.	.

InAlgorithm	NNP
3	CD
,	,
when	WRB
searching	VBG
for	IN
a	DT
new	JJ
group	NN
for	IN
each	DT
example	NN
in	IN
the	DT
relationship	NN
matrix	NN
,	,
the	DT
updating	VBG
operation	NN
,	,
by	IN
using	VBG
Theorems	NNS
3	CD
and	CC
4	CD
,	,
can	MD
be	VB
executed	VBN
within	IN
constant	JJ
time	NN
O	NN
-LRB-	-LRB-
1	CD
-RRB-	-RRB-
.	.

Besides	IN
,	,
Algorithm	NN
3	CD
is	VBZ
a	DT
greedy	JJ
algorithm	NN
.	.

In	IN
each	DT
iteration	NN
,	,
it	PRP
uses	VBZ
a	DT
local	JJ
optimization	NN
technique	NN
to	TO
cluster	VB
examples	NNS
into	IN
groups	NNS
that	WDT
maximizes	VBZ
Eq	NN
.	.

-LRB-	-LRB-
24	CD
-RRB-	-RRB-
.	.

There	EX
are	VBP
three	CD
tiers	NNS
of	IN
loops	NNS
in	IN
the	DT
algorithm	NN
.	.

The	DT
Ô	NN
¨	NN
rst	NN
tier	NN
aims	VBZ
to	TO
Ô	VB
¨	CD
nd	VBD
the	DT
best	JJS
group	NN
for	IN
each	DT
example	NN
x	NN
with	IN
the	DT
worst-case	JJ
complexity	NN
of	IN
O	NN
-LRB-	-LRB-
k	NN
-RRB-	-RRB-
-LRB-	-LRB-
i.e.	FW
,	,
traversing	VBG
all	PDT
the	DT
k	NN
groups	NNS
-RRB-	-RRB-
.	.

The	DT
second	JJ
tier	NN
aims	VBZ
to	TO
Ô	VB
¨	CD
nd	VBD
the	DT
best	JJS
groups	NNS
for	IN
all	DT
examples	NNS
in	IN
T4	NN
,	,
which	WDT
has	VBZ
the	DT
worst-case	JJ
complexity	NN
of	IN
O	NN
-LRB-	-LRB-
N	NN
-RRB-	-RRB-
-LRB-	-LRB-
i.e.	FW
,	,
searching	VBG
over	IN
all	PDT
the	DT
N	NN
examples	NNS
-RRB-	-RRB-
.	.

The	DT
last	JJ
tier	NN
aims	VBZ
to	TO
make	VB
the	DT
algorithm	NN
converge	VBP
to	TO
a	DT
stable	JJ
solution	NN
.	.

Obviously	RB
,	,
the	DT
Ô	NN
¨	CD
rst	NN
two	CD
tiers	NNS
dominate	VBP
the	DT
time	NN
consumption	NN
of	IN
the	DT
whole	JJ
algorithm	NN
,	,
and	CC
thus	RB
the	DT
time	NN
complexity	NN
of	IN
Algorithm	NN
3	CD
is	VBZ
O√	JJ
∞	NN
k√ûO√	NN
∞	CD
N√û¬	NN
1/4	CD
O√	NN
∞	CD
kN√û	NN
.	.


RK-TS3VM	NN
learning	NN
model	NN
:	:
Algorithm	NN
4	CD
lists	VBZ
the	DT
detailed	JJ
proce	NN
-	:
dures	NNS
of	IN
the	DT
RK-TS3VM	NN
learning	VBG
model	NN
,	,
which	WDT
is	VBZ
the	DT
combination	NN
of	IN
the	DT
TS3VM	NN
and	CC
RK	NN
learning	NN
models	NNS
.	.

Given	VBN
a	DT
training	NN
chunk	NN
D	NN
,	,
Step	NN
1	CD
identiÔ	NN
¨	CD
es	VBZ
the	DT
four	CD
types	NNS
of	IN
examples	NNS
T1	NN
,	,
T2	NN
,	,
T3	NN
and	CC
T4.Step	NN
2	CD
constructs	NNS
a	DT
group	NN
of	IN
k	NN
feature	NN
vectors	NNS
,	,
denoted	VBN
by	IN
m¬	NN
1/4	CD
fm1	NN
,	,
...	:
,	,
mkg	NN
,	,
by	IN
applying	VBG
RK	NN
to	TO
T1	NN
and	CC
T4	NN
.	.

In	IN
Steps	NNS
3	CD
and	CC
4	CD
,	,
the	DT
k	NN
new	JJ
features	NNS
are	VBP
appended	VBN
to	TO
each	DT
example	NN
in	IN
T1	NN
,	,
T2	NN
and	CC
T3	NN
to	TO
form	VB
three	CD
new	JJ
sets	NNS
denoted	VBN
by	IN
T01	NN
,	,
T02	NN
and	CC
T03	NN
,	,
respectively	RB
.	.

Step	VB
5	CD
builds	VBZ
a	DT
TS3VM	NN
model	NN
F	NN
from	IN
T01	NN
,	,
T02	NN
and	CC
T03	NN
.	.

In	IN
Step	NN
6	CD
,	,
the	DT
feature	NN
vectors	NNS
m	NN
and	CC
F	NN
are	VBP
combined	VBN
to	TO
form	VB
the	DT
Ô	NN
¨	CD
nal	JJ
prediction	NN
model	NN
.	.

For	IN
any	DT
example	NN
x	NN
in	IN
the	DT
testing	NN
chunk	NN
,	,
RK-TS3VM	NN
Ô	NN
¨	CD
rst	NN
calculates	VBZ
k	NN
new	JJ
features	NNS
for	IN
x	NN
,	,
then	RB
uses	VBZ
the	DT
TS3VM	NN
model	NN
to	TO
predict	VB
a	DT
label	NN
for	IN
x.	NN


Algorithm	NN
4	CD
.	.

RK-TS3VM	NN
learning	NN
model	NN
.	.


Require	VB
:	:
training	NN
chunk	NN
D	NN
,	,
chunk	NN
size	NN
n	NN
,	,
labeling	VBG
rate	NN
l	NN
,	,
concept	NN
drifting	VBG
probability	NN
c	NN
,	,
number	NN
of	IN
clusters	NNS
k	NN


Step	NN
1	CD
:	:
identify	VB
T1	NN
,	,
T2	NN
,	,
T3	NN
and	CC
T4	NN
in	IN
D	NN
according	VBG
to	TO
the	DT
labeling	NN
rate	NN
l	NN
and	CC
concept	NN
drifting	VBG
probability	NN
c	NN
using	VBG
Eq	NN
.	.

-LRB-	-LRB-
1	LS
-RRB-	-RRB-


Step	NN
2	CD
:	:
use	VB
RK	NN
model	NN
on	IN
T1	NN
and	CC
T4	NN
to	TO
get	VB
k	NN
cluster	NN
centers	NNS
denoted	VBN
by	IN
m¬	NN
1/4	CD
fm1	NN
,	,
...	:
,	,
mkg	NN


Step	NN
3	CD
:	:
for	IN
each	DT
example	NN
x	NN
in	IN
T1	NN
,	,
T2	NN
and	CC
T3	NN
,	,
add	VB
k	NN
attributes	NNS
using	VBG
the	DT
inner	JJ
product	NN
between	IN
x	NN
and	CC
m	NN


Step	VB
4	CD
:	:
get	VB
the	DT
new	JJ
examples	NNS
T01	NN
,	,
T02	NN
and	CC
T03	NN
from	IN
Step	NN
3	CD


Step	VB
5	CD
:	:
construct	NN
TS	NN


3VM	CD
from	IN


T	NN


0	CD


1	CD
,	,


T02	NN
and	CC
T03	NN
,	,
and	CC
use	VB
it	PRP
to	TO
train	VB
a	DT
model	NN
F	NN


return	NN
m	NN
and	CC
F	NN
together	RB
as	IN
the	DT
prediction	NN
model	NN


4	LS
.	.

Experiments	NNS


In	IN
this	DT
section	NN
,	,
we	PRP
report	VBP
experimental	JJ
results	NNS
.	.

The	DT
purpose	NN
of	IN
the	DT
experiments	NNS
is	VBZ
to	TO
validate	VB
the	DT
following	VBG
arguments	NNS
:	:
-LRB-	-LRB-
1	LS
-RRB-	-RRB-
when	WRB
T1	NN
dominates	VBZ
the	DT
training	NN
examples	NNS
,	,
using	VBG
SVM	NNP
to	TO
train	VB
on	IN
T1	NN
examples	NNS
is	VBZ
a	DT
desirable	JJ
trade-off	NN
solution	NN
.	.

-LRB-	-LRB-
2	LS
-RRB-	-RRB-
When	WRB
T3	NN
dominates	VBZ
the	DT
training	NN
examples	NNS
,	,
using	VBG
S	NN


3VM	CD
to	TO
train	VB
on	IN
both	DT


T1	NN
and	CC
T3	NN


can	MD
perform	VB
sufÔ	NN
¨	NN
ciently	RB
accurate	JJ
with	IN
less	JJR
training	NN
time	NN
in	IN
certain	JJ
learning	VBG
cases	NNS
and	CC
thus	RB
can	MD
be	VB
desirable	JJ
trade-off	NN
solutions	NNS
.	.


Data	NNS
streams	NNS
:	:
One	CD
synthetic	JJ
data	NNS
stream	NN
and	CC
three	CD
real-world	JJ
data	NNS
streams	NNS
were	VBD
used	VBN
in	IN
our	PRP$
experiments	NNS
.	.

The	DT
synthetic	JJ
data	NNS
stream	NN
was	VBD
used	VBN
to	TO
assess	VB
the	DT
performance	NN
of	IN
our	PRP$
framework	NN
under	IN
different	JJ
concept	NN
drifting	VBG
scenarios	NNS
,	,
which	WDT
are	VBP
hard	JJ
to	TO
capture	VB
from	IN
real-world	JJ
streams	NNS
.	.

It	PRP
was	VBD
generated	VBN
as	IN
an	DT
inÔ	NN
¨	NN
nite	JJ
sequence	NN
of	IN
f√	NN
∞	CD
xi	NN
,	,
yi√û	NN


√	NN
3/4	CD
1	CD


i	LS
¬	NN
1/4	CD
1g	NN
,	,
where	WRB


xiARd	NN
is	VBZ
the	DT
feature	NN
vector	NN
and	CC
yiAf1	NN
,	,
√	NN
3/4	CD
1g	NN
is	VBZ
the	DT
class	NN
label	NN
.	.

The	DT
feature	NN
values	NNS
of	IN
xi	NN
were	VBD
generated	VBN
by	IN
a	DT
uniform	JJ
distribution	NN
between	IN
0	CD
and	CC
1	CD
,	,
and	CC
the	DT
classiÔ	NN
¨	NN
cation	NN
boundary	NN
was	VBD
controlled	VBN


Xd	NN


aixi	NN
¬	NN
1/4	CD
a0	NN
i	FW
¬	FW
1/4	CD
1	CD


√	NN
∞	CD
30√û	NN


where	WRB
ai	VBP
controls	NNS
the	DT
decision	NN
boundaries.Pd	NN


For	IN
each	DT
example	NN
xi	NN
,	,
if	IN


i	LS
¬	NN
1/4	CD
1	CD


aixiZa0	NN
,	,
it	PRP
was	VBD
labeled	VBN
as	IN
yi	NN
¬	NN
1/4	CD
√	NN
3/4	CD
1	CD
;	:
otherwise	RB
,	,
yi	NN
¬	NN
1/4	CD
1	CD
.	.

To	TO
simulate	VB
the	DT
labeling	NN
process	NN
,	,
we	PRP


randomly	RB
chose	VBD
p	NN
percentage	NN
of	IN
examples	NNS
and	CC
labeled	VBN
them	PRP
using	VBG


Eq	NN
.	.

-LRB-	-LRB-
30	CD
-RRB-	-RRB-
.	.

To	TO
simulate	VB
concept	NN
drifting	VBG
,	,
ai	VBP
was	VBD
given	VBN
a	DT
probability	NN
c	NN
,	,


0rcr1	NN
,	,
to	TO
evolve	VB
between	IN
ai	VBP
and	CC
ai√	VBP
3/4	CD
0:1	CD
with	IN
10	CD
%	NN
probability	NN
to	TO


reverse	VB
the	DT
direction	NN
.	.

Besides	IN
,	,
we	PRP
set	VBD
a	DT
margin	NN
between	IN
the	DT
two	CD


classes	NNS
.	.

For	IN
the	DT
‚	NN
$	$
ò‚	CD
$	$
òP	CD
√	NN
3/4	CD
1‚	CD
$	$
ô	CD
‚	NN
$	$
ô	CD
class	NN
,	,
the	DT
boundary	NN
was	VBD
set	VBN
tod	NN


i	LS


P	NN


¬	NN
1/4	CD
0	CD


aixi√	NN
3/4	CD
0:05	CD
,	,
and	CC
for	IN
the	DT
‚	NN
$	$
ò‚	CD
$	$
ò1‚	CD
$	$
ô	CD
‚	NN
$	$
ô	CD
class	NN
,	,
the	DT
boundary	NN
was	VBD
setd	JJ


to	TO


i	LS
¬	NN
1/4	CD
0	CD


aixi0	NN
:05	CD
.	.

To	TO
keep	VB
class	NN
distributions	NNS
relatively	RB
balanced	JJ
,	,
we	PRP
enforced	VBD
the	DT
classiÔ	NN
¨	NN
cation	NN
boundary	NN
around	IN
the	DT
central	JJ
pointPd	NN


of	IN
the	DT
feature	NN
space	NN
by	IN
setting	VBG
a0	NN
¬	NN
1/4	CD
12	CD


i	LS
¬	NN
1/4	CD
1	CD


ai	VBP
.	.

In	IN
order	NN
to	TO
make	VB
the	DT
decision	NN
surface	NN
nonlinearly	JJ
separable	JJ
,	,
3	CD
%	NN
noise	NN
was	VBD
introduced	VBN
to	TO
the	DT
stream	NN
by	IN
randomly	RB
Ô	NN
¨	CD
Ç	NN
opping	VBG
the	DT
class	NN
labels	NNS
of	IN
the	DT
selected	VBN
instances	NNS
.	.


Three	CD
real-world	JJ
streams	NNS
were	VBD
used	VBN
in	IN
our	PRP$
experiments	NNS
:	:
wireless	JJ
sensor	NN
stream	NN
,	,
power	NN
supply	NN
stream	NN
,	,
and	CC
intrusion	NN
detection	NN
stream	NN
.	.

These	DT
data	NNS
streams	NNS
can	MD
be	VB
downloaded	VBN
at	IN
www.cse.fau.edu/xqzhu/stream.html	NN
.	.

The	DT
corresponding	JJ
learning	NN
tasks	NNS
have	VBP
been	VBN
discussed	VBN
in	IN
our	PRP$
Introduction	NN
section	NN
.	.


4.2	CD
.	.

Parameter	NN
study	NN


Among	IN
the	DT
four	CD
learning	NN
models	NNS
,	,
SVM	NN
and	CC
S3VM	NN
are	VBP
not	RB
new	JJ
.	.

Thus	RB
,	,
we	PRP
performed	VBD
parameter	NN
study	NN
on	IN
synthetic	JJ
data	NNS
for	IN
the	DT
TS3VM	NN
and	CC
RK	NN
models	NNS
under	IN
different	JJ
experimental	JJ
settings	NNS
.	.


The	DT
four	CD
parameters	NNS
of	IN
the	DT
TS3VM	NN
model	NN
in	IN
Eq	NN
.	.

-LRB-	-LRB-
10	CD
-RRB-	-RRB-
are	VBP
C1	NN
,	,
C2	NN
,	,
C	NN
and	CC
Cn	NN
.	.

From	IN
the	DT
multi-task	JJ
learning	NN
perspective	NN
,	,
C1	NN
and	CC
C2	NN
control	VBP
the	DT
discrepancies	NNS
between	IN
the	DT
global	JJ
optimal	JJ
boundary	NN
w	NN
and	CC
the	DT
local	JJ
optimal	JJ
boundary	NN
w√	NN
3/4	CD
v1	NN
and	CC
w√	NN
3/4	CD
v2	NN
.	.

If	IN
we	PRP
assign	VBP
a	DT
relative	JJ
large	JJ
value	NN
to	TO
C1	NN
-LRB-	-LRB-
compared	VBN
to	TO
C2	NN
-RRB-	-RRB-
,	,
the	DT
global	JJ
optimal	JJ
solution	NN
w	NN
will	MD
bias	NN
towards	IN
task	NN
1	CD
,	,
and	CC
vice	NN
versa	RB
.	.

If	IN
we	PRP
have	VBP
C1bC2	NN
,	,
i.e.	FW
,	,
C1	NN
=	JJ
C2410	NN
;	:
000	CD
,	,
v1	NN
will	MD
approach	VB
to	TO
0	CD
and	CC
the	DT
classiÔ	NN
¨	NN
cation	NN
boundary	NN
of	IN
task	NN
1	CD
becomes	VBZ
the	DT
global	JJ
optimal	JJ
boundary	NN
.	.

The	DT
parameter	NN
C	NN
controls	VBZ
the	DT
penalty	NN
of	IN
the	DT


1	CD


http://www.vni.com/products/imsl/	NN



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
7	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


0.96	CD


0.95	CD


parameter	NN
C1	NN


0	CD


0.01	CD


0.1	CD


1	CD


10	CD


100	CD


1000	CD
10000	CD


0.96	CD


0.95	CD


0.94	CD


parameter	NN
C	NN
*	SYM


0.93	CD


0	CD


0.01	CD


0.1	CD


1	CD


10	CD


100	CD


1000	CD
10000	CD


177	CD


0.96	CD


0.95	CD


parameter	NN
C2	NN


0	CD


0.01	CD


0.1	CD


1	CD


10	CD


100	CD


1000	CD
10000	CD


0.96	CD


0.95	CD


parameter	NN
C	NN


0	CD


0.01	CD


0.1	CD


1	CD


10	CD


100	CD


1000	CD
10000	CD


Fig.	NN
6	CD
.	.

Parameter	NN
study	NN
for	IN
TS3VM	NN
.	.

The	DT
y-axis	JJ
denotes	VBZ
accuracy	NN
and	CC
the	DT
x-axis	JJ
denotes	VBZ
parameter	NN
values	NNS
for	IN
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
C1	NN
,	,
-LRB-	-LRB-
b	LS
-RRB-	-RRB-
C2	NN
,	,
-LRB-	-LRB-
c	NN
-RRB-	-RRB-
Cn	NN
and	CC
-LRB-	-LRB-
d	LS
-RRB-	-RRB-
C	NN
,	,
each	DT
varying	VBG
from	IN
0	CD
to	TO
10,000	CD
.	.


0.95	CD


0.94	CD


Accuracy	NN


0.93	CD


Accuracy	NN
of	IN
TS3	NN
VM	NN


0.92	CD


1	CD


2	CD


3	CD
Number	NN
of	IN
Clusters	NNS


4	CD


5	CD


Fig.	NN
7	CD
.	.

Accuracy	NN
of	IN
TS3VM	NN
with	IN
respect	NN
to	TO
different	JJ
k	NN
values	NNS
for	IN
the	DT
RK	NN
model	NN
.	.

We	PRP
can	MD
observe	VB
that	IN
when	WRB
k	NN
increases	VBZ
from	IN
1	CD
to	TO
2	CD
,	,
the	DT
accuracy	NN
increases	VBZ
signiÔ	NN
¨	NN
cantly	RB
.	.

After	IN
that	DT
,	,
the	DT
improvement	NN
becomes	VBZ
marginal	JJ
.	.


misclassiÔ	NN
¨	CD
ed	VBD
examples	NNS
in	IN
T1	NN
and	CC
T2	NN
,	,
and	CC
the	DT
last	JJ
parameter	NN
Cn	NN
controls	VBZ
the	DT
penalty	NN
of	IN
the	DT
misclassiÔ	NN
¨	NN
ed	VBD
examples	NNS
in	IN
T3	NN
.	.


Fig.	NN
6	CD
reports	VBZ
the	DT
accuracy	NN
values	NNS
-LRB-	-LRB-
the	DT
y-axis	NN
-RRB-	-RRB-
of	IN
TS3VM	NN
with	IN
respect	NN
to	TO
different	JJ
parameter	NN
values	NNS
-LRB-	-LRB-
the	DT
x-axis	NN
-RRB-	-RRB-
.	.

All	PDT
the	DT
results	NNS
were	VBD
averaged	VBN
over	IN
100	CD
data	NNS
chunks	NNS
each	DT
containing	VBG
500	CD
exam	NN
-	:
ples	NNS
.	.

The	DT
concept	NN
drifting	VBG
probability	NN
c	NN
was	VBD
set	VBN
to	TO
50	CD
%	NN
and	CC
the	DT
labeling	NN
percentage	NN
was	VBD
set	VBN
to	TO
p¬	NN
1/4	CD
10	CD
%	NN
.	.

From	IN
Fig.	NN
6	CD
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
and	CC
-LRB-	-LRB-
b	LS
-RRB-	-RRB-
,	,
we	PRP
observe	VBP
that	IN
increasing	VBG
C2	NN
will	MD
result	VB
in	IN
a	DT
more	RBR
noticeable	JJ
performance	NN
deterioration	NN
than	IN
increasing	VBG
C1	NN
.	.

This	DT
is	VBZ
consistent	JJ
with	IN
our	PRP$
assumption	NN
that	IN
task	NN
1	CD
is	VBZ
supposed	VBN
to	TO
comply	VB
with	IN
the	DT
same	JJ
distribution	NN
as	IN
the	DT
target	NN
domain	NN
.	.

The	DT
results	NNS
in	IN
Fig.	NN
6	CD
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
and	CC
-LRB-	-LRB-
b	LS
-RRB-	-RRB-
also	RB
suggest	VBP
that	IN
a	DT
reasonable	JJ
setting	NN
for	IN
C1	NN
and	CC
C2	NN
is	VBZ
to	TO
ensure	VB
that	IN
C1	NN
=	JJ
C2	NN
¬	NN
1/4	CD
10	CD
.	.

From	IN
Fig.	NN
6	CD
-LRB-	-LRB-
c	NN
-RRB-	-RRB-
we	PRP
can	MD
observe	VB
that	IN
the	DT
performance	NN
of	IN
the	DT
TS3VM	NN
model	NN
has	VBZ
a	DT
signiÔ	NN
¨	CD
cant	JJ
improvement	NN
when	WRB
Cn	NN
increases	VBZ
from	IN
0	CD
-LRB-	-LRB-
where	WRB
the	DT
accuracy	NN
is	VBZ
about	IN
0.93	CD
-RRB-	-RRB-
to	TO
1	CD
-LRB-	-LRB-
where	WRB
the	DT
accuracy	NN
is	VBZ
above	IN
0.96	CD
-RRB-	-RRB-
.	.

That	DT
is	VBZ
to	TO
say	VB
,	,


adding	VBG
T3	NN
for	IN
training	NN
will	MD
signiÔ	VB
¨	CD
cantly	RB
improve	VB
the	DT
accuracy	NN
.	.

Based	VBN
on	IN
these	DT
observations	NNS
,	,
in	IN
the	DT
following	VBG
experiments	NNS
,	,
we	PRP
set	VBD
C1	NN
to	TO
10	CD
and	CC
the	DT
remaining	VBG
parameters	NNS
to	TO
1	CD
.	.


For	IN
the	DT
RK	NN
model	NN
,	,
the	DT
key	JJ
parameter	NN
is	VBZ
k	NN
,	,
i.e.	FW
,	,
the	DT
number	NN
of	IN
clusters	NNS
in	IN
Algorithm	NNP
3	CD
.	.

Intuitively	RB
,	,
increasing	VBG
k	NN
is	VBZ
equivalent	JJ
to	TO
increasing	VBG
the	DT
number	NN
of	IN
feature	NN
vectors	NNS
,	,
which	WDT
is	VBZ
supposed	VBN
to	TO
enhance	VB
the	DT
performance	NN
.	.

Our	PRP$
experimental	JJ
settings	NNS
were	VBD
as	IN
follows	VBZ
:	:
the	DT
TS3VM	NN
model	NN
was	VBD
tested	VBN
on	IN
100	CD
data	NNS
chunks	NNS
each	DT
containing	VBG
500	CD
examples	NNS
.	.

The	DT
probability	NN
of	IN
concept	NN
evolution	NN
/	:
change	NN
was	VBD
90	CD
%	NN
and	CC
only	RB
5	CD
%	NN
examples	NNS
were	VBD
labeled	VBN
.	.

From	IN
Fig.	NN
7	CD
we	PRP
can	MD
observe	VB
that	IN
when	WRB
setting	VBG
k	NN
to	TO
2	CD
,	,
there	EX
is	VBZ
a	DT
signiÔ	NN
¨	CD
cant	JJ
accuracy	NN
improvement	NN
-LRB-	-LRB-
from	IN
0.9291	CD
to	TO
0.9482	CD
-RRB-	-RRB-
.	.

After	IN
that	DT
,	,
the	DT
improvement	NN
becomes	VBZ
marginal	JJ
-LRB-	-LRB-
from	IN
0.9482	CD
to	TO
0.9516	CD
-RRB-	-RRB-
.	.

There	EX
-	:
fore	NN
,	,
in	IN
our	PRP$
following	VBG
experiments	NNS
,	,
we	PRP
set	VBD
k	NN
to	TO
2	CD
.	.


4.3	CD
.	.

Model	NNP
study	NN


In	IN
this	DT
series	NN
of	IN
experiments	NNS
,	,
we	PRP
studied	VBD
the	DT
performances	NNS
of	IN
the	DT
four	CD
learning	NN
models	NNS
under	IN
different	JJ
concept	NN
drifting	VBG
prob	NN
-	:
ability	NN
c	NN
and	CC
labeling	NN
percentage	NN
l	NN
.	.

We	PRP
designed	VBD
four	CD
experiments	NNS
,	,
each	DT
corresponding	VBG
to	TO
a	DT
different	JJ
combination	NN
of	IN
parameters	NNS
c	NN
and	CC
l	NN
representing	VBG
one	CD
of	IN
the	DT
four	CD
learning	NN
cases	NNS
.	.

All	DT
results	NNS
were	VBD
averaged	VBN
over	IN
100	CD
continuous	JJ
data	NNS
chunks	NNS
.	.


Case	NNP
1	CD
:	:
In	IN
the	DT
Ô	NN
¨	NN
rst	NN
experiment	NN
,	,
the	DT
concept	NN
drifting	VBG
probability	NN
was	VBD
set	VBN
to	TO
a	DT
very	RB
low	JJ
value	NN
of	IN
10	CD
%	NN
,	,
and	CC
the	DT
labeling	NN
percentage	NN
was	VBD
set	VBN
to	TO
a	DT
high	JJ
value	NN
of	IN
90	CD
%	NN
.	.

The	DT
proportion	NN
of	IN
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
can	MD
be	VB
calculated	VBN
as	IN
in	IN
Fig.	NN
8	CD
.	.

Obviously	RB
,	,
most	JJS
training	NN
examples	NNS
in	IN
this	DT
case	NN
are	VBP
of	IN
Type	NN
I	CD
.	.

The	DT
experiments	NNS
with	IN
respect	NN
to	TO
different	JJ
chunk	NN
sizes	NNS
D	NN
are	VBP
shown	VBN
in	IN
Table	NNP
1	CD
.	.

From	IN
the	DT
results	NNS
we	PRP
can	MD
observe	VB
that	IN
the	DT
SVM	NNP
model	NN
performs	VBZ
almost	RB
as	RB
well	RB
as	IN
other	JJ
three	CD
more	RBR
sophisticated	JJ
models	NNS
in	IN
terms	NNS
of	IN
accuracy	NN
.	.

This	DT
is	VBZ
because	IN
T1	NN
examples	NNS
dominate	VBP
the	DT
training	NN
chunk	NN
,	,
and	CC
we	PRP
can	MD
achieve	VB
satisfactory	JJ
results	NNS
by	IN
using	VBG
only	RB
T1	NN
for	IN
training	NN
.	.

Furthermore	RB
,	,
from	IN
Fig.	NNP
9	CD
,	,
we	PRP
can	MD
see	VB
that	IN
SVM	NNP
is	VBZ
the	DT



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
8	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



178	CD


P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


Fig.	NN
8	CD
.	.

Proportion	NN
of	IN
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
in	IN
Case	NNP
1	CD
.	.


Table	NNP
1	CD


Case	NNP
1	CD
accuracy	NN
study	NN
.	.


Learning	NNP
models	NNS
Chunk	NNP
size	NN


n¬	NN
1/4	CD
100	CD


n¬	NN
1/4	CD
500	CD


n¬	NN
1/4	CD
1000	CD


SVM	NN
0.9877	CD


70.02	CD
S3VM	NN
0.9893	CD


70.02	CD
TS3VM	NN
0.9910	CD


70.02	CD
RK-TS3VM	NN
0.9922	CD


70.01	CD


0.9902	CD


70.02	CD
0.9902	CD


70.02	CD
0.9922	CD


70.01	CD
0.9962	CD


70.01	CD


0.9945	CD


70.01	CD
0.9955	CD


70.01	CD
0.9967	CD


70.01	CD
0.9973	CD


70.01	CD


500	CD


400	CD


300	CD


S3VM	NN


TS3VM	NN


RK-TS3VM	NN


200	CD


SVM	NN


Training	VBG
Time	NNP
-LRB-	-LRB-
ms	NNS
-RRB-	-RRB-


100	CD


0	CD


Fig.	NNP
9	CD
.	.

Training	VBG
time	NN
of	IN
the	DT
four	CD
models	NNS
in	IN
Case	NNP
1	CD
.	.


Fig.	NN
10	CD
.	.

Proportion	NN
of	IN
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
in	IN
Case	NN
2	CD
.	.


Table	NNP
2	CD


Case	NN
2	CD
accuracy	NN
study	NN
.	.


Learning	NNP
models	NNS
Chunk	NNP
size	NN


n¬	NN
1/4	CD
100	CD


n¬	NN
1/4	CD
500	CD


n¬	NN
1/4	CD
1000	CD


SVM	NN
0.8560	CD


70.07	CD
S3VM	NN
0.9293	CD


70.04	CD
TS3VM	NN
0.9297	CD


70.04	CD
RK-TS3VM	NN
0.9330	CD


70.01	CD


0.8792	CD


70.07	CD
0.9575	CD


70.04	CD
0.9575	CD


70.04	CD
0.9610	CD


70.01	CD


0.8946	CD


70.04	CD
0.9621	CD


70.01	CD
0.9622	CD


70.01	CD
0.9660	CD


70.01	CD


most	RBS
efÔ	JJ
¨	NN
cient	JJ
model	NN
compared	VBN
to	TO
its	PRP$
peers	NNS
.	.

Therefore	RB
,	,
we	PRP
can	MD
conclude	VB
that	IN
SVM	NNP
is	VBZ
a	DT
better	JJR
trade-off	NN
option	NN
of	IN
models	NNS
when	WRB
Type	NN
I	CD
examples	NNS
dominate	VBP
the	DT
training	NN
chunk	NN
-LRB-	-LRB-
i.e.	FW
,	,
when	WRB
concept	NN
drifting	VBG
probability	NN
is	VBZ
low	JJ
and	CC
labeling	NN
percentage	NN
is	VBZ
high	JJ
-RRB-	-RRB-
.	.


Case	NN
2	CD
:	:
In	IN
the	DT
second	JJ
experiment	NN
,	,
both	CC
concept	NN
drifting	VBG
probability	NN
and	CC
labeling	NN
percentage	NN
were	VBD
set	VBN
to	TO
a	DT
very	RB
low	JJ
value	NN
of	IN
10	CD
%	NN
.	.

In	IN
this	DT
situation	NN
,	,
Type	NN
III	CD
examples	NNS
,	,
as	IN
shown	VBN
in	IN
Fig.	NNP
10	CD
,	,
dominate	VB
the	DT
training	NN
chunk	NN
.	.

The	DT
results	NNS
with	IN
respect	NN
to	TO
different	JJ


chunk	NN
sizes	NNS
are	VBP
presented	VBN
in	IN
Table	NNP
2	CD
.	.

We	PRP
can	MD
observe	VB
that	IN
S3VM	NN
outperforms	VBZ
SVM	NNP
,	,
and	CC
is	VBZ
almost	RB
as	RB
good	JJ
as	IN
other	JJ
two	CD
models	NNS
in	IN
terms	NNS
of	IN
accuracy	NN
.	.

From	IN
Fig.	NNP
11	CD
we	PRP
can	MD
observe	VB
that	IN
S3VM	NN
is	VBZ
more	RBR
efÔ	JJ
¨	NN
cient	NN
than	IN
both	DT
TS3VM	NN
and	CC
RK-TS3VM	NN
.	.

Therefore	RB
,	,
we	PRP
can	MD
conclude	VB
that	IN
S3VM	NN
is	VBZ
a	DT
better	JJR
trade-off	NN
option	NN
of	IN
models	NNS
when	WRB
Type	NN
III	CD
examples	NNS
dominates	VBZ
the	DT
training	NN
chunk	NN
-LRB-	-LRB-
i.e.	FW
,	,
both	DT
concept	NN
drifting	VBG
probability	NN
and	CC
labeling	NN
percentage	NN
are	VBP
low	JJ
-RRB-	-RRB-
.	.


Case	NNP
3	CD
:	:
In	IN
the	DT
third	JJ
experiment	NN
,	,
drifting	VBG
probability	NN
was	VBD
set	VBN
to	TO
a	DT
high	JJ
value	NN
of	IN
70	CD
%	NN
and	CC
labeling	NN
percentage	NN
to	TO
a	DT
high	JJ
value	NN
of	IN
90	CD
%	NN
.	.

The	DT
proportion	NN
of	IN
the	DT
four	CD
types	NNS
training	NN
examples	NNS
can	MD
be	VB
calculated	VBN
as	IN
in	IN
Fig.	NNP
12	CD
.	.

Obviously	RB
,	,
most	JJS
training	NN
examples	NNS
in	IN
this	DT
case	NN
are	VBP
of	IN
Type	NN
II	CD
.	.

The	DT
experiments	NNS
with	IN
respect	NN
to	TO
different	JJ
chunk	NN
sizes	NNS
are	VBP
shown	VBN
in	IN
Table	NNP
3	CD
.	.

From	IN
the	DT
results	NNS
we	PRP
can	MD
observe	VB
that	IN
TS3VM	NN
signiÔ	NN
¨	NN
cantly	RB
outperforms	VBZ
other	JJ
two	CD
models	NNS
SVM	NN
and	CC
S3VM	NN
,	,
and	CC
is	VBZ
almost	RB
as	RB
good	JJ
as	IN
RK-TS3VM	NN
in	IN
terms	NNS
of	IN
accuracy	NN
.	.

This	DT
is	VBZ
because	IN
T3	NN
examples	NNS
dominate	VBP
the	DT
training	NN
examples	NNS
,	,
and	CC
TS3VM	NN
learns	VBZ
from	IN
T3	NN
,	,
T2	NN
and	CC
T1	NN
simultaneously	RB
.	.

Furthermore	RB
,	,
from	IN
Fig.	NNP
13	CD
,	,
wecanseethatTS3VM	NN
is	VBZ
much	RB
more	JJR
efÔ	NN
¨	NN
cient	NN
than	IN
RK-TS3VM	NN
.	.

Therefore	RB
,	,
we	PRP
can	MD
conclude	VB
that	IN
TS3VM	NN
is	VBZ
a	DT
better	JJR
trade-off	NN
option	NN
of	IN
models	NNS
when	WRB
Type	NN
II	CD
examples	NNS
dominate	VBP
the	DT
training	NN
chunk	NN
-LRB-	-LRB-
i.e.	FW
,	,
both	DT
concept	NN
drifting	VBG
probability	NN
and	CC
labeling	NN
percentage	NN
are	VBP
high	JJ
-RRB-	-RRB-
.	.


Case	NNP
4	CD
:	:
In	IN
the	DT
last	JJ
experiment	NN
,	,
concept	NN
drifting	VBG
probability	NN
was	VBD
set	VBN
to	TO
a	DT
high	JJ
value	NN
of	IN
70	CD
%	NN
and	CC
labeling	NN
percentage	NN
was	VBD
set	VBN
to	TO
a	DT
low	JJ
value	NN
of	IN
10	CD
%	NN
.	.

The	DT
proportion	NN
of	IN
the	DT
four	CD
types	NNS
training	NN
examples	NNS
is	VBZ
shown	VBN
in	IN
Fig.	NNP
14	CD
.	.

In	IN
this	DT
case	NN
,	,
Type	NN
IV	CD
examples	NNS
dominate	VBP
the	DT
training	NN
chunk	NN
.	.

The	DT
results	NNS
with	IN
respect	NN
to	TO
different	JJ
chunk	NN
sizes	NNS
are	VBP
shown	VBN
in	IN
Table	NNP
4	CD
.	.

We	PRP
can	MD
observe	VB
that	IN
RK-TS	NN


3VM	NN
signiÔ	NN
¨	NN
cantly	RB


500	CD


400	CD


RK-TS3VM	NN


300	CD


S3VM	NN


TS3VM	NN


200	CD


Training	VBG
Time	NNP
-LRB-	-LRB-
ms	NNS
-RRB-	-RRB-


100	CD


SVM	NN


0	CD


Fig.	NN
11	CD
.	.

Training	VBG
time	NN
of	IN
the	DT
four	CD
models	NNS
in	IN
Case	NN
2	CD
.	.


Fig.	NN
12	CD
.	.

Proportion	NN
of	IN
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
in	IN
Case	NNP
3	CD
.	.


Table	NNP
3	CD


Case	NNP
3	CD
accuracy	NN
study	NN
.	.


Learning	NNP
models	NNS
Chunk	NNP
size	NN


n¬	NN
1/4	CD
100	CD


n¬	NN
1/4	CD
500	CD


n¬	NN
1/4	CD
1000	CD


SVM	NN
0.8311	CD


70.06	CD
S3VM	NN
0.8669	CD


70.04	CD
TS3VM	NN
0.9321	CD


70.04	CD
RK-TS3VM	NN
0.9330	CD


70.02	CD


0.8580	CD


70.04	CD
0.9072	CD


70.03	CD
0.9503	CD


70.02	CD
0.9522	CD


70.02	CD


0.8602	CD


70.02	CD
0.9101	CD


70.02	CD
0.9543	CD


70.02	CD
0.9545	CD


70.01	CD



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
9	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


179	CD


500	CD


400	CD


300	CD


RK-TS3VM	NN


TS3VM	NN


200	CD


S3VM	NN


Training	VBG
Time	NNP
-LRB-	-LRB-
ms	NNS
-RRB-	-RRB-


100	CD


SVM	NN


0	CD


Fig.	NNP
13	CD
.	.

Training	VBG
time	NN
of	IN
the	DT
four	CD
models	NNS
in	IN
Case	NNP
3	CD
.	.


Fig.	NN
14	CD
.	.

Proportion	NN
of	IN
the	DT
four	CD
types	NNS
of	IN
training	NN
examples	NNS
in	IN
Case	NNP
4	CD
.	.


Table	NNP
4	CD


Case	NNP
4	CD
accuracy	NN
study	NN
.	.


Learning	NNP
models	NNS
Chunk	NNP
size	NN


n¬	NN
1/4	CD
100	CD


n¬	NN
1/4	CD
500	CD


n¬	NN
1/4	CD
1000	CD


SVM	NN
0.795070.07	CD
S3VM	NN
0.821270.05	CD
TS3VM	NN
0.823170.05	CD
RK-TS3VM	NN
0.884370.04	CD


0.801170.05	CD
0.831070.04	CD
0.824270.04	CD
0.891070.04	CD


0.812970.03	CD
0.833270.03	CD
0.826670.02	CD
0.901870.02	CD


800	CD


700	CD


RK-TS3VM	NN


600	CD


500	CD


In	IN
order	NN
to	TO
decide	VB
the	DT
learning	NN
model	NN
,	,
we	PRP
need	VBP
to	TO
identify	VB
the	DT
main	JJ
type	NN
of	IN
examples	NNS
in	IN
the	DT
training	NN
chunk	NN
.	.

For	IN
this	DT
purpose	NN
,	,
we	PRP
need	VBP
to	TO
detect	VB
the	DT
concept	NN
drifting	VBG
probability	NN
c	NN
and	CC
decide	VB
the	DT
labeling	NN
rate	NN
l	NN
.	.

While	IN
several	JJ
concept	NN
change	NN
detection	NN
methods	NNS
are	VBP
available	JJ
-LSB-	-LRB-
16,20	CD
-RSB-	-RRB-
,	,
for	IN
simplicity	NN
-LRB-	-LRB-
we	PRP
do	VBP
not	RB
need	VB
very	RB
accurate	JJ
estimates	NNS
-RRB-	-RRB-
,	,
we	PRP
used	VBD
prediction	NN
accuracy	NN
to	TO
approximate	JJ
concept	NN
drifting	VBG
probability	NN
.	.

SpeciÔ	NN
¨	NN
cally	RB
,	,
we	PRP
Ô	VBP
¨	CD
rst	JJ
assume	VB
that	IN
all	PDT
the	DT
stream	NN
examples	NNS
are	VBP
labeled	VBN
.	.

If	IN
there	EX
is	VBZ
no	DT
concept	NN
drifting	VBG
,	,
the	DT
prediction	NN
accuracy	NN
will	MD
be	VB
close	JJ
to	TO
100	CD
%	NN
.	.

Otherwise	RB
,	,
the	DT
predic	JJ
-	:
tion	NN
error	NN
rate	NN
can	MD
be	VB
used	VBN
to	TO
approximate	JJ
the	DT
concept	NN
drifting	VBG
probability	NN
.	.

Fig.	NN
16	CD
shows	VBZ
the	DT
prediction	NN
accuracy	NN
over	IN
50	CD
con	NN
-	:
tinuous	JJ
data	NNS
chunks	NNS
of	IN
the	DT
three	CD
data	NNS
streams	NNS
.	.

The	DT
average	JJ
accuracy	NN
values	NNS
for	IN
the	DT
three	CD
streams	NNS
are	VBP
84.32	CD
%	NN
,	,
91.07	CD
%	NN
and	CC
99.13	CD
%	NN
,	,
respectively	RB
.	.

Thus	RB
,	,
the	DT
concept	NN
drifting	VBG
probability	NN
in	IN
the	DT
three	CD
streams	NNS
are	VBP
approximately	RB
15	CD
%	NN
,	,
10	CD
%	NN
and	CC
1	CD
%	NN
,	,
respectively	RB
.	.


The	DT
labeling	NN
rate	NN
depends	VBZ
on	IN
the	DT
labeling	NN
experts	NNS
.	.

They	PRP
were	VBD
set	VBN
to	TO
10	CD
%	NN
,	,
10	CD
%	NN
and	CC
90	CD
%	NN
,	,
respectively	RB
,	,
for	IN
the	DT
three	CD
streams	NNS
.	.

By	IN
doing	VBG
so	RB
,	,
in	IN
the	DT
wireless	JJ
sensor	NN
and	CC
power	NN
supply	NN
streams	NNS
,	,
Type	NN
II	CD
examples	NNS
dominate	VBP
the	DT
training	NN
trunk	NN
.	.

In	IN
the	DT
intrusion	NN
detection	NN
stream	NN
,	,
Type	NN
I	CD
examples	NNS
dominate	VBP
the	DT
training	NN
chunk	NN
.	.


Fig.	NN
17	CD
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
shows	VBZ
chunk-by-chunk	JJ
comparisons	NNS
for	IN
the	DT
four	CD
learn	VBP
-	:
ing	NN
models	NNS
on	IN
the	DT
sensor	NN
stream	NN
.	.

We	PRP
can	MD
observe	VB
that	IN
SVM	NNP
always	RB
has	VBZ
the	DT
worst	JJS
prediction	NN
accuracy	NN
.	.

The	DT
remaining	VBG
three	CD
models	NNS
performed	VBN
similarly	RB
and	CC
better	RB
than	IN
SVM	NN
.	.

Fig.	NN
18	CD
-LRB-	-LRB-
a	DT
-RRB-	-RRB-
shows	VBZ
compar	NN
-	:
isons	NNS
on	IN
time	NN
cost	NN
for	IN
the	DT
four	CD
models	NNS
.	.

We	PRP
can	MD
observe	VB
that	IN
S3VM	NN
is	VBZ
not	RB
as	IN
efÔ	NN
¨	CD
cient	NN
as	IN
SVM	NNP
,	,
but	CC
better	JJR
than	IN
the	DT
remaining	VBG
two	CD
models	NNS
.	.

Considering	VBG
both	DT
prediction	NN
accuracy	NN
and	CC
efÔ	NN
¨	CD
ciency	NN
,	,
we	PRP
can	MD
conclude	VB
that	IN
S3VM	NN
is	VBZ
the	DT
best	JJS
trade-off	NN
option	NN
of	IN
models	NNS
for	IN
classifying	VBG
the	DT
sensor	NN
stream	NN
data	NNS
.	.

Similar	JJ
results	NNS
,	,
as	IN
shown	VBN
in	IN
Figs.	NNP
17	CD
-LRB-	-LRB-
b	NN
-RRB-	-RRB-
and	CC
18	CD
-LRB-	-LRB-
b	NN
-RRB-	-RRB-
,	,
can	MD
also	RB
be	VB
observed	VBN
for	IN
the	DT
power	NN
supply	NN
stream	NN
.	.


Figs.	NNP
18	CD
-LRB-	-LRB-
c	NN
-RRB-	-RRB-
and	CC
17	CD
-LRB-	-LRB-
c	NN
-RRB-	-RRB-
show	VBP
comparisons	NNS
on	IN
the	DT
KDDCUP‚	NNP
$	$
ô	CD
99	CD
intrusion	NN
detection	NN
stream	NN
.	.

We	PRP
can	MD
observe	VB
that	IN
SVM	NNP
has	VBZ
the	DT
lowest	JJS
time	NN
cost	NN
.	.

On	IN
the	DT
other	JJ
hand	NN
,	,
SVM	NN
can	MD
achieve	VB
similar	JJ
prediction	NN
accuracies	NNS
to	TO
other	JJ
three	CD
models	NNS
over	IN
the	DT
continuous	JJ
50	CD
data	NNS
chunks	NNS
.	.

Therefore	RB
,	,
we	PRP
can	MD
conclude	VB
that	IN
SVM	NNP
is	VBZ
the	DT
best	JJS
trade-off	NN
option	NN
of	IN
models	NNS
in	IN
this	DT
case	NN
.	.


Another	DT
important	JJ
observation	NN
is	VBZ
that	IN
in	IN
all	DT
of	IN
the	DT
above	JJ
experiments	NNS
,	,
the	DT
proposed	VBN
RK-TS3VM	NN
model	NN
often	RB
had	VBD
the	DT
high	JJ
-	:
est	NN
prediction	NN
accuracy	NN
.	.

However	RB
,	,
due	JJ
to	TO
the	DT
complexity	NN
of	IN
the	DT
model	NN
,	,
it	PRP
always	RB
has	VBZ
the	DT
highest	JJS
time	NN
cost	NN
.	.

Therefore	RB
,	,
this	DT
model	NN
is	VBZ
preferred	VBN
in	IN
accuracy-critical	JJ
applications	NNS
where	WRB
the	DT
concept	NN
drifting	VBG
probability	NN
is	VBZ
high	JJ
and	CC
the	DT
labeling	NN
rate	NN
is	VBZ
low	JJ
.	.


400	CD


300	CD


5	CD
.	.

Related	JJ
work	NN


Training	VBG
Time	NNP
-LRB-	-LRB-
ms	NNS
-RRB-	-RRB-


200	CD


S3VM	NN


TS3VM	NN


100	CD


SVM	NN


0	CD


Fig.	NNP
15	CD
.	.

Training	VBG
time	NN
of	IN
the	DT
four	CD
models	NNS
in	IN
Case	NNP
4	CD
.	.


outperforms	VBZ
all	DT
other	JJ
models	NNS
in	IN
terms	NNS
of	IN
accuracy	NN
.	.

On	IN
the	DT
other	JJ
hand	NN
,	,
we	PRP
were	VBD
unable	JJ
to	TO
achieve	VB
accurate	JJ
results	NNS
by	IN
training	NN
only	RB
on	IN
T1	NN
,	,
T2	NN
and	CC
T3	NN
.	.

That	DT
is	VBZ
to	TO
say	VB
,	,
in	IN
this	DT
case	NN
,	,
we	PRP
have	VBP
to	TO
incorporate	VB
T4	NN
into	IN
training	NN
even	RB
if	IN
it	PRP
is	VBZ
time-wise	JJ
costly	JJ
as	IN
shown	VBN
in	IN
Fig.	NNP
15	CD
.	.

The	DT
results	NNS
validate	VBP
our	PRP$
claim	NN
that	IN
learning	VBG
under	IN
Case	NNP
4	CD
is	VBZ
the	DT
most	RBS
difÔ	JJ
¨	NN
cult	NN
,	,
and	CC
we	PRP
have	VBP
to	TO
use	VB
the	DT
RK-TS3VM	NN
model	NN
to	TO
gain	VB
satisfactory	JJ
accuracy	NN
.	.


4.4	CD
.	.

Experiments	NNS
on	IN
real-world	JJ
streams	NNS


In	IN
this	DT
series	NN
of	IN
experiments	NNS
,	,
we	PRP
compared	VBD
the	DT
four	CD
learning	NN
models	NNS
on	IN
three	CD
real-world	JJ
data	NNS
streams	NNS
:	:
wireless	JJ
sensor	NN
stream	NN
,	,
power	NN
supply	NN
stream	NN
,	,
and	CC
intrusion	NN
detection	NN
stream	NN
.	.


The	DT
work	NN
reported	VBN
in	IN
this	DT
paper	NN
applies	VBZ
sophisticated	JJ
machine	NN
learning	VBG
models	NNS
,	,
such	JJ
as	IN
transfer	NN
learning	NN
-LSB-	-LRB-
9	CD
-RSB-	-RRB-
and	CC
semi-super	NN
-	:
vised	VBN
learning	VBG
-LSB-	-LRB-
27	CD
-RSB-	-RRB-
,	,
to	TO
real-world	JJ
data	NNS
stream	NN
classiÔ	NN
¨	CD
cation	NN
-LSB-	-LRB-
40,42,33,2	CD
-RSB-	-RRB-
.	.


Two	CD
types	NNS
of	IN
classiÔ	NN
¨	CD
cation	NN
models	NNS
have	VBP
been	VBN
proposed	VBN
for	IN
data	NNS
stream	NN
classiÔ	NN
¨	CD
cation	NN
:	:
incremental	JJ
learning	NN
-LSB-	-LRB-
10,11	CD
-RSB-	-RRB-
and	CC
ensemble	NN
learning	NN
-LSB-	-LRB-
35,32,39,41,36	CD
-RSB-	-RRB-
.	.

The	DT
former	JJ
uses	NNS
new	JJ
data	NNS
to	TO
update	VB
models	NNS
trained	VBN
from	IN
historical	JJ
stream	NN
data	NNS
.	.

By	IN
doing	VBG
so	RB
,	,
the	DT
learning	VBG
process	NN
scales	NNS
to	TO
large	JJ
data	NNS
volumes	NNS
as	RB
well	RB
as	IN
adapts	NNS
to	TO
changing	VBG
concepts	NNS
.	.

For	IN
example	NN
,	,
Domingos	NNP
-LSB-	-LRB-
11	CD
-RSB-	-RRB-
proposed	VBD
a	DT
fast	JJ
decision	NN
tree	NN
learner	NN
VFDT	NNP
that	WDT
incrementally	RB
builds	VBZ
Hoeffding	JJ
trees	NNS
from	IN
overwhelming	JJ
volume	NN
of	IN
fast	JJ
Ô	NN
¨	CD
Ç	CD
owing	JJ
data	NNS
streams	NNS
.	.

An	DT
extended	JJ
approach	NN
CVFDT	NN
-LSB-	-LRB-
17	CD
-RSB-	-RRB-
handles	VBZ
time	NN
changing	VBG
and	CC
concept	NN
evolution	NN
streams	NNS
.	.

Other	JJ
methods	NNS
-LSB-	-LRB-
25	CD
-RSB-	-RRB-
also	RB
attempted	VBD
to	TO
employ	VB
incremental	JJ
learning	VBG
to	TO
tackle	VB
the	DT
challenge	NN
of	IN
concept	NN
evolution	NN
.	.


Ensemble	NN
learning	NN
,	,
on	IN
the	DT
other	JJ
hand	NN
,	,
trains	NNS
a	DT
number	NN
of	IN
base	NN
models	NNS
from	IN
a	DT
small	JJ
portion	NN
of	IN
stream	NN
data	NNS
-LRB-	-LRB-
i.e.	FW
,	,
a	DT
data	NN
chunk	NN
-RRB-	-RRB-
,	,
and	CC
combines	VBZ
all	DT
base	NN
models	NNS
to	TO
form	VB
an	DT
ensemble	NN
classiÔ	NN
¨	CD
er	NN
for	IN
prediction	NN
.	.

Existing	VBG
ensemble	NN
frameworks	NNS
can	MD
be	VB
further	RB



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
10	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



180	CD


P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


Fig.	NN
16	CD
.	.

Average	JJ
accuracy	NN
over	IN
50	CD
data	NNS
chunks	NNS
on	IN
the	DT
three	CD
data	NNS
streams	NNS
.	.

-LRB-	-LRB-
a	DT
-RRB-	-RRB-
Wireless	NNP
sensor	NN
,	,
-LRB-	-LRB-
b	LS
-RRB-	-RRB-
power	NN
supply	NN
and	CC
-LRB-	-LRB-
c	LS
-RRB-	-RRB-
intrusion	NN
detection	NN
.	.


Fig.	NN
17	CD
.	.

Chunk	NN
by	IN
chunk	NN
comparisons	NNS
of	IN
the	DT
Ô	NN
¨	CD
rst	NN
50	CD
data	NNS
chunks	NNS
on	IN
the	DT
three	CD
data	NNS
streams	NNS
.	.

-LRB-	-LRB-
a	DT
-RRB-	-RRB-
Wireless	NNP
sensor	NN
,	,
-LRB-	-LRB-
b	LS
-RRB-	-RRB-
power	NN
supply	NN
and	CC
-LRB-	-LRB-
c	LS
-RRB-	-RRB-
intrusion	NN
detection	NN
.	.


300	CD


300	CD


250	CD


250	CD


200	CD


RK-TS3VM	NN


200	CD


150	CD


S3VM	NN


TS3VM	NN


150	CD


S3VM	NN


100	CD


100	CD


Training	VBG
Time	NNP
-LRB-	-LRB-
ms	NNS
-RRB-	-RRB-


50	CD


Training	VBG
Time	NNP
-LRB-	-LRB-
ms	NNS
-RRB-	-RRB-


SVM	NN


50	CD


SVM	NN


0	CD


0	CD


S3VM	NN


RK-TS3VM	NN
TS3VM	NN


RK-TS3VM	NN


SVM	NN


TS3VM	NN


Training	VBG
Time	NNP
-LRB-	-LRB-
ms	NNS
-RRB-	-RRB-


400†350†300†250	CD
200†150†100	CD
50	CD


0	CD


Fig.	NN
18	CD
.	.

Training	VBG
time	NN
comparisons	NNS
on	IN
the	DT
three	CD
data	NNS
streams	NNS
.	.

-LRB-	-LRB-
a	DT
-RRB-	-RRB-
Wireless	NNP
sensor	NN
,	,
-LRB-	-LRB-
b	LS
-RRB-	-RRB-
power	NN
supply	NN
and	CC
-LRB-	-LRB-
c	LS
-RRB-	-RRB-
intrusion	NN
detection	NN
.	.


categorized	VBN
into	IN
two	CD
paradigms	NNS
:	:
horizontal	JJ
ensemble	NN
that	WDT
builds	VBZ
base	NN
classiÔ	NN
¨	CD
ers	NNPS
on	IN
different	JJ
buffered	VBN
chunks	NNS
by	IN
using	VBG
one	CD
single	JJ
learning	VBG
algorithm	NN
,	,
and	CC
vertical	JJ
ensemble	NN
that	WDT
builds	VBZ
base	NN
classi	NN
-	:
Ô	NN
¨	CD
ers	NNPS
on	IN
the	DT
most-recent	JJ
buffered	JJ
chunk	NN
by	IN
using	VBG
various	JJ
learning	VBG
algorithms	NNS
.	.


A	DT
large	JJ
portion	NN
of	IN
ensemble	NN
methods	NNS
belong	VBP
to	TO
the	DT
horizontal	JJ
ensemble	NN
paradigm	NN
.	.

For	IN
example	NN
,	,
Street	NNP
-LSB-	-LRB-
24	CD
-RSB-	-RRB-
proposed	VBD
a	DT
SEA	NN
algo	NN
-	:
rithm	NN
that	WDT
combines	VBZ
decision	NN
tree	NN
models	NNS
using	VBG
majority	NN
voting	NN
.	.

Kolter	NNP
-LSB-	-LRB-
21	CD
-RSB-	-RRB-
proposed	VBD
an	DT
ensemble	NN
method	NN
by	IN
using	VBG
weighted	JJ
online	JJ
learners	NNS
to	TO
handle	VB
drifting	VBG
concepts	NNS
.	.

Wang	NNP
et	FW
al.	FW
-LSB-	-LRB-
18	CD
-RSB-	-RRB-
proposed	VBD
an	DT
accuracy-weighted	JJ
ensemble	NN
method	NN
that	WDT
assigns	VBZ
each	DT
classiÔ	NN
¨	CD
er	NN
a	DT
weight	NN
reversely	RB
proportional	JJ
to	TO
its	PRP$
accuracy	NN
on	IN
the	DT
most	RBS
recent	JJ
data	NNS
chunk	NN
.	.

Yang	NNP
et	FW
al.	FW
-LSB-	-LRB-
28	CD
-RSB-	-RRB-
proposed	VBD
proactive	JJ
learning	NN
where	WRB
concepts	NNS
-LRB-	-LRB-
models	NNS
-RRB-	-RRB-
learnt	VBN
from	IN
previous	JJ
data	NNS
chunks	NNS
are	VBP
used	VBN
to	TO
foresee	VB
the	DT
best	JJS
model	NN
to	TO
predict	VB
data	NNS
in	IN
the	DT
current	JJ
chunk	NN
.	.

Zhu	NNP
et	FW
al.	FW
-LSB-	-LRB-
41	CD
-RSB-	-RRB-
proposed	VBD
an	DT
active	JJ
learning	NN
framework	NN
that	WDT
selectively	RB
labels	VBZ
exam	NN
-	:
ples	NNS
for	IN
concept	NN
evolution	NN
data	NNS
streams	NNS
.	.


Some	DT
most	RBS
recent	JJ
ensemble	NN
methods	NNS
,	,
however	RB
,	,
belong	VBP
to	TO
the	DT
vertical	JJ
ensemble	NN
paradigm	NN
.	.

For	IN
example	NN
,	,
Gao	NNP
et	FW
al.	FW
-LSB-	-LRB-
14	CD
-RSB-	-RRB-
and	CC
Zhang	NNP
et	FW
al.	FW
-LSB-	-LRB-
34	CD
-RSB-	-RRB-
.	.

Without	IN
the	DT
prior	JJ
knowledge	NN
that	WDT
when	WRB
and	CC
where	WRB
concept	NN
evolution	NN
may	MD
occur	VB
,	,
buffered	VBN
data	NNS
chunks	NNS
may	MD
contain	VB
obsolete	JJ
patterns	NNS
that	WDT
deteriorate	VBP
the	DT
ensemble‚	NN
$	$
ô	CD
s	NNS


performance	NN
.	.

Based	VBN
on	IN
this	DT
observation	NN
,	,
they	PRP
proposed	VBD
a	DT
new	JJ
approach	NN
that	WDT
builds	VBZ
the	DT
ensemble	NN
only	RB
from	IN
the	DT
most	RBS
recent	JJ
data	NNS
chunk	NN
by	IN
using	VBG
different	JJ
learning	NN
algorithms	NNS
such	JJ
as	IN
decision	NN
tree	NN
,	,
SVMs	NNS
,	,
and	CC
logistic	JJ
regression	NN
models	NNS
.	.


Existing	VBG
data	NNS
stream	NN
classiÔ	NN
¨	CD
cation	NN
models	NNS
assume	VBP
that	IN
training	NN
examples	NNS
are	VBP
fully	RB
labeled	VBN
.	.

However	RB
,	,
labeling	NN
by	IN
experts	NNS
is	VBZ
very	RB
expensive	JJ
.	.

For	IN
stream	NN
data	NNS
with	IN
large	JJ
,	,
continuous	JJ
volumes	NNS
,	,
this	DT
assumption	NN
would	MD
not	RB
hold	VB
.	.

In	IN
other	JJ
words	NNS
,	,
in	IN
practice	NN
,	,
training	NN
data	NNS
are	VBP
often	RB
partially	RB
labeled	VBN
.	.


Learning	NNP
from	IN
unlabeled	JJ
examples	NNS
has	VBZ
been	VBN
widely	RB
studied	VBN
in	IN
the	DT
machine	NN
learning	NN
and	CC
data	NNS
mining	NN
communities	NNS
.	.

For	IN
this	DT
purpose	NN
many	JJ
semi-supervised	JJ
learning	NN
models	NNS
-LSB-	-LRB-
19,6	CD
-RSB-	-RRB-
have	VBP
been	VBN
proposed	VBN
.	.

Meanwhile	RB
,	,
algorithms	NNS
such	JJ
as	IN
EM	NN
with	IN
generative	JJ
mixture	NN
models	NNS
-LSB-	-LRB-
23	CD
-RSB-	-RRB-
,	,
self-training	JJ
-LSB-	-LRB-
12	CD
-RSB-	-RRB-
,	,
co-training	NN
-LSB-	-LRB-
1	CD
-RSB-	-RRB-
,	,
transductive	JJ
Support	NN
Vector	NNP
Machines	NNP
-LSB-	-LRB-
19,8	CD
-RSB-	-RRB-
,	,
and	CC
graph-based	JJ
-LSB-	-LRB-
27	CD
-RSB-	-RRB-
methods	NNS
can	MD
be	VB
categorized	VBN
as	IN
the	DT
semi-supervised	JJ
learning	NN
category	NN
.	.


However	RB
,	,
these	DT
methods	NNS
only	RB
can	MD
be	VB
used	VBN
in	IN
stationary	JJ
databases	NNS
.	.

Very	RB
few	JJ
studies	NNS
consider	VBP
data	NNS
stream	NN
classiÔ	NN
¨	CD
cation	NN
with	IN
unlabeled	JJ
training	NN
examples	NNS
.	.

Previously	RB
,	,
Masud	NNP
et	FW
al.	FW
-LSB-	-LRB-
22	CD
-RSB-	-RRB-
proposed	VBD
a	DT
micro	JJ
-	:
cluster-based	JJ
method	NN
that	WDT
clusters	NNS
unlabeled	JJ
examples	NNS
into	IN
micro	JJ
-	:
clusters	NNS
,	,
which	WDT
are	VBP
combined	VBN
with	IN
labeled	VBN
examples	NNS
to	TO
generate	VB
decision	NN
boundaries	NNS
.	.

Zhang	NNP
et	FW
al.	FW
-LSB-	-LRB-
31	CD
-RSB-	-RRB-
proposed	VBD
an	DT
ensemble-based	JJ



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
11	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


model	NN
that	WDT
combines	VBZ
base	NN
classiÔ	NN
¨	CD
ers	NNPS
built	VBN
from	IN
labeled	VBN
examples	NNS
and	CC
clusters	NNS
built	VBN
from	IN
unlabeled	JJ
examples	NNS
.	.

Zhu	NNP
et	FW
al.	FW
-LSB-	-LRB-
41	CD
-RSB-	-RRB-
proposed	VBD
an	DT
active	JJ
learning-based	JJ
model	NN
that	WDT
minimizes	VBZ
labeling	NN
cost	NN
by	IN
selecting	VBG
the	DT
most	RBS
important	JJ
examples	NNS
for	IN
labeling	NN
.	.

Different	JJ
from	IN
these	DT
methods	NNS
,	,
we	PRP
perform	VBP
a	DT
systematic	JJ
study	NN
and	CC
provide	VB
a	DT
comprehen	NN
-	:
sive	JJ
solution	NN
for	IN
classiÔ	NN
¨	CD
cation	NN
of	IN
real-world	JJ
data	NNS
streams	NNS
featuring	VBG
different	JJ
degrees	NNS
of	IN
concept	NN
drifting	VBG
and	CC
labeling	VBG
percentage	NN
,	,
target	NN
-	:
ing	NN
not	RB
only	RB
high	JJ
predicting	VBG
accuracy	NN
,	,
but	CC
also	RB
improved	VBD
learning	VBG
efÔ	NN
¨	NN
ciency	NN
.	.


6	CD
.	.

Conclusions	NNS


Data	NNP
stream	NN
classiÔ	NN
¨	CD
cation	NN
for	IN
real-world	JJ
applications	NNS
has	VBZ
three	CD
major	JJ
challenges	NNS
:	:
concept	NN
drifting	VBG
,	,
large	JJ
volumes	NNS
,	,
and	CC
partial	JJ
labeling	NN
.	.

We	PRP
have	VBP
addressed	VBN
these	DT
challenges	NNS
and	CC
proposed	VBD
a	DT
comprehensive	JJ
learning	NN
framework	NN
that	WDT
can	MD
efÔ	VB
¨	CD
ciently	RB
learn	VBP
accurate	JJ
models	NNS
from	IN
diverse	JJ
training	NN
examples	NNS
.	.

In	IN
our	PRP$
framework	NN
,	,
training	NN
examples	NNS
are	VBP
categorized	VBN
into	IN
four	CD
types	NNS
:	:
labeled	VBN
and	CC
from	IN
the	DT
target	NN
domain	NN
-LRB-	-LRB-
Type	NN
I	CD
-RRB-	-RRB-
,	,
labeled	VBN
and	CC
from	IN
a	DT
similar	JJ
domain	NN
-LRB-	-LRB-
Type	NN
II	CD
-RRB-	-RRB-
,	,
unlabeled	JJ
and	CC
from	IN
the	DT
target	NN
domain	NN
-LRB-	-LRB-
Type	NN
III	CD
-RRB-	-RRB-
and	CC
unlabeled	JJ
and	CC
from	IN
a	DT
similar	JJ
domain	NN
-LRB-	-LRB-
Type	NN
IV	CD
-RRB-	-RRB-
.	.

Each	DT
type	NN
has	VBZ
its	PRP$
own	JJ
learning	NN
priority	NN
.	.

Then	RB
,	,
based	VBN
on	IN
the	DT
proportion	NN
and	CC
learning	VBG
priority	NN
of	IN
the	DT
different	JJ
types	NNS
of	IN
training	NN
examples	NNS
,	,
four	CD
learning	NN
cases	NNS
are	VBP
considered	VBN
and	CC
for	IN
each	DT
case	NN
,	,
a	DT
different	JJ
SVM-based	JJ
learning	NN
model	NN
is	VBZ
applied	VBN
.	.

The	DT
learning	NN
models	NNS
go	VBP
from	IN
relatively	RB
simple	JJ
-LRB-	-LRB-
Cases	NNS
1	CD
and	CC
2	CD
-RRB-	-RRB-
to	TO
fairly	RB
sophisticated	JJ
-LRB-	-LRB-
Cases	NNS
3	CD
and	CC
4	CD
-RRB-	-RRB-
.	.

The	DT
framework	NN
gains	NNS
in	IN
efÔ	NN
¨	CD
ciency	NN
by	IN
learning	VBG
simpler	JJR
models	NNS
whenever	WRB
possible	JJ
depending	VBG
on	IN
the	DT
learning	NN
cases	NNS
.	.

Yet	RB
for	IN
each	DT
case	NN
,	,
our	PRP$
framework	NN
makes	VBZ
sure	JJ
the	DT
most	RBS
informative	JJ
examples	NNS
are	VBP
utilized	VBN
and	CC
the	DT
learning	NN
model	NN
is	VBZ
sufÔ	JJ
¨	NN
ciently	RB
accurate	JJ
.	.

Thus	RB
,	,
our	PRP$
framework	NN
also	RB
achieves	VBZ
high	JJ
accuracy	NN
.	.

Extensive	JJ
experiments	NNS
on	IN
both	DT
synthetic	JJ
and	CC
real	JJ
data	NNS
streams	NNS
have	VBP
demonstrated	VBN
the	DT
effectiveness	NN
and	CC
efÔ	NN
¨	CD
ciency	NN
of	IN
our	PRP$
framework	NN
.	.


There	EX
are	VBP
several	JJ
interesting	JJ
directions	NNS
for	IN
future	JJ
work	NN
.	.

To	TO
improve	VB
efÔ	NN
¨	NN
ciency	NN
of	IN
the	DT
TS3VM	NN
model	NN
,	,
we	PRP
will	MD
study	VB
how	WRB
to	TO
train	VB
linear	JJ
TS3VM	NN
model	NN
in	IN
linear	JJ
time	NN
for	IN
high	JJ
dimensional	JJ
sparse	JJ
data	NNS
.	.

We	PRP
will	MD
also	RB
attempt	VB
to	TO
improve	VB
accuracy	NN
of	IN
the	DT
TS3VM	NN
model	NN
by	IN
incorporating	VBG
kernel	NN
functions	NNS
.	.


Acknowledgment	NN


This	DT
research	NN
was	VBD
supported	VBN
by	IN
the	DT
National	NNP
Science	NNP
Foundation	NNP
of	IN
China	NNP
-LRB-	-LRB-
NSFC	NNP
-RRB-	-RRB-
Grants	NNPS
-LRB-	-LRB-
61003167	CD
,	,
90718042	CD
,	,
71110107026	CD
-RRB-	-RRB-
,	,
National	NNP
High	NNP
Technology	NNP
Research	NNP
and	CC
Development	NNP
Program	NNP
863	CD
Grant	NNP
-LRB-	-LRB-
2011AA010705	NNP
-RRB-	-RRB-
,	,
Texas	NNP
Norman	NNP
Hackerman	NNP
Advanced	NNP
Research	NNP
Program	NNP
Grant	NNP
-LRB-	-LRB-
003656-0035-2009	CD
-RRB-	-RRB-
,	,
and	CC
CAS/SAFEA	NN
Inter	NNP
-	:
national	JJ
Partnership	NNP
Program	NNP
for	IN
Creative	NNP
Research	NNP
Teams	NNPS
-LRB-	-LRB-
70921061	CD
-RRB-	-RRB-
.	.


References	NNS


-LSB-	-LRB-
1	LS
-RSB-	-RRB-
A.	NN
Blum	NNP
,	,
T.	NNP
Mitchell	NNP
,	,
Combining	NNP
labeled	VBN
and	CC
unlabeled	JJ
data	NNS
with	IN
co-training	NN
,	,


in	IN
:	:
The	DT
Workshop	NNP
on	IN
Computational	NNP
Learning	NNP
Theory	NNP
,	,
1998	CD
,	,
pp.	FW
92‚	FW
$	$
``	``
100	CD
.	.

-LSB-	-LRB-
2	CD
-RSB-	-RRB-
C.	NNP
Aggarwal	NNP
,	,
Data	NNP
Streams	NNPS
:	:
Models	NNS
and	CC
Algorithms	NNS
,	,
Springer	NNP
,	,
2006	CD
.	.

-LSB-	-LRB-
3	CD
-RSB-	-RRB-
C.	NNP
Aggarwal	NNP
,	,
J.	NNP
Han	NNP
,	,
J.	NNP
Wang	NNP
,	,
Y.	NNP
Philip	NNP
,	,
A	DT
framework	NN
for	IN
clustering	NN
evolving	VBG


data	NNS
streams	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
VLDB	NNP
,	,
2003	CD
,	,
pp.	FW
81‚	FW
$	$
``	``
92	CD
.	.


-LSB-	-LRB-
4	LS
-RSB-	-RRB-
A.	NN
Asuncion	NNP
,	,
D.	NNP
Newman	NNP
,	,
UCI	NNP
Machine	NNP
Learning	NNP
Repository	NNP
,	,
Irvine	NNP
,	,
CA	NNP
.	.


University	NNP
of	IN
California	NNP
,	,
School	NNP
of	IN
Information	NNP
and	CC
Computer	NNP
Sciences	NNPS
,	,
Irvine	NNP
,	,


/	:
http://archive.ics.uci.edu/ml	NN
S	NN
,	,
2007	CD
.	.


-LSB-	-LRB-
5	CD
-RSB-	-RRB-
B.	NNP
Brian	NNP
,	,
B.	NNP
Shivnath	NNP
,	,
D.	NNP
Mayur	NNP
,	,
M.	NNP
Rajeev	NNP
,	,
W.	NNP
Jennifer	NNP
,	,
Models	NNS
and	CC
issues	NNS
in	IN


data	NNS
stream	NN
systems	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
PODS	NN
,	,
2002	CD
,	,
pp.	FW
1‚	FW
$	$
``	``
16	CD
.	.

-LSB-	-LRB-
6	CD
-RSB-	-RRB-
O.	NNP
Chapelle	NNP
,	,
B.	NNP
Scholkopf	NNP
,	,
A.	NNP
Zien	NNP
,	,
Semi-Supervised	NNP
Learning	NNP
,	,
MIT	NNP
Press	NNP
,	,


Cambridge	NNP
,	,
MA	NNP
,	,
2006	CD
.	.


-LSB-	-LRB-
7	CD
-RSB-	-RRB-
O.	NNP
Chapelle	NNP
,	,
V.	NNP
Sindhwani	NNP
,	,
S.	NNP
Keerthi	NNP
,	,
Optimization	NNP
techniques	NNS
for	IN
semi	NN
-	:


supervised	JJ
support	NN
vector	NN
machines	NNS
,	,
J.	NNP
Mach	NNP
.	.

Learn	VB
.	.

Res	NNP
.	.

9	CD
-LRB-	-LRB-
2008	CD
-RRB-	-RRB-
203‚	RB
$	$
``	``
233	CD
.	.

-LSB-	-LRB-
8	CD
-RSB-	-RRB-
R.	NNP
Collobert	NNP
,	,
F.	NNP
Sinz	NNP
,	,
J.	NNP
Weston	NNP
,	,
Large	JJ
scale	NN
transductive	JJ
SVMS	NNS
,	,
J.	NNP
Mach	NNP
.	.

Learn	VB
.	.


Res	NNP
.	.

7	CD
-LRB-	-LRB-
2006	CD
-RRB-	-RRB-
1687‚	CD
$	$
``	``
1712	CD
.	.


181	CD


-LSB-	-LRB-
9	CD
-RSB-	-RRB-
W.	NNP
Dai	NNP
,	,
Q.	NNP
Yang	NNP
,	,
G.	NNP
Xue	NNP
,	,
Y.	NNP
Yu	NNP
,	,
Boosting	NNP
for	IN
transfer	NN
learning	NN
,	,
in	IN
:	:
Proceedings	NNP


of	IN
the	DT
ICML	NN
,	,
2007	CD
,	,
pp.	FW
193‚	FW
$	$
``	``
200	CD
.	.


-LSB-	-LRB-
10	CD
-RSB-	-RRB-
C.	NNP
Domeniconi	NNP
,	,
D.	NNP
Gunopulos	NNP
,	,
Incremental	JJ
support	NN
vector	NN
machine	NN
construc	NN
-	:


tion	NN
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ICDM	NN
,	,
2001	CD
,	,
pp.	FW
589‚	FW
$	$
``	``
592	CD
.	.


-LSB-	-LRB-
11	CD
-RSB-	-RRB-
P.	NNP
Domingos	NNP
,	,
G.	NNP
Hulten	NNP
,	,
Mining	NNP
high-speed	JJ
data	NNS
streams	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN


the	DT
KDD	NNP
,	,
2000	CD
,	,
pp.	FW
71‚	FW
$	$
``	``
80	CD
.	.


-LSB-	-LRB-
12	CD
-RSB-	-RRB-
D.	NNP
Yarowsky	NNP
,	,
Unsupervised	JJ
word	NN
sense	NN
disambiguation	NN
rivaling	VBG
supervised	VBN


methods	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ACL	NN
,	,
1995	CD
,	,
pp.	FW
189‚	FW
$	$
``	``
196	CD
.	.


-LSB-	-LRB-
13	CD
-RSB-	-RRB-
T.	NNP
Evgeniou	NNP
,	,
M.	NNP
Pontil	NNP
,	,
Regularized	VBN
multi-task	JJ
learning	NN
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT


KDD	NNP
,	,
2004	CD
,	,
pp.	FW
109‚	FW
$	$
``	``
117	CD
.	.


-LSB-	-LRB-
14	CD
-RSB-	-RRB-
J.	NNP
Gao	NNP
,	,
W.	NNP
Fan	NNP
,	,
J.	NNP
Han	NNP
,	,
On	IN
appropriate	JJ
assumptions	NNS
to	TO
mine	JJ
data	NNS
streams	NNS
:	:


analysis	NN
and	CC
practice	NN
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ICDM	NN
,	,
2007	CD
,	,
pp.	FW
143‚	FW
$	$
``	``
152	CD
.	.

-LSB-	-LRB-
15	CD
-RSB-	-RRB-
J.	NNP
Han	NNP
,	,
H.	NNP
Cheng	NNP
,	,
D.	NNP
Xin	NNP
,	,
X.	NNP
Yan	NNP
,	,
Frequent	JJ
pattern	NN
mining	NN
:	:
current	JJ
status	NN
and	CC
future	NN


directions	NNS
,	,
Data	NNS
Mining	NN
and	CC
Knowledge	NN
Discovery	NNP
-LRB-	-LRB-
DMKD	NNP
-RRB-	-RRB-
15	CD
-LRB-	-LRB-
13‚	CD
$	$
``	``
15	CD
-RRB-	-RRB-
-LRB-	-LRB-
2007	CD
-RRB-	-RRB-


55‚	JJ
$	$
``	``
86	CD
.	.


-LSB-	-LRB-
16	CD
-RSB-	-RRB-
S.	NNP
Ho	NNP
,	,
A	DT
martingale	NN
framework	NN
for	IN
concept	NN
change	NN
detection	NN
in	IN
time-varying	JJ


data	NNS
streams	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ICML	NN
,	,
2005	CD
,	,
pp.	FW
321‚	FW
$	$
``	``
328	CD
.	.


-LSB-	-LRB-
17	CD
-RSB-	-RRB-
G.	NNP
Hulten	NNP
,	,
L.	NNP
Spencer	NNP
,	,
P.	NNP
Domingos	NNP
,	,
Mining	NNP
time-changing	JJ
data	NNS
streams	NNS
,	,
in	IN
:	:


Proceedings	NNP
of	IN
the	DT
KDD	NNP
,	,
2001	CD
,	,
pp	NN
97‚	NN
$	$
``	``
106	CD
.	.


-LSB-	-LRB-
18	CD
-RSB-	-RRB-
H.	NNP
Wang	NNP
,	,
W.	NNP
Fan	NNP
,	,
P.	NNP
Yu	NNP
,	,
J.	NNP
Han	NNP
,	,
Mining	NNP
concept-drifting	JJ
data	NNS
streams	NNS
using	VBG


ensemble	NN
classiÔ	NN
¨	CD
ers	NNPS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
KDD	NNP
,	,
2003	CD
,	,
pp.	FW
226‚	FW
$	$
``	``
235	CD
.	.

-LSB-	-LRB-
19	CD
-RSB-	-RRB-
T.	FW
Joachims	FW
,	,
Transductive	JJ
inference	NN
for	IN
text	NN
classiÔ	NN
¨	CD
cation	NN
using	VBG
support	NN


vector	NN
machines	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ICML	NN
,	,
1999	CD
,	,
pp.	FW
200‚	FW
$	$
``	``
209	CD
.	.


-LSB-	-LRB-
20	CD
-RSB-	-RRB-
D.	NNP
Kifer	NNP
,	,
J.G.S.	NNP
Ben-David	NNP
,	,
Detecting	VBG
change	NN
in	IN
data	NNS
streams	NNS
,	,
in	IN
:	:
Proceedings	NNP


of	IN
the	DT
VLDB	NNP
,	,
2004	CD
,	,
pp.	VBP
180-191	CD
.	.


-LSB-	-LRB-
21	CD
-RSB-	-RRB-
J.	NNP
Kolter	NNP
,	,
M.	NNP
Maloof	NNP
,	,
Using	VBG
additive	JJ
expert	NN
ensembles	NNS
to	TO
cope	VB
with	IN
concept	NN


drift	NN
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ICML	NN
,	,
2005	CD
,	,
pp.	FW
449‚	FW
$	$
``	``
456	CD
.	.


-LSB-	-LRB-
22	CD
-RSB-	-RRB-
M.	NNP
Masud	NNP
,	,
J.	NNP
Gao	NNP
,	,
L.	NNP
Khan	NNP
,	,
J.	NNP
Han	NNP
,	,
B.	NNP
Thuraisingham	NNP
,	,
A	DT
practical	JJ
approach	NN
to	TO


classify	VB
evolving	VBG
data	NNS
streams	NNS
:	:
training	NN
with	IN
limited	JJ
amount	NN
of	IN
labeled	VBN
data	NNS
,	,


in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ICDM	NN
,	,
2008	CD
,	,
pp.	FW
339‚	FW
$	$
``	``
348	CD
.	.


-LSB-	-LRB-
23	CD
-RSB-	-RRB-
K.	NNP
Nigam	NNP
,	,
R.	NNP
Ghani	NNP
,	,
Analyzing	VBG
the	DT
effectiveness	NN
and	CC
applicability	NN
of	IN
co	NN
-	:


training	NN
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
CIKM	NNP
,	,
2000	CD
,	,
pp.	FW
86‚	FW
$	$
``	``
93	CD
.	.


-LSB-	-LRB-
24	CD
-RSB-	-RRB-
W.N.	NNP
Street	NNP
,	,
Y.	NNP
Kim	NNP
,	,
A	DT
streaming	NN
ensemble	NN
algorithm	NN
-LRB-	-LRB-
sea	NN
-RRB-	-RRB-
for	IN
large-scale	JJ


classiÔ	NN
¨	CD
cation	NN
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
KDD	NNP
,	,
2001	CD
,	,
pp.	FW
377‚	FW
$	$
``	``
382	CD
.	.


-LSB-	-LRB-
25	CD
-RSB-	-RRB-
N.	NNP
Syed	NNP
,	,
H.	NNP
Liu	NNP
,	,
K.	NNP
Sung	NNP
,	,
Handling	VBG
concept	NN
drifts	VBZ
in	IN
incremental	JJ
learning	NN
with	IN


support	NN
vector	NN
machines	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
KDD	NNP
,	,
1999	CD
,	,
pp.	FW
317‚	FW
$	$
``	``
321	CD
.	.

-LSB-	-LRB-
26	CD
-RSB-	-RRB-
A.	NN
Tsymbal	NNP
,	,
The	DT
problem	NN
of	IN
concept	NN
drift	NN
:	:
deÔ	NN
¨	NN
nitions	NNS
and	CC
related	JJ
work	NN
.	.


Available	JJ
online	NN
:	:
/	:
http://www.scss.tcd.ie/publications/tech-reports/reports	NNS
.	.


04/TCD-CS	NN
-2004	CD
-15	CD
.	.

pdfS	NN
.	.


-LSB-	-LRB-
27	CD
-RSB-	-RRB-
X.	NNP
Zhu	NNP
,	,
Semi-supervised	JJ
learning	NN
literature	NN
survey	NN
,	,
Technical	NNP
Report	NNP
1530	CD
,	,


University	NNP
of	IN
Wisconsin-Madison	NNP
,	,
2005	CD
.	.


-LSB-	-LRB-
28	CD
-RSB-	-RRB-
Y.	NNP
Yang	NNP
,	,
X.	NNP
Wu	NNP
,	,
X.	NNP
Zhu	NNP
,	,
Combining	NNP
proactive	JJ
and	CC
reactive	JJ
predictions	NNS
of	IN
data	NNS


streams	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
KDD	NNP
,	,
2005	CD
,	,
pp.	FW
710‚	FW
$	$
``	``
715	CD
.	.


-LSB-	-LRB-
29	CD
-RSB-	-RRB-
A.	NN
Yuille	NNP
,	,
A.	NNP
Rangarajan	NNP
,	,
The	DT
concave-convex	JJ
procedure	NN
,	,
in	IN
:	:
Proceedings	NNP
of	IN


the	DT
NIPS	NNP
,	,
2001	CD
,	,
pp.	FW
1033‚	FW
$	$
``	``
1040	CD
.	.


-LSB-	-LRB-
30	CD
-RSB-	-RRB-
P.	NNP
Zhang	NNP
,	,
J.	NNP
Li	NNP
,	,
P.	NNP
Wang	NNP
,	,
B.	NNP
Gao	NNP
,	,
X.	NNP
Zhu	NNP
,	,
L.	NNP
Guo	NNP
,	,
Enabling	NNP
fast	RB
prediction	NN
for	IN


ensemble	NN
models	NNS
on	IN
data	NNS
streams	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
KDD	NNP
,	,
2011	CD
,	,


pp.	NN
177‚	CD
$	$
``	``
185	CD
.	.


-LSB-	-LRB-
31	CD
-RSB-	-RRB-
P.	NNP
Zhang	NNP
,	,
X.	NNP
Zhu	NNP
,	,
L.	NNP
Guo	NNP
,	,
Mining	NNP
data	NNS
streams	NNS
with	IN
labeled	VBN
and	CC
unlabeled	JJ


training	NN
examples	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ICDM	NN
,	,
2009	CD
,	,
pp.	FW
627‚	FW
$	$
``	``
636	CD
.	.

-LSB-	-LRB-
32	CD
-RSB-	-RRB-
P.	NNP
Zhang	NNP
,	,
X.	NNP
Zhu	NNP
,	,
Y.	NNP
Shi	NNP
,	,
L.	NNP
Guo	NNP
,	,
X.	NNP
Wu	NNP
,	,
Robust	JJ
ensemble	NN
learning	VBG
for	IN
mining	NN


noisy	JJ
data	NNS
streams	NNS
,	,
Dec.	NNP
.	.

Support	NN
Syst	NN
.	.

50	CD
-LRB-	-LRB-
2	CD
-RRB-	-RRB-
-LRB-	-LRB-
2011	CD
-RRB-	-RRB-
469‚	RB
$	$
``	``
479	CD
.	.


-LSB-	-LRB-
33	CD
-RSB-	-RRB-
P.	NNP
Zhang	NNP
,	,
X.	NNP
Zhu	NNP
,	,
J.	NNP
Tan	NNP
,	,
L.	NNP
Guo	NNP
,	,
Skif	NNP
:	:
a	DT
data	NN
imputation	NN
framework	NN
for	IN
concept	NN


drifting	VBG
data	NNS
streams	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
CIKM	NNP
,	,
2010	CD
,	,
pp.	FW
1869‚	FW
$	$
``	``
1872	CD
.	.

-LSB-	-LRB-
34	CD
-RSB-	-RRB-
P.	NNP
Zhang	NNP
,	,
X.	NNP
Zhu	NNP
,	,
Y.	NNP
Shi	NNP
,	,
Categorizing	VBG
and	CC
mining	VBG
concept	NN
drifting	VBG
data	NNS


streams	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
KDD	NNP
,	,
2008	CD
,	,
pp.	FW
812‚	FW
$	$
``	``
820	CD
.	.


-LSB-	-LRB-
35	CD
-RSB-	-RRB-
P.	NNP
Zhang	NNP
,	,
X.	NNP
Zhu	NNP
,	,
J.	NNP
Tan	NNP
,	,
L.	NNP
Guo	NNP
,	,
ClassiÔ	NNP
¨	CD
erandclusterensemblesforminingconcept	JJ


drifting	VBG
data	NNS
streams	NNS
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ICDM	NN
,	,
2010	CD
,	,
pp.	FW
1175‚	FW
$	$
``	``
1180	CD
.	.

-LSB-	-LRB-
36	CD
-RSB-	-RRB-
P.	NNP
Zhang	NNP
,	,
X.	NNP
Zhu	NNP
,	,
X.	NNP
Wu	NNP
,	,
Y.	NNP
Shi	NNP
,	,
An	DT
aggregate	JJ
ensemble	NN
for	IN
mining	NN
concept	NN
drifting	VBG


data	NNS
streams	NNS
with	IN
noise	NN
,	,
in	IN
:	:
Proceedings	NNP
of	IN
the	DT
PAKDD	NNP
,	,
2009	CD
,	,
pp.	FW
1021‚	FW
$	$
``	``
1029	CD
.	.

-LSB-	-LRB-
37	CD
-RSB-	-RRB-
X.	NNP
Zhu	NNP
,	,
Stream	NNP
data	NNS
mining	NN
repository	JJ
/	:
www.cse.fau.edu/xqzhu/S	NN
,	,
2009	CD
.	.

-LSB-	-LRB-
38	CD
-RSB-	-RRB-
X.	NNP
Zhu	NNP
,	,
R.	NNP
Jin	NNP
,	,
Multiple	JJ
information	NN
sources	NNS
cooperative	JJ
learning	NN
,	,
in	IN
:	:
Proceed	VB
-	:


ings	NNS
of	IN
the	DT
IJCAI	NNP
,	,
2007	CD
,	,
pp.	FW
1369‚	FW
$	$
``	``
1375	CD
.	.


-LSB-	-LRB-
39	CD
-RSB-	-RRB-
X.	NNP
Zhu	NNP
,	,
X.	NNP
Wu	NNP
,	,
C.	NNP
Zhang	NNP
,	,
Vague	NNP
one-class	JJ
learning	NN
for	IN
data	NNS
streams	NNS
,	,
in	IN
:	:


Proceedings	NNP
of	IN
the	DT
ICDM	NN
,	,
2009	CD
,	,
pp.	FW
657‚	FW
$	$
``	``
666	CD
.	.


-LSB-	-LRB-
40	CD
-RSB-	-RRB-
X.	NNP
Zhu	NNP
,	,
P.	NNP
Zhang	NNP
,	,
X.	NNP
Lin	NNP
,	,
Y.	NNP
Shi	NNP
,	,
Active	JJ
learning	NN
from	IN
data	NNS
streams	NNS
,	,
in	IN
:	:


Proceedings	NNP
of	IN
the	DT
ICDM	NN
,	,
2007	CD
,	,
pp.	FW
757‚	FW
$	$
``	``
762	CD
.	.


-LSB-	-LRB-
41	CD
-RSB-	-RRB-
X.	NNP
Zhu	NNP
,	,
P.	NNP
Zhang	NNP
,	,
X.	NNP
Lin	NNP
,	,
Y.	NNP
Shi	NNP
,	,
Active	JJ
learning	NN
from	IN
stream	NN
data	NNS
using	VBG
optimal	JJ


weight	NN
classiÔ	NN
¨	CD
er	NN
ensemble	NN
,	,
IEEE	NNP
Trans	NNP
.	.

Syst	NNP
.	.

Man	NN
Cybernet	NNP
.	.

Part	NN
B	NN
40	CD
-LRB-	-LRB-
4	CD
-RRB-	-RRB-


-LRB-	-LRB-
2010	CD
-RRB-	-RRB-
1‚	RB
$	$
``	``
15	CD
.	.


-LSB-	-LRB-
42	CD
-RSB-	-RRB-
X.	NNP
Zhu	NNP
,	,
P.	NNP
Zhang	NNP
,	,
X.	NNP
Wu	NNP
,	,
D.	NNP
He	PRP
,	,
C.	NNP
Zhang	NNP
,	,
Y.	NNP
Shi	NNP
,	,
Cleansing	NNP
noisy	JJ
data	NNS
streams	NNS
,	,


in	IN
:	:
Proceedings	NNP
of	IN
the	DT
ICDM	NN
,	,
2008	CD
,	,
pp.	FW
1139‚	FW
$	$
``	``
1144	CD
.	.


Peng	NNP
Zhang	NNP
is	VBZ
an	DT
Assistant	NNP
Professor	NNP
with	IN
the	DT
Institute	NNP
of	IN
Computing	NNP
Technology	NNP
,	,
Chinese	NNP
Academy	NNP
of	IN
Sciences	NNPS
,	,
Beijing	NNP
-LRB-	-LRB-
China	NNP
-RRB-	-RRB-
.	.

He	PRP
received	VBD
his	PRP$
PhD	NN
-LRB-	-LRB-
2009	CD
-RRB-	-RRB-
in	IN
Computer	NNP
Science	NNP
from	IN
the	DT
Graduate	NNP
University	NNP
of	IN
the	DT
Chinese	JJ
Academy	NN
of	IN
Sciences	NNPS
,	,
Beijing	NNP
,	,
China	NNP
.	.

His	PRP$
research	NN
interests	NNS
include	VBP
data	NNS
stream	NN
mining	NN
and	CC
information	NN
security	NN
.	.



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
12	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



182	CD


P.	NNP
Zhang	NNP
et	FW
al.	FW
/	:
Neurocomputing	VBG
92	CD
-LRB-	-LRB-
2012	CD
-RRB-	-RRB-
170‚	RB
$	$
``	``
182	CD


Byron	NNP
J.	NNP
Gao	NNP
received	VBD
PhD	NN
and	CC
BSc	NN
in	IN
Computer	NNP
Science	NNP
from	IN
Simon	NNP
Fraser	NNP
University	NNP
,	,
Canada	NNP
,	,
in	IN
2007	CD
and	CC
2003	CD
,	,
respectively	RB
.	.

He	PRP
was	VBD
a	DT
postdoctoral	JJ
fellow	NN
at	IN
the	DT
Uni	NNP
-	:
versity	NN
of	IN
Wisconsin-Madison	NNP
before	IN
joining	VBG
Texas	NNP
State	NNP
University-San	NNP
Marcos	NNP
in	IN
2008	CD
.	.

His	PRP$
research	NN
spans	VBZ
several	JJ
related	JJ
Ô	NN
¨	NN
elds	NNS
including	VBG
data	NNS
mining	NN
,	,
databases	NNS
,	,
informa	FW
-	:
tion	NN
retrieval	NN
,	,
and	CC
bioinformatics	NNS
.	.


Ping	VB
Liu	NNP
is	VBZ
an	DT
Assistant	NNP
Professor	NNP
with	IN
the	DT
Institute	NNP
of	IN
Computing	NNP
Technology	NNP
,	,
Chinese	NNP
Academy	NNP
of	IN
Sciences	NNPS
,	,
Beijing	NNP
-LRB-	-LRB-
China	NNP
-RRB-	-RRB-
.	.

Her	PRP$
research	NN
interests	NNS
include	VBP
string	NN
matching	NN
and	CC
information	NN
security	NN
.	.


Yong	NNP
Shi	NNP
is	VBZ
the	DT
Distinguished	NNP
Professor	NNP
of	IN
Information	NNP
Technology	NNP
,	,
College	NNP
of	IN
Information	NNP
Science	NNP
and	CC
Tech	NNP
-	:
nology	NN
,	,
Peter	NNP
Kiewit	NNP
Institute	NNP
,	,
University	NNP
of	IN
Nebraska	NNP
,	,
USA	NNP
.	.

He	PRP
is	VBZ
also	RB
the	DT
Executive	NNP
Deputy	NNP
Director	NNP
of	IN
the	DT
Fictitious	NNP
Economy	NNP
and	CC
Data	NNP
Science	NNP
Research	NNP
Center	NNP
,	,
Chinese	NNP
Academy	NNP
of	IN
Sciences	NNPS
,	,
Beijing	NNP
,	,
China	NNP
.	.

He	PRP
is	VBZ
the	DT
Editor-in-Chief	NN
of	IN
International	NNP
Journal	NNP
of	IN
Information	NNP
Technology	NNP
and	CC
Decision	NNP
Making	VBG
-LRB-	-LRB-
SCI	NNP
-RRB-	-RRB-
,	,
an	DT
Area	NNP
Editor	NNP
of	IN
International	NNP
Journal	NNP
of	IN
Operations	NNP
and	CC
Quantitative	JJ
Management	NN
,	,
a	DT
member	NN
of	IN
Editorial	NNP
Board	NNP
for	IN
a	DT
number	NN
of	IN
academic	JJ
journals	NNS
,	,
including	VBG
International	NNP
Journal	NNP
of	IN
Data	NNP
Mining	NNP
and	CC
Business	NNP
Intelligence	NNP
.	.


Li	NNP
Guo	NNP
is	VBZ
the	DT
Director	NN
of	IN
the	DT
Information	NNP
Security	NNP
Research	NNP
Center	NNP
,	,
Institute	NNP
of	IN
Computing	NNP
Technology	NNP
,	,
Chinese	NNP
Academy	NNP
of	IN
Sciences	NNPS
.	.

Her	PRP$
research	NN
interests	NNS
include	VBP
data	NNS
stream	NN
management	NN
and	CC
information	NN
security	NN
.	.



=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
13	CD
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ
=	JJ



