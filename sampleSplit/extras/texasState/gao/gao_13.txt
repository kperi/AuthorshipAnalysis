Building Community Wikipedias: A Machine-Human Partnership Approach 
Pedro DeRose1, Xiaoyong Chai1, Byron J. Gao1, Warren Shen1 
AnHai Doan1, Philip Bohannon2, Jerry Zhu1 
1University of Wisconsin-Madison, 2Yahoo! Research 
Abstract 
The rapid growth of Web communities has motivated many solutions for building community data portals. These solu- tions follow roughly two approaches. The ﬁrst approach (e.g ., Cimple, Libra, Citeseer) employs semi-automatic methods to extract and integrate data from a multitude of data sources. The second approach (e.g., Wikipedia, Intellipedia) deploys an initial portal in wiki format, then invites community mem- bers to revise and add material. In this paper we consider combining the above two approaches to building community portals. The new hybrid machine-human approach brings signiﬁcant beneﬁts. It can achieve broader and deeper cov- erage, provide more incentives for users to contribute, and keep the portal more up to date with less user efforts. In a sense, it enables building “community wikipedias”, backed up by an underlying structured database that is continuously updated using automatic techniques. We outline our ideas for the new approach, describe its challenges and opportu- nities, and provide initial solutions. Finally, we describe a real-world implementation and preliminary experiments that demonstrate the utility of the new approach. 
1 Introduction 
The growing presence of Web communities has motivated many solutions to build community data portals. These so- lutions follow roughly two approaches. The ﬁrst, machine- based, approach employs semi-automatic methods to extract and integrate data from a multitude of data sources, to cre- ate structured data portals. Examples include Cimple, Libra, Rexa.info, BlogScope, and Blogosphere [16, 21, 6, 17, 11, 5]. 
The above approach incurs relatively little human efforts, often generates a reasonable initial portal, keeps portals fresh with automatic updates, and enables structured queries over portals. However, it usually suffers from inaccuracies, caused by imperfect extraction and integration methods, and limited coverage, because it can only infer whichever information is available in the data sources. 
The second, human-based, approach manually deploys an initial portal in wiki format, then invites community users to revise and add materials. Examples include Wikipedia, 
Intellipedia, umasswiki.com, ecolicommunity.org, and many wiki-based intranets. This approach avoids many problems of the machine-based approach, but suffers from its own limita- tions. In particular, it may be difﬁcult to solicit sufﬁcien t user participation, can incur signiﬁcant user efforts to keep po r- tals up to date, and cannot accommodate structured queries, because users contribute mostly text and images. 
In this paper we consider combining the above two com- plimentary approaches to build community portals. Speciﬁ- cally, we use “machines” to deploy an initial portal in wiki format, then allow both machines and human users to revise and add materials. Machines can add structured information to certain parts of wiki pages, while users can add both text and structured information. Machines and human can also correct and augment each other's contributions, in a synergis- tic fashion. We refer to this approach asCwiki. The following example illustrates the approach. 
Example 1.1. Suppose we apply Cwiki to build a portal for the database community. We can start by applying a semi-automatic approach (i.e., “machines”) to extract structured data fro m the Web, then use the data to create and deploy wiki pages, such as pageW in Figure 1.a. Page W contains “structured data pieces” mixed with ordinary wiki text, and will display as the HTML page in Figure 1.b. In effect, W describes a person entity who has three attributes: id = 1, name = David J. DeWitt, and title = Professor. This person also participates in a relationship called “interests” wit h an entity of type “topic”, whose name is “Parallel Database”. 
Once W has been deployed, a user U may come in and edit page W, e.g., by correcting the value of attribute title from “Pro- fessor”, which was generated by machines, to “John P. Morgri dge Professor”. U may also contribute a structured data piece “ <# person(id=1){organization}= UW #>”, to state that this person is working for an organization called “UW”. Finally, U adds free text “since 1976” after this data piece. The edited page W′ is shown in Figure 1.c. 
Later a machine M may discover from data sources that the above person also participates in “interests” relationshi p with topic “Privacy”. M can then add this piece of information to the page, as “ <#person(id=1).interests (id=5).topic(id=6){name}=Privacy #>”. With high conﬁdence, M may also correct the value of at- tribute organization from “UW”, which was contributed by U, to “UW-Madison”. The resulting wiki page W′′ is in Figure 1.d, and it will display as the HTML page in Figure 1.e. Thus, page W has been evolved over time, with both machines and users' contributing 

========1========

<# person(id=1){name}=David J. DeWitt #> 
David J. DeWitt 
<# person(id=1){name}=David J. DeWitt #> 
<# person(id=1){title}=Professor #> 
Professor 
<# person(id=1){title}=John P. Morgridge 
Professor #> 
<strong>Interests:</strong> 
<# person(id=1).interests(id=3) .topic(id=4){name}=Parallel Database #> 
Interests: 
Parallel Database 
<# person(id=1) {organization}=UW #>  
since 1976 
<strong>Interests:</strong> 
<# person(id=1).interests(id=3) .topic(id=4){name}=Parallel Database #> 
<# person(id=1){name}=David J. DeWitt #> 
David J. DeWitt 
<# person(id=1){title}=  John P. Morgridge Professor #> 
John P. Morgridge Professor UW-Madison since 1976 
<# person(id=1){organization}=UW-Madison#> since 1976 
<strong>Interests:</strong> 
<# person(id=1).interests(id=3) .topic(id=4){name}=Parallel Database #> 
Interests: 
Parallel Database 
Privacy 
<# person(id=1).interests(id=5) .topic(id=6){name}=Privacy #> 
(a) (b) (c) (d) (e) 
Figure 1. An example to illustrate the machine-human approach. 
and correcting each other's contributions. 
As described, this new hybrid machine-human approach enables building “community wikipedias” that are backed up by an underlying structured database that is continuously up- dated using automatic techniques. The approach can bring signiﬁcant beneﬁts. First, it can achieve broader and deepe r coverage, because it exploits both machines and human users. Second, it can provide more incentives for users to contribute, because the initial portal built by machines can already be reasonably useful and comprehensive, thus motivating users to further improving it. Third, it can keep the portal more up to date, with less user efforts, because machines can contin- uously monitor data sources and update certain parts of the portal. Finally, the structured data in the wiki pages of the portal is also stored in an underlying structured database,thus enabling a variety of structured queries over the portal. 
In the rest of the paper we elaborate on the above ap- proach. First, we consider how to build an initial wiki- based portal, using machines. We cast this as a view creation problem: store the data generated by machines in a struc- tured database G, create structured views over G, then export the views in wiki pages. The key questions are then: How to model and implement the structured database G? What should be the view language? And how to export the struc- tured data of the views into wiki pages? As parts of our solution, we represent the machine-generated data using an entity-relationship (ER) model, deﬁne a path-based view la n- guage over this model, extend the standard wiki language [2] withs-slots – constructs to embed structured data into the nat- ural text of wiki pages, then show how to export the views in wiki pages, using s-slots (Section 4.3). 
Next, we consider how to manage user contributions to the portal. If a user U has edited a wiki page W, then we want to extract the “structured” part of U's edits, and “push” it all the way into the underlying database G. The key questions here are: What is it that U is conceptually allowed to edit? And how to efﬁciently infer such edits based on what U has done to a wiki page W? To answer these questions, we cast the problem of processing user contributions as a problem of mapping U's edits over the wiki page into edits over the cor- responding view, then from this view into edits over G. This is a view update problem. But it is complicated (compared to RDBMS view update) by the facts that here (a) U can also edit the schema, not just the data, of the view, and (b) U's edits, being limited to the wiki interface, are often ambigu- 
ous. Furthermore, after we have updated database G with edits from W, we must decide how to propagate this update to other views and corresponding wiki pages. In Section 5 we elaborate on these issues, then provide a solution. 
Finally, for the sake of completeness (but not as a part of the contribution of this paper), in Section 6 we brieﬂy touch upon the problem of managing multiple users, where we ex- tend current solutions employed in Wikipedia (namely, opti- mistic concurrency control and access rights based on a user hierarchy) to handle concurrent editing and malicious users. We also consider how to let machines join users in updating the portal. The key challenge is the following: once a user has entered an edit, can machines be allowed to overwrite the edit, and when? 
We have been applying the above solution to build a com- munity wikipedia for the database research community (see the live system at [1]). In Section 7 we report on our expe- rience and preliminary experiments that demonstrate the po- tentials of this approach, and suggest opportunities for future research. 
To summarize, we make the following contributions: 
• Introduce a new hybrid approach that employs both ma- chines and human users to build community portals, backed up by an underlying structured database. As far as we know, ours is the ﬁrst work that studies this direc- tion in depth. 
• Provide solutions to modeling the underlying structure database, representing views over this database with a path-based language, and exporting these views in wiki pages. 
• Provide an efﬁcient solution to process user edits in wiki pages and “push” these edits into the underlying database. The solution recasts this problem as translat- ing edits across different user interfaces. 
• Empirical results over a real-world implementation that demonstrates the promise of the approach and suggests opportunities for future research. 
2 Related Work 
We are not aware of any published work that has stud- ied combining “machines” and human approaches to build- ing community portals. Many portals (e.g., Wikipedia) do 

========2========

employ automatic programs (called “bots”) to generate new pages according to some template, and to detect problems (e.g., vandalism) with current pages. But these programs do not contribute structured data nor do they update existing data, as we do here. 
Perhaps the work closest to ours is Semantic Wikipedia [24]. This work develops new wiki language constructs that allow users to add structured data to wiki pages. We also de- velop similar wiki language constructs (see Section 4.3). But our constructs are far more powerful: we can embed arbi- trary ER data graphs in a wiki page, whereas the constructs in [24] in a sense only allow embedding node and relationat- tributes. More importantly, Semantic Wikipedia and several similar efforts, including semantic wikis [3] and Metaweb [4], have focused largely on extending wiki languages so that users can contribute structured data. They have not focused on allowing machines to contribute, nor do they study how to “push” structured contributions from users into an underly ing database. Our work here is therefore complementary to these efforts. 
Many semi-automatic approaches have been developed to build structured portals (see [14] for an extensive discussion). Any of these can be employed as “machines” in our current work. 
Processing structured user edits in our context is a vari- ation on the classical view update problem [10, 12]. Un- like relational view update, however, in our context users can also edit the schemas of views as well as of the underlying database. Since users employ the wiki interface, which is rather limited for expressing structured edits, this posesprob- lems in interpreting user intentions that do not arise in rela- tional view updates. 
We recast processing structured user edits in our context as a problem of translating these edits across different user interfaces (wiki, ER, and relational, see Section 5.2). Such UI translations have been studied, e.g., translating a natural- language user query into a structured one [9, 19]. Translating free natural-language queries is well known to be difﬁcult [ 9, 19]. Our problem here is still difﬁcult, but more manageable , as we only translate structured edits. 
Finally, our work can be viewed as a mass collaboration, Web 2.0 effort to build, maintain, and expand a hybrid struc- tured data-text community database. Mass collaboration ap- proaches to data management have recently received increas- ing attention in the database community (e.g., mass collab- oration panel at VLDB-07, Web 2.0 track at ICDE-08, see also [8, 20, 25, 22, 15, 7]. Our work here contributes to this emerging direction. 
3 The Cwiki Approach 
In the rest of the paper we describe the Cwiki approach. Figure 2 illustrates howCwikiworks. It starts by applyingM, a machine-based solution, to extract and integrate data from a set of data sources, then loads this data into a structured 
V1 
W1 
Data Sources 
M 
G 
V2 
W2 
V3 
W3 
V3’ 
W3’ 
u1 
T 
T3’ 
Figure 2. The Cwiki architecture 
database G. Next, it initializes an empty text database T, which will be used in the future to store text generated by users. Then Cwiki generates structured views over G (e.g., V1  V3 in Figure 2), and exports them in wiki pages (e.g., W1  W3). The initial portalW then consists of all such wiki pages. 
Community users and machineM then revise and add ma- terials to W. Suppose a user u1 has revised wiki page W3′ 
into page W 
3 
(Figure 2). Then Cwiki extracts the structured data portion V 
′ 
from W′3 
3 
and uses it to update the structured database G. Next, Cwiki extracts the text portionT′3 fromW′3 and stores it in the text database T. Cwiki also reruns ma- chine M at regular intervals (to obtain the latest information from the data sources), updates G based on the output of M, then updates the views and wiki pages accordingly. Updating a wiki page Wi for example means creating a new version of Wi that combines the latest versions of its structured data portion from G and text portion from T. In addition to revis- ing existing wiki pages, as described above, both users and machines can add new pages or delete existing ones. 
The next two sections describe the key contributions of this paper: how to build the initial portal and to manage user contributions. Section 6 brieﬂy touches upon the issue of managing multiple users and machine. 
4 Creating the Initial Community Portal 
To create the initial portal, we proceed in three steps: em- ploy a machine M to create a structured database G, create structured views Vi over G, then convert each view Vi into a wiki page Wi. 
4.1 Creating a Structured Database G 
Here we describe in detail the language we use to model database G, how we extend a conventional RDBMS to cap- ture temporal aspect of G, and how we initialize G using the Cimple solution [14]. 
4.1.1 Modeling Database G 
To model G, we can choose from a wide variety of data lan- guages. Since the data from G will eventually appear in wiki pages as structured constructs (see Section 4.3 for a motiva- tion for this), we had to select a data language that ordinary, database-illiterate users are familiar with, and can quickly understand and edit. Since most users are already familiar with the concepts of entity and relationship, as commonly 

========3========

idid = 8= 8 namename = Statistics= Statistics 
interestsinterests idid = 7= 7 
idid = 6= 6 namename = Privacy= Privacy 
interestsinterests idid = 5= 5 
idid = 12= 12 
namename = Sigmod 02= Sigmod 02 servicesservices 
idid = 11= 11 
asas =general chair=general chair 
idid = 14= 14 
servicesservices 
namename = Sigmod 06= Sigmod 06 
idid = 13= 13 
asas =tutorial chair=tutorial chair 
+ person(id=1){name,title} 
+ person(id=1).interests.topic{name} 
– person(id=1).interests.topic(name=Statistics){name } 
id = 6 name = Privacy 
interests id = 5 
interestsinterests 
idid = 3= 3 idid = 4= 4 
namename = Parallel Database= Parallel Database 
idid = 1= 1 
namename = David J. DeWitt= David J. DeWitt titletitle = John P. Morgridge Professor= John P. Morgridge Professor organizationorganization = UW-Madison= UW-Madison 
interests 
id = 3 id = 4 
name = Parallel Database 
<# person(id=1){name}=David J. DeWitt #> <# person(id=1){title}=John P. Morgridge 
Professor #> 
(b) 
<# person(id=1) {organization}=UW-Madison #> 
id = 1 
name = David J. DeWitt title = John P. Morgridge Professor organization = UW-Madison 
<strong>Interests:</strong> 
<# person(id=1).interests(id=3) 
.topic(id=4){name}=Parallel Database #> 
<# person(id=1).interests(id=5) 
.topic(id=6){name}=Privacy #> 
(c) 
(d) 
Figure 3. 
sample data is exported into a wiki page in the s-slot wiki language. 
(a)(a) 
(a) A snapshot of the ER graph G, (b) a sample view schema, (c) a sample data of the above view, and (d) how the above 
employed by current community portals, we choose an ER language to represent the data in G. 
Speciﬁcally, we deﬁne the schema Gs of G to consist of a set of entity types E1, . . . , En and a set of relation types R1, . . . , Rm. Each entity/relation type is speciﬁed using a set of attributes. Attributes are either atomic, taking string or numeric values, or set-valued. 
Next, we deﬁne the data Gd of G to be a temporal ER data graph. This graph contains (a) a set of nodes that specify entity instances (or entities for short when there is no ambi- guity), (b) a set of edges that specify relation instances (or relations for short when there is no ambiguity), (c) temporal information regarding attributes, entities, and relations, e.g., when an attribute/entity/relation was created, by which user, when it was deleted, by whom, when it was reinstated, etc. This information will be used in managing users (Section 6). We view machine M as a special user M. 
We require G to be a temporal database that captures all changes so far, so that later we can develop undo facilities (not yet considered in this paper). Note also that even if Gs speciﬁes that a person entity has an attribute email, this at - tribute can be missing from a particular person instance. 
Figure 3.a shows for example the snapshot of a tiny Gd at time 1. On this snapshot the nodes are entities and the edges are relations (labeled with relation names). The attributes are described next to the nodes and edges. 
4.1.2 Storing G using RDBMS 
We want to query G efﬁciently and may want to implement a variety of concurrency control schemes later (to manage concurrent user edits), including lock-based schemes. Con- sequently, we decided to store Gs and Gd using an RDBMS. The key questions are then: (1) How to convert Gs, essen- tially an ER graph, into a set of relational tables? (2) How to extend a conventional RDBMS to store temporal data? (3) How to manage data from multiple users and machine? In what follows, we ﬁrst elaborate on and propose an initial so- lution to each question. Then we present a complete solution to storing G using an RDBMS. 
Converting Gs into Relational Tables: As described above, schemaGs consists of a set of entity types and relation types. A standard approach to translating Gs into a relational 
database schema is to convert each entity (or relation) type into a table. And each attribute of the entity (or relation) type becomes an attribute of the table. An example is shown in Figure 4.a. Table person store person entity instances. In the table, column id gives the ID of a person entity, and name, title and organization are the three attributes describing each person. Such a design, however, is not space-optimized in our scenario for the following reasons: 
• A table may be sparse. Take a person table for exam- 
ple. Most title values may be missing. This happens 
when title values are obtained from data sources, but the 
extractors are not powerful enough to extract them, or 
many title values are simply not available in the sources. • Users may create new attributes for an entity type (e.g., 
creating attributes homepage and country for person). 
In this case, we need to enlarge the schema of the entity 
table, and entries for these new attributes are empty. • Last but not the least, as we will see later, space uti- 
lization gets worse when we extend an RDBMS to store 
temporal data. When an attribute is updated, instead 
of updating the value in place, we logically delete the 
record with the old value and insert a new record with 
the new value. Other attribute values in the old record 
are copied to the new record. Consequently, we waste 
space in duplicating other attributes. Waste is signiﬁcant 
when the table is wide (i.e., contains many attributes) 
and updates are frequent. 
To address these problems, we chose to vertically partition an entity or relation table along each attribute. Consider an entity type E. Let A1, . . . , An be the set of attributes E has. We convert E into n attribute tables. Each attribute table Ti (1 ≤ i ≤ n) is deﬁned as Ti(id, value), where id stores the ID of an entity e, and value stores the Ai value of e. In ta- ble Ti, we only store those entities that have an Ai value. A partitioning of the person table in Figure 4.a is given in Fig- ure 4.b-d. Note that table person title has only one record since title values for the other two persons are missing. Sim- ilarly, we can convert a relation type into a set of attribute tables. For a relation type, in addition to the attribute tables, we need one more table to store the IDs of the entities that each relation relates, as we will see later. 

========4========

person_name 
idid 11 22 33 
namename David J. DeWittDavid J. DeWitt Mike BrownMike Brown Chris CliftonChris Clifton 
person 
titletitle 
ProfessorProfessor 
NULLNULL 
NULL NULL  
organizationorganization UW-MadisonUW-Madison 
NULLNULL 
PurduePurdue 
idid 11 22 33 
(a) 
person_title 
person_organization 
valuevalue David J. DeWittDavid J. DeWitt Mike BrownMike Brown Chris CliftonChris Clifton 
idid 11 
valuevalue ProfessorProfessor 
idid 11 33 
valuevalue UW-MadisonUW-Madison 
PurduePurdue 
(b) 
(c) 
(d) 
Figure 4. Tables for person entities: (a) a single table for all attributes, and (b)-(d) vertical partitions of the single table. 
Supporting Temporal Data: A user may enter an incorrect data value into the database, either unintentionally or inten- tionally. Once detected, we need to be able to rollback the data item to its previous correct value, which may be a long time ago. To provide such undo facilities, we require G to be a temporal database. Extending a conventional database to support temporal data has been well-studied [23, 18]. Cur- rently we use the transaction-time table solution which is de- scribed in detail in [23]. 
Speciﬁcally, to convert a non-temporal attribute table T(id, value) into a temporal table T′, we append T with two columns, denoted as start and stop. Thus we obtain T′(id, value, start, stop). Attributes start and stop are two timestamps: start indicates when a value was ﬁrst inserted into the database, and stop indicates when the value was up- dated or deleted. Note that the primary key of T′ consists of id and stop. This is because an entity (or relation) attribute may take different values at different times. In our design, all these values are stored in the same table with the same entity (or relation) ID but different stop values. 
Figure 5.a gives an example of a temporal table for per- son organization (Figure 4.d). In the example, at time 2007- 04-01 08:01:20, a user entered organization “UW-Madison” for the person entity with id = 1 (person1 for short). At- tribute start was set to “2007-04-01 08:01:20” to indicate that the value “UW-Madison” started to be current at the time of insertion. Attribute stop was set to “9999-12-31 23:59:59”, which is the largest timestamp, to indicate that the value would be current forever. 
Moreover, when an attribute value is updated or deleted, we ﬁrst logically delete its record, then insert a new record with the new value (for update) or a NULL value (for dele- tion). Consider again the table in Figure 5.a. Suppose that at time 2007-05-27 09:50:10, another user modiﬁed the orga- nization value of person1 from “UW-Madison” to “UW”. To reﬂect the modiﬁcation in the table, ﬁrst we located the reco rd with the value “UW-Madison”, and changed the stop time of the record to the current time, denoting that the value of “UW- Madison” stopped to exist at 2007-05-27 09:50:10. Next, we inserted a new record for value “UW”. We set start and stop of the new record to “2007-05-27 09:50:10” and “9999-12- 31 23:59:59”, respectively, denoting that “UW” would be the current value from 2007-05-27 09:50:10 on. The temporal table after the modiﬁcation is shown in Figure 5.b. 
idid 11 33 
valuevalue UW-MadisonUW-Madison 
PurduePurdue 
startstart 2007-04-01 08:01:202007-04-01 08:01:20 2007-05-02 11:40:352007-05-02 11:40:35 
(a) 
stopstop 9999-12-31 23:59:599999-12-31 23:59:59 9999-12-31 23:59:599999-12-31 23:59:59 
idid valuevalue startstart stopstop 
11 UW-MadisonUW-Madison 2007-04-01 08:01:202007-04-01 08:01:20 2007-05-27 09:50:102007-05-27 09:50:10 
33 PurduePurdue 2007-05-02 11:40:352007-05-02 11:40:35 9999-12-31 23:59:599999-12-31 23:59:59 
11 UWUW 2007-05-27 09:50:102007-05-27 09:50:10 9999-12-31 23:59:599999-12-31 23:59:59 
(b) 
Figure 5. Examples of transaction-time tables for per- son organization: (a) before entity with id=1 is updated, and (b) after entity with id=1 is updated. 
By adding start and stop to an attribute table and by do- ing logical deletions and updates, we keep track of all values that an attribute has taken, and for each value, the time period during which it was current. This way, we are able to recover an attribute value of any time in the past. Besides tracking attribute values, we also need to maintain temporal informa- tion regarding entities and relations themselves, e.g., when an entity was created, and when a relation was deleted. To store such temporal information, for each entity and relation type, we ﬁrst create a special attribute exists, then create a tem- poral table for exists the same as we do for other attributes. Attribute exists can take one of the two values, 1, denoting that the corresponding instance was created or reinstated, or 0, denoting that the instance was deleted. Creating an entity or relation instance can thus be implemented as inserting a record into an exists table with a value of 1, and deleting an instance can thus be implemented as logically updating the value to 0. This way, we are able to tell from an exists table whether an instance existed at a given time. 
Managing Data from Multiple Users: Multiple users may contribute data into the database. For user management (Sec- tion 6), we need to know which user inserted, updated or deleted a data item. Moreover, two users may disagree on the value for one data item. And we need to decide whose value to use in generating Vd for a wiki page (Section 4.2). 
To track the source of each data item, we further extend a temporal table T′ by appending a column who, which stores the ID of the user who entered that item. The resulting table T′′ is deﬁned as T′′(id, value, start, stop, who). Note that the primary key does not change, since we only allow one 

========5========

value of each attribute to be current at any time, regardlessof by whom. 
Among all users, machine M is a special one. It au- tomatically extracts and integrates data from a set of data sources. Thus it supplies data into the database much more frequently than any particular human user. On the other hand, M's data suffers from inaccuracies due to the capac- ity of the extraction and integration methods M uses. Con- sequently, M's data has lower credibility than other users' data. Therefore, we need to distinguish M from the rest of users. As a solution, for each attribute A, we create two temporal tables, A m(id, value, start, stop, who)1 and A u(id, value, start, stop, who). Table A m stores attribute values entered by M, and table A u stores values entered by human users. 
An attribute may have different values in tables A m and A u. To decide which value to use in generatingVd, we need to resolve conﬂicts between the two tables. As a solution, we deﬁne a view table A p over A m and A u. Table A p has the same schema as A m and A u, and it stores the [[ne- gotiated]] value of each attribute. Table A p is updated when A morA uis updated. Thus we can embed in its update pro- cedure how we resolve conﬂicts in attribute values. Specif- ically, when an attribute a is updated in either of A m and A u, we ﬁrst check whether a is already in A p. If not, we simply insert a with its value into A p. (Values for start, stop and who are assigned accordingly.) Otherwise, we need to decide whether we should overwrite a's value in A p. A reasonable approach is to allow a user U to overwrite data entered by M or another user. We also allow M to overwrite its own data, but only allow it to overwriteU's data in certain situations, for example, when M is sufﬁciently conﬁdent in its data. 
An example of A m, A u and A p for table per- son organization is shown in Figures 6. For simplicity of illustration, we assume that a user U can overwrite ma- chine M's data but M cannot overwrite U's data. Based on this assumption, when user U2 entered value “UW- Madison” for person1, we ﬁrst inserted the value into ta- ble person organization u, then logically updated the exist- ing value “UW” in table person organization p. Value “UW” was entered by M and thus we overwrote it with U2's value. In contrast, when M entered “MITRE” for person3 into per- son organization m, we did not update value “Purdue” in person organization p since “Purdue” was entered by a hu- man user. 
Finally, table A p can be explicitly stored in the database or computed as needed. In our design, we chose to material- ize A p for efﬁciency. 
A Complete Solution: With all the problems addressed, we now present a complete solution to storing G in an RDBMS. 
1In an 
A m table, who ≡“M” since M is the only machine involved. We keeps attribute who in the table so that our design is easily extensible to multiple machines. 
Formally, let Gs and Gd be the schema and the data of G. Let E1, . . . , En be the set of entity types in Gs, and R1, . . . , Rm be the set of relation types in Gs. Suppose for simplicity that each relation type is binary. We create the fol- lowing relational tables to store G: 
• An entity ID table Entity ID(id, ename), where id 
and ename store the ID and the type of an entity. • For each entity type E, we create a special attribute 
exists, whose value can be either 1 or 0. Denote ex- 
ists as A0. Let A1, . . . , Ak be the attributes of E in 
Gs. For each attribute A ∈ {A0, . . . , Ak}, we create 
three temporal tables, A m, A u and A p. Each table 
T ∈ {A m, A u, A p} is deﬁned as follows: 
T(id, value, start, stop, who), 
where id is the ID of an entity, and value is the value of attribute A of that entity. Timestamps start and stop speciﬁes a time period during which the value was cur- rent. And ﬁnally, who gives the ID of the user who en- tered that value. 
• For each relation type R, we create a relation ID table R ID. Let E1 and E2 be the two entity types that R relates in Gs, table R ID is deﬁned as follows: 
R ID(id, eid1, eid2), 
where id is the ID of a relation, and eid1 and eid2 are 
the IDs of the two related entities. Similar to converting 
an entity type, we ﬁrst create attribute exists for R, then 
create tables A m, A u and A p for attribute exists and 
each attribute of R in Gs. 
A user may create an entity type (same for a relation type and an attribute), delete an entity type, or reinstate a deletedentity type. To enrich catalog data with temporal information, we also create three meta tables: 
• Table meta entity(ename, start, stop, who), which 
stores the names of the entity types that have been cre- 
ated. Attributes start, stop and who (same for those 
attributes in tables meta relation and meta attribute 
below) have the same semantics as they do in an attribute 
table. 
• Tablemeta relation(rname, ename1, ename2, start, 
stop, who), which stores the names of the relation types 
that have been created. For each relation type R, the 
table also store the names of the two entity types that R 
relates. 
• Tablemeta attribute(tname, aname, category, type, 
start, stop, who), which stores the name of each at- 
tribute (aname) that each entity or relation type (tname) 
has. For each attribute, the table also gives its category 
(atomic or set-valued) and data type (string or numeric) 
speciﬁcations in category and type, respectively. 
Examples of the meta tables are shown in Figure 7. 

========6========

person_organization_m 
idid 11 33 
valuevalue UW-MadisonUW-Madison 
MITREMITRE 
idid 33 11 
valuevalue PurduePurdue UWUW 
startstart stopstop whowho 2007-04-01 08:01:202007-04-01 08:01:20 9999-12-31 23:59:599999-12-31 23:59:59 MM 2007-05-20 16:20:302007-05-20 16:20:30 9999-12-31 23:59:599999-12-31 23:59:59 MM 
(a) 
person_organization_u 
startstart stop whostop who 2007-05-02 11:40:352007-05-02 11:40:35 9999-12-31 23:59:599999-12-31 23:59:59 UU11 2007-05-27 09:50:102007-05-27 09:50:10 9999-12-31 23:59:599999-12-31 23:59:59 UU22 
(b) 
person_organization_p 
idid 11 33 11 
valuevalue UW-MadisonUW-Madison 
PurduePurdue 
UWUW 
startstart 2007-04-01 08:01:202007-04-01 08:01:20 2007-05-02 11:40:352007-05-02 11:40:35 2007-05-27 09:50:102007-05-27 09:50:10 
stopstop 2007-05-27 09:50:102007-05-27 09:50:10 9999-12-31 23:59:599999-12-31 23:59:59 9999-12-31 23:59:599999-12-31 23:59:59 
whowho MM UU11 UU22 
(c) 
Figure 6. An example of attribute tables for organization of entity type person: (a) A m, (b) A u, and (c) A p. 
enameename personperson pubpub topictopic …… 
meta_entity 
startstart stopstop 2007-03-12 05:10:002007-03-12 05:10:00 9999-12-31 23:59:599999-12-31 23:59:59 2007-03-12 05:10:102007-03-12 05:10:10 9999-12-31 23:59:599999-12-31 23:59:59 2007-03-12 05:10:202007-03-12 05:10:20 9999-12-31 23:59:599999-12-31 23:59:59 
…… …… 
(a) 
whowho MM MM MM …… 
rnamername interestsinterests write-pubwrite-pub adviseadvise 
…… 
tnametname personperson personperson personperson …… 
anameaname titletitle ageage ageage …… 
categorycategory atomicatomic atomicatomic NULLNULL 
…… 
meta_attribute 
typetype CHAR(100)CHAR(100) 
INTINT 
NULLNULL 
…… 
(c) 
ename1ename1 personperson personperson personperson 
…… 
ename2ename2 topictopic pubpub personperson 
…… 
meta_relation 
startstart 2007-03-12 05:10:302007-03-12 05:10:30 2007-03-12 05:10:402007-03-12 05:10:40 2007-05-24 16:04:272007-05-24 16:04:27 
…… 
(b) 
stopstop 9999-12-31 23:59:599999-12-31 23:59:59 9999-12-31 23:59:599999-12-31 23:59:59 9999-12-31 23:59:599999-12-31 23:59:59 
…… 
whowho MM MM UU11 …… 
startstart 2007-03-12 05:10:502007-03-12 05:10:50 2007-04-18 12:40:192007-04-18 12:40:19 2007-06-10 10:30:252007-06-10 10:30:25 
…… 
stopstop 9999-12-31 23:59:599999-12-31 23:59:59 2007-06-10 10:30:252007-06-10 10:30:25 9999-12-31 23:59:599999-12-31 23:59:59 
…… 
whowho MM UU22 UU33 …… 
Figure 7. Examples of meta tables: (a) meta entity, (b) meta relation, and (c) meta attribute. 
4.1.3 Initializing G 
To initialize G, we employ a machine-based solution M. Many such solutions exist [14]. Currently we use the Cim- ple solution which is described in detail in [14]. The solution works in two steps: (1) creating an entity-relationship (ER) graph, and (2) importing the ER graph into database G. Creating an Entity-Relationship Graph: First, a com- munity expert provides Cimple with a set of relevant data source. Use the community of database researchers as an example. Data sources can be home pages of database re- searchers, DBLP, conference pages, etc.. The expect also provides domain knowledge about entities and relations of interest. For example, person and conference are two entity types, and between them exists a relation type give-talk. 
Then Cimple uses simple but focused automatic methods to create an ER graph of the community. Speciﬁcally, Cim- ple ﬁrst crawls the sources at regular intervals to obtain data pages, then marks up mentions of relevant entities. Exam- ples of mentions include people names (e.g., “D. DeWitt”, “David J. DeWitt”), conference names, and paper titles. Nex t, Cimple matches mentions and groups them into entities (e.g., mentions “D. DeWitt” and “David J. DeWitt” refer to the same person entity). Cimple then discovers relations among the entities. As a result, Cimple creates an ER graph from 
the raw data sources. 
DBLife is an example portal built using such a semi- automatic solution. 
Importing the ER Graph into DatabaseG: Cimple stores the ER graph in a set of XML ﬁles. To initialize database G, we ﬁrst convert Gs into a set of relational tables, as described in Section 4.1.2. Then we use an import module to bulk load the XML data into G. 
4.2 Creating Views over Database G 
View Language Requirements: To create views overG, we must deﬁne a view language L. We now discuss the require- ments for L. First, we note that a primary goal of community portals is to describe interesting entities and relations in the community. Toward this goal, we use each wiki page W to describe an entitye or a relationr. A popular way to describe an entity e, say, is to describe a “neighborhood” of e on the ER data graphG, e.g., all or most nodes within two hops from e. Consequently, language L must be such that we can easily write and modify views that describe such “neighborhoods”. 
Second, when a user requests a wiki pageW, we material- ize it on the ﬂy, to ensure the page contain the latest updates . This in turn requires materializing the view V underlying W (see Section 5.3). Consequently,Lmust be such that its views 

========7========

can be materialized quickly, to ensure real-time user interac- tion. 
Finally, when a user U edits a wiki page W, we assume that U may also edit the schema of view V underlying W, e.g., by removing all papers from W, U may be modifying V 's schema to exclude all papers (Section 5.1 discusses this assumption in depth). Hence, language L must be such that we can modify a view schema quickly, based on user edits, to ensure real-time user editing. 
A Path-based View Language: The above requirements led us to design a path-based view language Lp. To deﬁne Lp, ﬁrst we deﬁne data and schema paths. Intuitively, a data path is a path on the ER graph G that (a) starts with an entity node e1 and ends at an entity node en, and (b) retains only certain attributes for each node/edge along the path. 
A schema path p = ep1.rp2.ep3. . . . .rpn−1.epn then speciﬁes a set of data paths, which start with node ep1, fol- low edge rp2, etc., then end with node epn. To further con- strain these data paths, we express each epi as Ti(Ci){Ai}, meaning that (a) epi must have type Ti and satisfy condition Ci (which is a conjunction of conditions over the attributes), and (b) we keep only those attributes of epi that appear in Ai (which is a set of attribute names). Ti is required, but (Ci) and {Ai} are optional. A missing {Ai} means that we retain all attributes. We express each rpi in an analogous fashion. 
Example 4.1. The schema path person(id = 1){name, title} speciﬁes a single data path that corresponds to person entit y with id=1 and that contains only attributes name and title of this entity. The schema path, person(id=1).give-tutorial.conf{name}, speciﬁes a set of data paths, each of which starts with a person node whose id is 1, follows an edge give-tutorial, then ends with a conf node. For each path, we retain all attributes of person node and give-tutorial edge, but retain only the name attribute of conf node. 
We can now deﬁne ER views considered in this paper as fol- lows: 
Deﬁnition 1 (Path-based ER views). A path-based ER view (or view for short when there is no ambiguity) V has a schema Vs = (In, Ex), where In and Ex are disjoint sets of schema paths over G. Evaluating Vs over G yields the view data Vd. Vd is a sub- graph of G that contains only data paths that are (a) speciﬁed by some path schema in In and (b) not speciﬁed by some path schema in Ex. We refer to schema paths in In and Ex as inclusive and exclusive paths, respectively. 
Example 4.2. Figure 3.b shows a sample Vs that has two inclusive paths and one exclusive path. This view schema selects a person e with id = 1, retains name and title of e, then selects all interests of e except those named “Statistics”. Evaluating this view sche ma over the ER graph G of Figure 3.a produces the view data Vd in Figure 3.c. 
We now discuss how language Lp satisﬁes the require- ments outlined earlier. First, most “neighborhoods” of an e n- tity e (e.g., all nodes within two hops of e on ER graph G) can be expressed with a set of inclusive and exclusive data 
paths. Hence, Lp allows us to quickly write views that cap- ture such neighborhood, in an intuitive manner. Second, eval- uating schema paths amounts to performing selection opera- tions overG. Hence, views inLp can be materialized quickly. Finally, if a user edits a view schema (using a wiki page), then such edits can be quickly mapped into a set of inclusive and exclusive schema paths, allowing us to modify the view schema quickly and easily (see [13] for an in-depth discus- sion). 
Creating Views over ER Graph G: Now that we have de- ﬁned the view language Lp, we can discuss how Cwiki uses Lp to create views over G. First, Cwiki decides on the set of entities and relations to be “wikiﬁed”. Currently, for simp lic- ity we consider all entities, but no relations. Next, for each entity e of a particular type (e.g., person), Cwiki speciﬁes a default view schema Vs that speciﬁes a “neighborhood” of e. Cwiki thus speciﬁes as many default view schemas as the number of entity types to be “wikiﬁed”. These default view schemas are application speciﬁc. The data of the views is not stored, but will be materialized on the ﬂy, when creating and refreshing wiki pages, which we discuss next. 
4.3 Converting Views to Wiki Pages 
Given a view V with schema Vs and data Vd as deﬁned above, we now discuss converting Vd into a wiki page W. In the following, we introduce our novel s-slot solution. We also discuss some other non-trivial design issues, such as the ordering of entities, the formation of URLs and the use of schema pages. 
A Spectrum of Solutions: Since most current wiki data (e.g., Wikipedia) is natural text, the straightforward solution is to convert Vd into a set of natural-language sentences. For example, suppose Vd speciﬁes that person X works for orga- nization Y . Then we can convert this into sentence “X works for Y ” in wiki page W. Knowing this template, if a user later modiﬁes the sentence to be “ X works for Y 
′”, we can still parse it back, realize that Y has been modiﬁed to be Y 
′, then update the underlying database G accordingly. 
This was indeed the ﬁrst solution we tried. It is very easy for users to edit natural-language wiki pages generated by this solution. But after extensive experiments, we found that it is difﬁcult to extract and update structured data. The set of templates that we can use in natural language settings is somewhat limited; hence, they get reused in multiple con- texts, causing many ambiguities for the extractor. Further- more, suppose G has been updated so that X is now working for Y 
′. To update 
W with this information, we must be able to pinpoint the location of Y . This is equivalent to being able to extract Y , a difﬁcult task, as discussed earlier. 
For these reasons, we wanted a solution where it is trivial to pinpoint pieces of structured data contributed by Vd. A wiki page then contains multiple “islands” of structured da ta from Vd, in a “sea” of natural text contributed by users. We refer to these “islands” as s-slots (shorthand for structured 

========8========

slot). Below we describe this s-slot solution. In Section 7 we discuss how the natural-language and s-slot solutions lie at two ends of a spectrum of solutions that trade off (a) ease of user edit, (b) ease of extracting and updating structured data, and (c) ease of moving data around on wiki pages. The S-Slot Solution: We ﬁrst deﬁne the notion of at- tribute path. Recall that a schema path p has the form T1(C1){A1}. . . . .Tn(Cn){An}. We say that p is an attribute path iff A1  An−1 are empty sets and An identiﬁes a single attribute a. Thus, p uniquely identiﬁes attribute a. Examples of attribute paths are person(id = 1){title} and 
person(id = 1).write-pub(id = 5).pub(id = 14){name}. 
An s-slot s then has the form <# p = v #>, which speciﬁes that the attribute a uniquely identiﬁed by the attribute path p takes value v. An example of wiki text including an s-slot is 
<# person(id=1){name}=David DeWitt #> works for <# person(id=1).work-org.org(id=13){name}=UW #> since 1976. 
When a wiki page is rendered into an HTML page, only the value v of an s-slot < # p = v # > is presented while other parts, as meta data, are suppressed. Thus the HTML presentation of the above example wiki text will dis- play “David DeWitt works for UW since 1976”. 
An s-slot of <# p = v #> can be marked with a “nodis- play” attribute as in <# p = v nodisplay#>. In this case, the whole s-slot will be suppressed and even the value v will not be presented in the HTML page. Such s-slots are useful when the values are conﬁdence scores used for entity order- ing, as to be discussed shortly. 
An s-slot of < # p = v #> can also be marked with an “invalid” attribute as in < # p = v invalid#>, indi- cating that the path p is broken and unsupported by the un- derlying database, and thus, the validity of the value v ex- pired. This situation is generally caused by deletion of struc- tured data from other related wiki pages. When a page con- taining invalid structured data is requested, the “invalid” at- tributes will be added by machine for the corresponding s- slots. <# p = v invalid#> will be presented in the HTML page as “v(invalid)”, reminding the user of the fact and leav- ing him/her the right to delete the s-slot or ﬁx the broken pat h. 
Now let V be a view with schema Vs that Cwiki has de- ﬁned over database G (see Section 4.2). Then Cwiki gener- ates the default wiki pageW for V in two steps: (a) evaluates Vs over G to obtain the view data Vd, which is a subgraph of the ER graph G, then (b) convert Vd into a wiki page W using s-slots interleaved with English text. 
Step (a) is relatively straightforward. Step (b) can be ex- ecuted in many different ways. We currently adopt a de- fault solution. Suppose we know that view V (and thus wiki page W) describes entity e, e.g., David DeWitt. Then our default solution ﬁrst generates the line < #person(id = 1){name} = David DeW itt #> as the title of the wiki 
Input: Output: 
View data graph Vd describing entity e. Wiki page W. 
1. initialize W to be empty; 
2. make title of W the s-slot corresponding to the name attribute of e; 3. create a section S in W for the attributes of e; 
4. FOR each selected attribute type a of e other than name in Vd DO 5. insert the s-slot corresponding to a into S; 
6. FOR each relationship type r of e in Vd DO 
7. create a section Sr in W for r; 
8. identify a set P of data paths from Vd corresponding to r; 
9. IF P is sortable THEN sort P; 
10. FOR each edge (e, f) corresponding to an instance of r DO 11. create an item I in Sr; 
12. identify a subset Pf ⊆ P of paths that share (e, f); 
13. insert into I the s-slots corresponding to all selected attributes in Pf; 
Figure 8. Generating wiki page W from view data Vd 
page. Next, it displays the attributes of e, then the relation- ships. Figure 3.d shows how the data graph Vd in Figure 3.c may have been displayed in a wiki page. In the following, we explain the algorithmic details about how to generate a wiki page W from a view data graph Vd. 
The Algorithm Generating W from Vd: The algorithm presented in Figure 8 generates a wiki page W from a given view data graph Vd for entity e. In line 1, W is initialized to be empty. In line 2, the s-slot corresponding to the name attribute of e is made title of W. In lines 3–4, a section is created in W for other selected attributes of e, that provides the basic attributional information describing e. In lines 5– 13, a section is created in W for each relationship type. 
Each section is labeled properly with a uniform default look. This can be done since in building an initial community portal W, the only participating user is the portal builder, for whom the semantics of each attribute type, entity type and relationship type are transparent to him/her since he/she was the one who created the initial view schema Vs. The selec- tion of view V delivers the builder's intention and the look of the wiki page represents his/her preferences. For the same reason, in line 7, the data paths in Vd for relationship type r can be extracted properly. Notice that Vd itself does not em- bed such information that how it should be decomposed and presented. Rather, the extraction mechanisms are hard-coded for each relationship section. For example, for the “writes” relationship, the paths of type person.write-pub.pub.write- pub.person starting at entity e are extracted from Vd. 
In line 8, the extracted paths are possibly sorted if the or- dering information is provided in the paths. In lines 9–13, t he extracted paths are grouped such that each group corresponds to a unique instance of the relationship type r. Then, the s- slots for the selected attributes of each group form an item and the item is inserted into the section. 
The portal builder has every reason to capture the prefer- ences of the majority of users. The above hard-coded inter- pretation mechanism translates Vd into a default wiki page W, so that the initial community portal mathw features 

========9========

HTML pages with a uniform look that is easy to the eyes of the majority of users. Later, W would be edited by dif- ferent individuals, and this default interpretation mechanism will not be used in updatingW by machine, in order not to in- tervene users' intentions and interpretations. Instead, all the fresh structured contents will be inserted into a special sec- tion called “New”, from which users can pick up items and move them around according to their own preferences. 
Ordering of Entities: Handling the ordering of entities is a non-trivial design issue. In many cases, entities have a natu- ral ordering depending on how much they relate to a common entity. For example, the related people of a person can be or- dered by the closeness of their relationships to that person. The related topics of a person can be ordered by the degree of interest and involvement of that person in those topics. As an- other obvious example, all the authors of a publication must be ordered by how they appear in the publication. To capture the ordering information, we assign each involving relation- ship a conﬁdence score as attribute. 
In order for applicable entities to appear ordered in the HTML page, the conﬁdence score attribute needs to be se- lected in Vs. Then, the corresponding data paths in Vd will present this ordering information and be ordered properly by the algorithm (line 9) convertingVd toW. The corresponding s-slots in W will be marked with “nodisplay” and thus those actual conﬁdence score values will not be displayed in the HTML page. This handling of entity ordering is not meant to be systematic and sophisticated to cover arbitrary ordering needs; rather, it focuses on simplicity and adequacy in terms of fulﬁlling the basic ordering functionality. 
Formation of URLs: The formation of URLs raises another non-trivial design issue. For the HTML page speciﬁed by a URL of http://dblife-labs.cs.wisc.edu/wiki - test/index.php/David DeWitt, the corresponding wiki page will have a URL of http://dblife-labs.cs.wisc.edu/wiki- test/index.php?title=David DeWitt&action=edit. “David De- Witt” is the page title for the HTML page as well as the wiki page. As page title is the only replaceable element in a URL, the formation of URLs comes down to the formation of page titles. 
Within the same namespace, each entity e must have a unique page title. A natural solution to achieve this unique- ness is to use entity ID's as titles. However, such page titles are neither informative to users nor cooperative with search engines. Entity names seem to be the most informative titles; however, they cannot guarantee the uniqueness since multiple entities may share the same name. In our design, a mapping table is maintained to map each entity ID to a unique page title. In general cases, entity names are used as page titles. In cases a title is used by another entity, a concatenation of entity name and ID will be used. 
In particular, we create a mapping table with three ﬁelds eid, title, and type, storing entity ID's, page titles and en- 
tity types respectively. Both eid and title are keys. When a new entity e is inserted into the database, a default wiki page will be created for e and the mapping table is used to generate the page title. First, the entity ID of e, say 15, is checked against existing ones in the mapping table. If no du- plicates, the name of e, say “David DeWitt”, is then checked against existing page titles in the table. If no duplicates, 15 and “David DeWitt” will form a tuple and be inserted into the table. Otherwise, a concatenation of “David DeWitt” and 15, i.e., “David DeWitt15”, will be used instead as the page title. Obviously, the page titles thus-generated are guaranteed to be unique. 
Use of Schema Page: As to be discussed in §5.1, we expose view schemas in wiki pages to allow user editing. Thus, a default schema page Ws will be created for each default wiki page W. Ws will have the same page ti- tle as W but under the namespace of “Schema”. For ex- ample, the URL for the schema page of the wiki page of David DeWitt will be http://dblife-labs.cs.wisc.edu/wiki- test/index.php/Schema:David DeWitt. 
Since all the default schema pages of the same type dif- fer only in entity ID, they can be automatically generated and bulk-loaded into the system when building the initial com- munity portal. In particular, all the entities are ﬁrst regi stered in the mapping table. Then, a default schema page is gener- ated for each tuple in the table according to the entity type stored in the table. Next, all these schema pages are written in a single ﬁle, which is then bulk-loaded into the database supporting the wiki system, without utilizing the interface of the system. 
The set of all wiki pages generated as above constitutes the initial community portal W. The next section discusses how users can contribute to this portal. 
5 Managing User Contributions 
In this section we discuss what users can edit and how to process those edits. 
5.1 What Can Users Edit? 
Consider a user U editing a wiki page W. We allow U to edit both text and structured data of W. Editing text is trivial. Editing structured data of W means U can modify or delete s-slots, or insert new ones. 
In modifying an s-slot s =<#p = v#>, U can modify the attribute path p as well as value v, but is not allowed to modify the formatting characters (e.g., <#, =, and #>). If U were to do so, then the parser would fail to recognize the s-slot, and hence would interpret the modiﬁed s-slot as text , not structured data. 
Let V be the underlying view of W. Conceptually, editing structured data of W means editing one or a combination of the following components: the data of V , the schema of V , the data of G, and the schema of G (denoted Vd, Vs, Gd, Gs, respectively). 

========10========

In traditional settings such as RDBMS, ordinary users can only edit view data and thus also the underlying relational database data. This maps to editing Vd and Gd in our case. Should we also allow users to edit Vs and Gs? We decided to allow these actions, because there is often a natural need to do so. For example, a user U may naturally want to modify W so that it no longer displays emails. To do this, U must modify Vs. U cannot modify Vd because this would mean removing certain emails from G, not the desired effect. As another example, a user U may naturally want to add to an entitye(described inW) a new attributeathat has not existed so far in the portal. To do this, U must modify both Gs and Vs. 
The next question then is: what is the best way to allow users to modify Vs and Gs? A possible option is to expose these schemas in wiki pages, for users to edit. For example, we can expose Vs in a wiki page Ws. Then when U edits W, we interpret such edits as editing Vd, and when U edits Ws, we interpret such edits as editing Vs. 
The above option would greatly reduce the ambiguity in interpreting user edits. However, we decided against it, be- cause we found from experimentation that it is difﬁcult for ordinary, database-illiterate users to remember this option. In fact, users often are not even aware of the distinction be- tween data and schema edits. Instead, they appear to prefer to edit only the wiki page W, then rely on Cwiki to assist them in executing the right kind of edit actions. 
For these reasons, we allow U to edit only wiki page W, then ask U (in English) to clarify if he or she intends to edit the data or the schema. In what follows we discuss this pro- cess in detail. 
5.2 Infer & Execute Structured Edits 
Suppose user U has edited wiki pageW into W′. Then we can parse W′ to extract a text portionT′ and a structured data portion D′. The text portion can immediately be stored in a text database T (see Figure 2). The structured data portion D′ consists of all s-slots in W. 
Next, we can merge all s-slots in D′ together to obtain an ER graph that we will refer to as V 
′ 
d. Given that each s- slot maps uniquely into an attribute in the ER graph G, the merging process is relatively straightforward, and hence will not be discussed further, for lack of space. Our problem now is: given V 
′ 
d, infer what actions user 
U intends to execute on Vd, Vs, Gd, Gs, then execute those actions. 
Basic Relational and ER Actions: To solve the above prob- lem, we ﬁrst deﬁne a set of basic actions that U can execute over Vd, Vs, Gd, Gs. For example, basic actions on Vd in- clude modifying the value of an entity or relation attribute, and deleting an entity. Basic actions on Vs include inserting a new entity and deleting an attribute of a relationship. We have implemented each basic action as a program over the temporal relational database that stores G. The complete sets of basic actions on Vd, Vs, Gd and Gs are given in Table 1. 
Basic ER Actions 
a1: Modify attribute value a2: Insert an existing attribute a3: Insert a new attribute a4: Insert an existing entity a5: Insert a new entity a6: Insert an existing relationship a7: Insert a new relationship a8: Delete an attribute a9: Delete an entity 
a10: Delete a relationship 
Vd           
Vs 
Gd  opt.  opt.  opt.  opt. opt. opt. 
Gs 
         
 
 
 opt. opt. opt. 
Table 2. Basic ER actions that we have deﬁned. 
Appendix A give their implementations. Abusing notation, we will refer to these basic actions as basic relational ac- tions, to distinguish them from the basic ER actions that we will introduce soon below. 
Now given V 
′ 
d, we must infer the sequence of basic rela- tional actions that we believe user U intends to execute. To do this in a manageable fashion, we introduce an intermediate user interface: the ER interface. This interface would display an ER data graph (e.g., Vd) in a graphical fashion, and al- low users to execute a number of basic ER actions, such as modifying a node or an edge, deleting a node, etc. 
The ﬁrst column of Table 2 lists the ten basic ER actions we have deﬁned. We have implemented each ER action as a sequence of relational actions. For example, action a1 (see the table) translates into the sole relational action that modi- ﬁes the value of an entity attribute (in both Vd and Gd). 
However, it turns out that an ER action can be ambigu- ous, in that it can map into different sequences of relational actions, depending on the user intention, as the following ex- ample illustrates: 
Example 5.1. Suppose a user U applies action a8 (see Table 2) to delete an attribute x of, say, a person entity e in an ER graph, e.g., Vd. Then U may mean to delete x from (a) Vs, i.e., do not display x in view V , or (b) Gd, thus declaring that entity e does not have attribute x, or (c) Gs, thus declaring that attribute x does not exist for person (the entity type of e). 
Since we do not know U's intention, if U executes ac- tion a8, then we ﬁrst ask U (in an English phrase) to choose among options (a)-(c) in the above example. Next, we trans- late a8 into the appropriate sequence of relational actions, de- pending onU's answer. For example, ifU chooses option (c), then the sequence of relational actions is: delete x from Vs, delete x from Gd, delete x from Gs. 
For each ER action, Columns 2-5 of Table 2 shows which components (Vd, Vs, etc.) that the action may modify (“opt.” means “optional”, depending on external conditions such as user intentions). 
Mapping User Edits into Sequence of Basic Actions: With the introduction of the ER interface, our problem can be recast as follows. When user U edits the structured data portion of wiki page W, we view it to be equivalent to U 

========11========

a1 a2 a3 a4 a5 a6 a7 a8 a9 a10 
Actions on Vd Modify an entity attribute value Modify a relation attribute value Insert an entity attribute Insert a relation attribute Insert an entity 
Insert a relation 
Delete an entity attribute Delete a relation attribute Delete an entity 
Delete a relation 
Actions on Vs Insert an entity attribute Insert a relation attribute Insert an entity Insert a relation Delete an entity attribute Delete a relation attribute Delete an entity Delete a relation 
Table 1. Basic relational actions on Vd, Vs, Gd and Gs. 
Input: 
Output: 
Data graphs Vd and V 
′ 
d. 
Vd=(E, R, A), V 
′ ′, 
d=(E 
R′, A′), where E, E′ are sets of entity instances, R, R′ are sets of′ 
relationship instances, and A, A are sets of attributes. Sequence of GUI actions SER. 
1. FOR each entity instance e ∈ E′ − E DO 
2. IF entity type exists THEN append a4 to SER; 
3. ELSE append a5 to SER; 
4. FOR each relationship instance r ∈ R′ − R DO 
5. IF relationship type exists THEN append a6 to SER; 6. ELSE append a7 to SER; 
7. FOR each attribute a ∈ A′ − A DO 
8. IF attribute type exists THEN append a2 to SER; 
9. ELSE append a3 to SER; 
10. FOR each attribute a ∈ A − A′ DO 
11. append a8 to SER; 
12. FOR each relationship instance r ∈ R − R′ DO 
13. append a10 to SER; 
14. FOR each entity instance e ∈ E − E′ DO 
15. append a9 to SER; 
16. FOR each attribute a ∈ A ∩ A′ DO 
17. IF it has the same value in Vd and V 
′ 
d 
THEN append a1 to SER; 18. Return SER; 
Figure 9. Generating SER from Vd and V 
′d 
editing the ER graph Vd in the ER interface, using basic ER actions. We do not know what basic ER actions U executes. But we do know the end result, which is the ER graph V 
′ 
d, as described earlier. 
Thus, in this perspective, U has executed a sequence SER of basic ER actions on the original ER graph Vd, transform-′ 
ing it into a new ER graph V 
d. Our task then is to “reverse engineer” SER, by comparingVd with V 
′ 
d, then execute 
SER. Figure 9 shows the pseudo code of our current algorithm to reverse engineer SER. 
To “push” the structured edits of U into the database G, we then execute the actions of SER sequentially. Recall that each such action is a basic ER action (see Table 2), which can be ambiguous. If this happens, recall also that we resolve the problem by asking user U a disambiguating question. We then execute each basic ER action by executing the sequence of relational actions that it maps to, as described earlier. 
A minor problem is thatSER is not unique. Given any two Vd and V 
′ 
d, multiple sequences of actions 
SER may exist that all transform Vd into V 
′ 
d. Fortunately they all have the same 
Actions on Gd Modify an entity attribute value Modify a relation attribute value Insert an entity attribute Insert a relation attribute Insert an entity 
Insert a relation 
Delete an entity attribute Delete a relation attribute Delete an entity 
Delete a relation 
Actions on Gs Create an entity attribute Create a relation attribute Create an entity type Create a relation type Drop an entity attribute Drop a relation attribute Delete an entity type Delete a relation type 
effect, as this theorem shows: 
Theorem 1. Let S1, . . . ,Sk be all sequences of basic ER actions that transform a Vd into a V 
′d. Then when executing any 
Si, the set of questions we pose to user U will be the same for all i. If U gives the same answers to these questions, then executing any Si, i ∈ [1, k], results in the same Vd, Vs, Gd and Gs. 
5.3 Propagate Structured Edits 
Let W1 and W2 be two wiki pages that describe two re- searchers A and B, respectively. Suppose A and B share one publicationp. Sopappears in bothW1 andW2. Now suppose that a user U has edited p in W1. When should we update p in W2? In general, once a user has edited the structured data portion of a wiki page W, how should we propagate this edit to other pages? 
A solution is to immediately refresh other pages, e.g., page W2 in the above example. We call this eager propagation. This solution ensures timely updates of pages, but can raise tricky concurrency control issues. Hence, we currently adopt a lazy propagation approach, where we refresh a page, say W2, only when a user requests the page again. At that mo- ment, we rematerialize the page from the structured database G and the text database T. Section 7 empirically shows that we can refresh pages on the ﬂy quickly, in a few seconds, thus making this lazy approach a practical solution. 
6 Managing Multiple Users and Machine 
While not a contribution of this paper, for completeness we will brieﬂy touch on the key problems of managing mul- tiple users and machines as they contribute to the portal. The full paper [13] discusses these problems and our proposed solutions in detail. 
First, we must manage concurrent editing of a wiki page by multiple users, or concurrent editing of some structured data pieces (e.g., a paper) that appear in multiple wiki pages. Currently we employ the optimistic concurrency con- trol scheme of Wikipedia for this purpose. 
Next, we must detect and remove malicious users. To do this, we currently employ a hierarchy of users, reminiscent to the Wikipedia solution for the same problem. Speciﬁcally , 

========12========

we require users log in to edit, and employ a set of editors whose job is to monitor most active wiki pages. 
Finally, if a user U has modiﬁed a data item X, can ma- chine M overwrite U's modiﬁcation, and if so, then when? Our current solution allows M to overwrite U's data only for certain pre-speciﬁed data types (e.g., certain attributes of per- son), if M is sufﬁciently conﬁdent in its data. For all other data types, we do not allow M to overwriteU's modiﬁcation, but allow it to add a suggestion next to U's modiﬁcations, in parentheses, e.g., “age is 45 (according to M, age is 47)”. 
7 Empirical Evaluation 
To evaluate Cwiki, we have been applying it to build a community wikipedia for the database community (see [1] for the current portal, still under continuous development). We now report on preliminary experiments with this portal, which demonstrate the potentials of Cwiki and suggest re- search opportunities. 
Building an Initial Community Portal: We began by em- ploying DBLife as machine M (see Section 4). It took a two-person team four weeks to developDBLife from scratch. DBLife was ﬁrst deployed on May of 2005, and has been on “auto pilot” since, requiring only about one hour of maintenance per month (for more details, see [14]). Each day DBLife crawls 10,000+ database research related data sources, extracts and integrates the data, to generate a daily ER data graph. 
We used one such daily ER data graph A (98M of XML data) to initialize the structured database G. G's schema has ﬁve entities and nine relationships, and G's data contains 164,043 entity instances and 558,260 relation instances, for a total size of 413M. This size is greater than the ER data graph size of 98M due to the extra space needed to store tem- poral information. It took 216 seconds to load A into G, and 183 minutes to generate and store all wiki pages (164,043 pages for entities). These results suggest that we can create moderate-size initial portals (a one-time task) with relatively little efforts. 
Next, we wanted to know if the initial portal can be main- tained efﬁciently, assuming no user contributions yet. We found that over 10 days, as DBLife contributed data to the structured database G, G's size increased from 413M to 600M. This was somewhat surprising, because DBLife data should not have changed so much over 10 days. Upon a closer inspection, we found that the conﬁdence scores of most rela- tion instances in G (e.g., person X is related to person Y with score .8) were changed by DBLife everyday, due to the changing raw data (retrieved by DBLife). Hence, the conﬁ- dence scores of most relation instances in G were updated everyday, leading to a rapid growth in G's size (recall that G is a temporal database that does not allow update in place, hence changes are added to G). Once we disallowed updat- ing conﬁdence scores, then G grew very slowly (by less than 5M). Thus, this experiment suggests that the current designof 
14.0 12.0 
Page request 
10.0 8.0 6.0 4.0 
Response time (sec) 
2.0 0.0 
10 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 
Page size (# of s-slots) 
(a) 
70.0% 
60.0% 
Page size distribution 
50.0% 
40.0% 
30.0% 
20.0% 
10.0% 
Percent of all pages   
0.0% 
10 20 30 40 50 100 200 300 400 
Page size (# of s-slots) 
(b) 
Figure 10. Time to request a wiki page and distribution of page size. 
# of s-slots = 52     time in sec 
Type of edits 5 edits 10 edits 15 edits 20 edits 25 edits modification 0.258 0.266 0.275 0.283 0.291 insertion 1.041 1.314 1.583 1.826 2.115 deletion 1.012 1.122 1.253 1.363 1.483 # of s-slots = 196    time in sec 
Type of edits 5 edits 10 edits 15 edits 20 edits 25 edits modification 1.183 1.209 1.231 1.247 1.266 insertion 1.971 2.214 2.436 2.662 2.855 deletion 1.615 1.633 1.649 1.665 1.681 
Figure 11. Time to process user edits on a wiki page. 
G is efﬁcient for maintaining all aspects of the initial porta l over time, except for conﬁdence/uncertainty scores. We are currently examining how to modify the temporal design of G to efﬁciently accommodate frequent changes in uncertainty scores. 
Expressive Power of the S-Slot Wiki Language: In the current DBLife system (see dblife.cs.wisc.edu) each user superhomepage is a structured view V over the underlying structured database. We found that the s-slot wiki language (Section 4.3) was sufﬁciently powerful to enable us to expre ss all structured data pieces in such views in wiki pages, except two types of data pieces: top-k and aggregate. A top-k data piece is technically a view that lists the topk items of a ranked list, e.g., the top three authors, cited papers, etc. An aggregate data piece is an aggregate view such as the total number of papers per author, or the total number of citations. 
We found that top-k and aggregate views also appear in many other community portals. Thus, any future attempt to extend wiki languages with structured constructs must ad- dress the problem of expressing such views. The challenge then is how to efﬁciently update such views. 
Efﬁciencies of User Interaction: In the next step, we exam- ined how fast users can interact with the portal. Figure 10.a shows the time it takes from when a user requests a page W until when W is served. Note that to ensure freshness, 

========13========

Editing  tasks Time (sec) Accurac y editing a sentence of free text 13.2 (10~21) 100% modifying a data path 16.4 (10~30) 100% inserting a data path 52 (30~60) 100% inserting two bonded data paths 55 (30~85) 100% inserting a paragraph of data paths 152 (60~240) 100% deleting data paths 36.6 (15~60) 100% 
Figure 12. User performance on several editing tasks. 
we materialize W on the ﬂy, from the underlying structured database G and text database T (Section 5.3). Hence, it is critical that such materialization can be done quickly, to en- sure real-time user interaction. 
The results show that request time increases linearly w.r.t. page size, measured in the number of s-slots in the page, and stays small, e.g., under 2 seconds for page sizes up to 150. Figure 10.b shows that the vast majority of current pages have a size under 50 (the ﬁrst ﬁve bars of the ﬁgure), and thus incur under 1 second request time. This result suggests that we can materialize wiki pages quickly, and that the lazy update approach (Section 5.3) can work well in practice. 
Since processing user edits requires us to translate these edits across different user interfaces and then to invoke the underlying relational database, we wanted to know if it can be done efﬁciently. Figure 11 shows the time it takes from when a user submits his/her edits until when the edits have been processed, i.e., updates on Vs, Vd, Gs, Gd, if any, have been carried out. This time does not include the time users spent answering disambiguating questions (Section 5.2). The top table of the ﬁgure shows edit times over a wiki page with 52 s-slots (each time is averaged over 10 runs). Here each edit is a user action that affects a single s-slot. 
The bottom table of the ﬁgure shows similar edit times, but over a wiki page with 196 s-slots. In both cases, the results show that the edit times remain small, under 2.2 seconds for the small wiki page and 2.9 seconds for the large wiki page. This suggests that Cwiki can process user edits efﬁciently. Ease of User Interaction: Next, we evaluated how easy it is for users to edit structured data in a wiki page W. We conducted a preliminary experiment with 6 users, where each user was asked to edit a certain item on the HTML represen- tation of W. To do so, they had to go to W, locate and then edit the appropriate piece of structured data. We measured how long it took them to ﬁnish the given editing tasks and the correctness of the results. For comparison purposes, we also asked users to edit some free text. 
Figure 12 shows that 100% correctness was achieved for all the editing tasks. Editing time is measured from when the edit button is clicked until when the new HTML page is ren- dered. Figure 12 shows the average and range of recorded editing time over all the users. The results show that the simplest structured data editing task, modifying a data path (modifying an attribute), took comparable time to editing a sentence of free text. 
Inserting a data path generally involves adding several en- tities and relationships to the database. Users need to type a complete legal path. Inserting two bonded data paths is a bit more complex since users need to make sure that several entities (or relationships) are assigned the same id. Inserting a paragraph of data paths is probably the most complex task that generally involves multiple bonded data paths. Speciﬁ - cally, the users were asked to add a publication with a title, an ordered author list, and the conference, year, page, and ci- tation information. The results show that the editing time is very reasonable considering the high complexity of the task. 
Deletion of data paths would generate some ambiguities since the user may mean to delete the structured data from the underlying database or just from the wiki page. Thus after the user clicks the submit button, several questions may be presented as radio buttons to clear the possible ambiguities. Deleting a single data path or many data paths would take similar amount of time from the editing point of view. The only difference is the number of questions to ask. 
This experiment is strictly preliminary. But it does sug- gest that the current solutions may already be adequate in the sense that users are able to correctly execute the various edit- ing tasks within a reasonable amount of time. 
The experiment also suggests that it may be even easier for users to edit if we introduce some macro that hide the de- tails of the structured data and make the structured data looks very clean. This point was conﬁrmed by the users' qualita- tive feedback on how convenient it is to use the system. On a scale of 1 (least convenient) to 5 (most convenient), the cur- rent system scored an average of 2.5. A typical comment is that while the system is easy to learn and functioning well, it is verbose. These comments meet our expectations since our goal for the current version focuses almost exclusively on the adequacy instead of convenience. 
In general, as commented in Section 4.3, a lesson we learned from our current Cwiki experience is that there is a spectrum of solutions on how structured data can be repre- sented in wiki pages. Our s-slot solution represents one spec- trum end and the natural-language solution (see Section 4.3) the other. In between we can have solutions that present struc- tured data using, e.g., XML formats (in wiki pages). 
The key tradeoff factors for these solutions include (a) how easy it is for users to edit, (b) how easy it is for machines to re-extract structured data, and (c) how easy it is for users to move various pieces of structured data around, i.e., rearrange them in the wiki page. 
The s-slot solution appears best for (b) and (c), and so-so for (a). The natural-language solution is best for (a), so-so for (c), and difﬁcult for (b). An XML-like solution appears best for (a) and (b), but so-so for (c). Developing more solutions, evaluating them, and selecting a good one is an interesting future research direction. 

========14========

8 Conclusions & Future Work 
We have described Cwiki, an approach that employs both “machines” and human users to build structured community portals. This new hybrid machine-human approach can bring signiﬁcant beneﬁts. It can achieve broader and deeper cover - age, provide more incentives for users to contribute, and keep the portal more up to date, with less user efforts. We have applied Cwiki to build a “wikipedia” portal for the database community [1]. We reported on our experience with this por- tal that demonstrates the potentials of Cwiki and suggests many research opportunities. 
Indeed, it is clear that our work here has only scratched the surface of this direction (of combining “machines” and human to build structured wikipedias). Virtually any prob- lem that we have discussed can be “drilled down” deeper. Example problems include: (a) extending the s-slot wiki lan- guage to handle top-k and aggregate views and studying up- dating for such views, (b) developing “macros” that hide the low-level structured constructs to allow users to edit certain structured data pieces more efﬁciently, (c) developing efﬁ - cient eager-update-propagation schemes, (d) developing bet- ter solutions to handle machine updates to data already mod- iﬁed by users, and (e) learning how to leverage user edits to improve the extraction and integration accuracy of machines. 
In addition, we will continue to develop the structured wikipedia for the database community [1], as a real-world application that we can use to evaluate Cwiki. Finally, we plan to release the Cwiki source code to encourage further development and evaluation of community wikipedias in ad- ditional domains. 
References 
[1] http://dblife-labs.cs.wisc.edu/wiki-test/index.php/main page. [2] http://en.wikipedia.org/. 
[3] http://en.wikipedia.org/wiki/semantic wiki. 
[4] http://metaweb.com/. 
[5] http://oak.cs.ucla.edu/blogocenter. 
[6] http://rexa.info/. 
[7] Sixth international workshop on information integration on the 
web. 2007. 
[8] S. Amer-Yahia. A database solution to search 2.0. WebDB-07. [9] I. Androutsopoulos, G. D. Ritchie, and P. Thanisch. Natural 
language interfaces to databases–an introduction. Journal of 
Language Engineering, 1(1):29–81, 1995. 
[10] F. Bancilhon and N. Spyratos. Update semantics of relational 
views. ACM Transactions on Database Systems, 6(4):557–575, 
1981. 
[11] N. Bansal and N. Koudas. Blogscope: Spatio-temporal analy- 
sis of the blogosphere. In WWW-07. 
[12] U. Dayal and P. A. Bernstein. On the correct translation of 
update operations on relational views. ACM Transactions on 
Database Systems, 7(3):381–416, 1982. 
[13] P. DeRose, X. Chai, B. J. Gao, W. Shen, A. Doan, 
P. Bohannon, and J. Zhu. Building community 
wikipedias: A machine-human partnership approach. 
http://pages.cs.wisc.edu/ xchai/cwiki.pdf, 2007. 
[14] P. DeRose, W. Shen, F. Chen, A. Doan, and R. Ramakrishnan. 
Building structured web community portals: The case for an 
incremental and compositional approach. In VLDB-07. [15] A. Doan, P. Bohannon, R. Ramakrishnan, X. Chai, P. DeRose, 
B. Gao, and W. Shen. User-centric research challenges in com- 
munity information management systems. IEEE Data Engi- 
neering Bulletin, Special Issue on Data Management in Social 
Networks, 2007. 
[16] A. Doan, R. Ramakrishnan, F. Chen, P. DeRose, Y. Lee, 
R. McCann, M. Sayyadian, and W. Shen. Community infor- 
mation management. IEEE Data Engineering Bulletin, Special 
Issue on Probabilistic Databases, 29(1), 2006. 
[17] C. Giles, K. Bollacker, and S. Lawrence. Citeseer: An auto- 
matic citation indexing system. In DL-98. 
[18] H. Gregersen and C. S. Jensen. Temporal entity-relationship 
models - a survey. Knowledge and Data Engineering, 
11(3):464–497, 1999. 
[19] Y. Li, H. Yang, and H. V. Jagadish. Constructing a generic 
natural language interface for an xml database. In EDBT-06. [20] R. McCann, A. Kramnik, W. Shen, V. Varadarajan, O. Sobulo, 
and A. Doan. Integrating data from disparate sources: A mass 
collaboration approach. In ICDE-05. 
[21] Z. Nie, J. Wen, and W. Ma. Object-level vertical search. In 
CIDR-07. 
[22] R. Ramakrishnan. Community systems: The world online. In 
CIDR-07. 
[23] R. T. Snodgrass. Developing Time-Oriented Database Appli- 
cations in SQL. Morgan Kaufmann Publishers, Inc., 1999. [24] M. Volkel, M. Krotzsch, D. Vrandecic, H. Haller, and 
R. Studer. Semantic wikipedia. In WWW-06. 
[25] F. Wang, C. Rabsch, P. Kling, P. Liu, and P. John. Web-based 
collaborative information integration for scientiﬁc rese arch. In 
ICDE-07. 
Appendix 
A Implementing Basic Relational Actions 
We deﬁne a set of basic relational actions that a user can execute over Vd, Vs, Gd and Gs. There are 10 actions for Vd, 8 for Vs, 10 for Gd, and 8 for Gs. In the following, we give our implementation of each action. To distinguish actions in different categories, we preﬁx each action by its categor y name. For example, we denote action ai for Vd as Vd::ai. 
A.1 Actions for Vd 
Action a1: Modify an Entity Attribute Value Steps: 
1. Execute Gd::a1. 
Action a2: Modify a Relation Attribute Value Steps: 
1. Execute Gd::a2. 

========15========

Action a3: Insert an Entity Attribute 
Let eid be the entity ID and E be the entity type. Let A be the attribute to insert. 
Steps: 
1. Execute Gd::a3; 
2. Add an inclusive path E(id = eid){A} to Vs. 
Action a4: Insert a Relation Attribute 
Let rid be the relation ID and R be the relation type. Let A be the attribute to insert. 
Steps: 
1. Execute Gd::a4; 
2. Add an inclusive path R(id = rid){A} to Vs. 
Action a5: Insert a New Entity 
Let e be the entity to insert and E be its type. Steps: 
1. Execute Gd::a5, let eid be the ID of e; 
2. Add an inclusive path E(id = eid) to Vs. 
Action a6: Insert a New Relation 
Let r be the relation to insert and R be its type. Let eid1 and eid2 be the IDs of the two entities that r relates, and E1 and E2 be their types. 
Steps: 
1. Execute Gd::a6, let rid be the ID of r; 
2. Add an inclusive path E1(id = eid1).R(id = rid).E2(id = 
eid2) to Vs. 
Action a7: Delete an Entity Attribute 
Let eid be the ID of the entity and E be its type. Let A be the attribute to delete. 
Steps: 
1. Execute Gd::a7; 
2. Add an exclusive path E(id = eid){A} to Vs. 
Action a8: Delete a Relation Attribute 
Let rid be the ID of the relation and R be its type. Let A be the attribute to delete. 
Steps: 
1. Execute Gd::a8; 
2. Add an exclusive path R(id = rid){A} to Vs. 
Action a9: Delete an Entity 
Let e be the entity to delete. Let eid be e's ID and E be e's type. 
Steps: 
1. FOR each relation r that relates e DO 
Execute Vd::a10; 
2. FOR each attribute A (including exists) of e DO 
Execute Vd::a7; 
3. Add an exclusive path E(id = eid) to Vs. 
Action a10: Delete a Relation 
Let r be the relation to delete. Let rid be r's ID and R be r's type. Let eid1 and eid2 be the IDs of the entities that r relates, and E1 and E2 be their types. 
Steps: 
1. FOR each attribute A (including exists) of r DO 
Execute Vd::a8; 
2. Add an exclusive path E1(id = eid1).R(id = rid).E2(id = 
eid2) to Vs. 
A.2 Actions for Vs 
Action a1: Insert an Entity Attribute 
Let eid be the ID of the entity and E be its type. Let A be the attribute to insert. 
Steps: 
1. Add an inclusive path E(id = eid){A} to Vs. 
Action a2: Insert a Relation Attribute 
Let rid be the ID of the relation and R be its type. Let A be the attribute to insert. 
Steps: 
1. Add an inclusive path R(id = rid){A} to Vs. 
Action a3: Insert an Entity 
Let eid be the ID of the entity and E be its type. Steps: 
1. Add an inclusive path E(id = eid) to Vs. 
Action a4: Insert a Relation 
Let r be the relation to insert. Let rid be r's ID and R be r's type. Let eid1 and eid2 be the IDs of the entities that r relates, and E1 and E2 be their types. 
Steps: 
1. Add an inclusive path E1(id = eid1).R(id = rid).E2(id = 
eid2) to Vs. 
Action a5: Delete an Entity Attribute 
Let eid be the ID of the entity and E be its type. Let A be the attribute to delete. 
Steps: 
1. Add an exclusive path E(id = eid){A} to Vs. 
Action a6: Delete a Relation Attribute 
Let rid be the ID of the relation and R be its type. Let A be the attribute to delete. 
Steps: 
1. Add an exclusive path R(id = rid){A} to Vs. 
Action a7: Delete an Entity 
Let e be the entity to delete. Let eid be e's ID and E be e's type. 
Steps: 
1. FOR each relation r that relates e DO 
Execute Vs::a8; 
2. FOR each attribute A (including exists) of e DO 
Execute Vs::a5; 
3. Add an exclusive path E(id = eid) to Vs. 
Action a8: Delete a Relation 

========16========

Let r be the relation to insert. Let rid be r's ID and R be r's type. Let eid1 and eid2 be the IDs of the entities that r relates, and E1 and E2 be their types. 
Steps: 
1. FOR each attribute A (including exists) of r DO 
Execute Vs::a6; 
2. Add an exclusive path E1(id = eid1).R(id = rid).E2(id = 
eid2) to Vs. 
A.3 Actions for Gd 
We use the following notations to represent tables in G: E A m – table for attribute A of entity type E that stores 
attribute values entered by machine M; E A u – table for attribute A of entity type E that stores 
attribute values entered by human users; E A p – table for attribute A of entity type E that stores 
attribute values used in generating Vd; R A m, R A u, R A p – similar to those above but for 
relation type R instead; 
R ID – relation ID table for relation type R. 
Action a1: Modify an Entity Attribute Value 
Let E be the type of the entity and A be the attribute. Let w be the ID of the user who modiﬁes A. 
Steps: 
1. IF w = M THEN 
Logically delete the current value of A in E A m; 
Insert the new value of A into E A m; 
ELSE 
Logically delete the current value of A in E A u; 
Insert the new value of A into E A u; 
2. IF the current value in E A p was entered by M 
OR w != M THEN 
Logically delete the current value of A in E A p; 
Insert the new value of A into E A p; 
Action a2: Modify a Relation Attribute Value 
Let R be the type of the relation and A be the attribute. Let w be the ID of the user who modiﬁes A. 
Steps: 
1. IF w = M THEN 
Logically delete the current value of A in R A m; 
Insert the new value of A into R A m; 
ELSE 
Logically delete the current value of A in R A u; 
Insert the new value of A into R A u; 
2. IF the current value in R A p was entered by M 
OR w != M THEN 
Logically delete the current value of A in R A p; 
Insert the new value of A into R A p; 
Action a3: Insert an Entity Attribute 
Let eid be the ID of the entity and E be its type. Let A be the attribute and w be the ID of the user who inserts A. Steps: 
1. IF w = M THEN 
IF exists a record with id = eid 
AND stop=“9999-12-31 23:59:59” in E A m THEN 
Logically delete the record; 
Insert the new value of A into E A m; 
ELSE 
IF exists a record with id = eid 
AND stop=“9999-12-31 23:59:59” in E A m THEN 
Logically delete the record; 
Insert the new value of A into E A u; 
2. IF exists a record with id = eid 
AND stop=“9999-12-31 23:59:59” in E A p THEN 
IF the record was entered by M OR w! = M THEN 
Logically delete the record; 
Insert the new value of A into E A p; 
Action a4: Insert a Relation Attribute 
Let rid be the ID of the relation and E be its type. Let A be the attribute and w be the ID of the user who inserts A. Steps: 
1. IF w = M THEN 
IF exists a record with id = rid 
AND stop=“9999-12-31 23:59:59” in R A m THEN 
Logically delete the record; 
Insert the new value of A into R A m; 
ELSE 
IF exists a record with id = rid 
AND stop=“9999-12-31 23:59:59” in R A m THEN 
Logically delete the record; 
Insert the new value of A into R A u; 
2. IF exists a record with id = rid 
AND stop=“9999-12-31 23:59:59” in R A p THEN 
IF the record was entered by M OR w! = M THEN 
Logically delete the record; 
Insert the new value of A into R A p; 
Action a5: Insert a New Entity 
Let E be the entity type and max eid be the largest ID in table entity ID. 
Steps: 
1. Insert record (max eid + 1, E) into entity ID. 
Action a6: Insert a New Relation 
Let r be the relation to insert and R be its type. Let eid1 and eid2 be the IDs of the entities that r relates. Let max rid be the largest ID in table R ID. 
Steps: 
1. Insert record (max rid + 1, eid1, eid2) into R ID. 
Action a7: Delete an Entity Attribute Steps: 
1. Execute Gd::a1 with NULL as the attribute value. 
Action a8: Delete a Relation Attribute Steps: 
1. Execute Gd::a2 with NULL as the attribute value. 
Action a9: Delete an Entity 
Let e be the entity to delete. Steps: 

========17========

1. FOR each relation r that relates e DO 
Execute Gd::a10; 
2. FOR each attribute A (including exists) of e DO 
Execute Gd::a7; 
Execute Gs::a5; 
3. Logically delete entity type E in meta entity; 
Action a10: Delete a Relation 
Let r be the relation to delete. 
Steps: 
1. FOR each attribute A (including exists) of r DO 
Execute Gd::a8; 
Action a8: Drop a Relation Type 
Let R be the relation type to drop. 
Steps: 
1. FOR each attribute A (including exists) of R DO 
Execute Gs::a6; 
2. Logically delete entity type R in meta relation; 
A.4 Actions for Gs 
Action a1: Create an Entity Attribute 
Let E be the type of the entity and A be the attribute to create. 
Steps: 
1. Insert attribute A into table meta attribute; 
2. Create tables E A m, E A u and E A p. 
Action a2: Create a Relation Attribute 
Let R be the type of the relation and A be the attribute to create. 
Steps: 
1. Insert attribute A into table meta attribute; 
2. Create tables R A m, R A u and R A p. 
Action a3: Create an Entity Type 
Let E be the entity type to create. Steps: 
1. Insert entity type E into table meta entity; 
2. Execute Gs::a1 for attribute exists. 
Action a4: Create a Relation Type 
Let R be the relation type to create. Steps: 
1. Insert relation type R into table meta relation; 
2. Create table R ID; 
3. Execute Gs::a2 for attribute exists. 
Action a5: Drop an Entity Attribute 
Let E be the entity type and A be the attribute to drop. Steps: 
1. Logically delete attribute A in table meta attribute; 
2. Logically delete all records in E A m, E A u and E A p. 
Action a6: Drop a Relation Attribute 
Let R be the relation type and A be the attribute to drop. Steps: 
1. Logically delete attribute A in table meta attribute; 
2. Logically delete all records in R A m, R A u and R A p. 
Action a7: Drop an Entity Type 
Let E be the entity type to drop. 
Steps: 
1. FOR each relation type R that relates E DO 
Execute Gs::a8; 
2. FOR each attribute A (including exists) of E DO 

========18========

